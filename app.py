import streamlit as st
import pandas as pd
import json
import os
import io
import requests
import shutil
import re
from datetime import datetime, timedelta
from base64 import b64decode

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ PyGithub (Ù„Ø±ÙØ¹ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª)
try:
    from github import Github
    GITHUB_AVAILABLE = True
except Exception:
    GITHUB_AVAILABLE = False

# ===============================
# âš™ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ - ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ Ø¨Ø³Ù‡ÙˆÙ„Ø©
# ===============================
APP_CONFIG = {
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ø§Ù…Ø©
    "APP_TITLE": "CMMS - bel",
    "APP_ICON": "ğŸ­",
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª GitHub
    "REPO_NAME": "mahmedabdallh123/Elqds",
    "BRANCH": "main",
    "FILE_PATH": "l4.xlsx",
    "LOCAL_FILE": "l4.xlsx",
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†
    "MAX_ACTIVE_USERS": 2,
    "SESSION_DURATION_MINUTES": 15,
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
    "SHOW_TECH_SUPPORT_TO_ALL": False,
    "CUSTOM_TABS": ["ğŸ“Š ÙØ­Øµ Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³", "ğŸ“‹ ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†", "ğŸ›  ØªØ¹Ø¯ÙŠÙ„ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "ğŸ‘¥ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†", "ğŸ“ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ"]
}

# ===============================
# ğŸ—‚ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª
# ===============================
USERS_FILE = "users.json"
STATE_FILE = "state.json"
SESSION_DURATION = timedelta(minutes=APP_CONFIG["SESSION_DURATION_MINUTES"])
MAX_ACTIVE_USERS = APP_CONFIG["MAX_ACTIVE_USERS"]

# Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· GitHub ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
GITHUB_EXCEL_URL = f"https://github.com/{APP_CONFIG['REPO_NAME'].split('/')[0]}/{APP_CONFIG['REPO_NAME'].split('/')[1]}/raw/{APP_CONFIG['BRANCH']}/{APP_CONFIG['FILE_PATH']}"

# -------------------------------
# ğŸ§© Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ø­Ø§Ù„Ø©
# -------------------------------
def load_users():
    """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† Ù…Ù„Ù JSON - Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø©"""
    if not os.path.exists(USERS_FILE):
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§ÙØªØ±Ø§Ø¶ÙŠÙŠÙ† Ù…Ø¹ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        default_users = {
            "admin": {
                "password": "admin123", 
                "role": "admin", 
                "created_at": datetime.now().isoformat(),
                "permissions": ["all"]
            }
        }
        with open(USERS_FILE, "w", encoding="utf-8") as f:
            json.dump(default_users, f, indent=4, ensure_ascii=False)
        return default_users
    
    try:
        with open(USERS_FILE, "r", encoding="utf-8") as f:
            users = json.load(f)
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… admin Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        if "admin" not in users:
            users["admin"] = {
                "password": "admin123", 
                "role": "admin", 
                "created_at": datetime.now().isoformat(),
                "permissions": ["all"]
            }
            # Ø­ÙØ¸ Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ù…Ø¨Ø§Ø´Ø±Ø©
            with open(USERS_FILE, "w", encoding="utf-8") as f:
                json.dump(users, f, indent=4, ensure_ascii=False)
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„ÙƒÙ„ Ù…Ø³ØªØ®Ø¯Ù…
        for username, user_data in users.items():
            if "role" not in user_data:
                if username == "admin":
                    user_data["role"] = "admin"
                    user_data["permissions"] = ["all"]
                else:
                    user_data["role"] = "viewer"
                    user_data["permissions"] = ["view"]
            
            if "permissions" not in user_data:
                if user_data.get("role") == "admin":
                    user_data["permissions"] = ["all"]
                elif user_data.get("role") == "editor":
                    user_data["permissions"] = ["view", "edit"]
                else:
                    user_data["permissions"] = ["view"]
                    
            if "created_at" not in user_data:
                user_data["created_at"] = datetime.now().isoformat()
        
        # Ø­ÙØ¸ Ø£ÙŠ ØªØ­Ø¯ÙŠØ«Ø§Øª
        with open(USERS_FILE, "w", encoding="utf-8") as f:
            json.dump(users, f, indent=4, ensure_ascii=False)
        
        return users
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ù„Ù users.json: {e}")
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠÙŠÙ† ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
        return {
            "admin": {
                "password": "admin123", 
                "role": "admin", 
                "created_at": datetime.now().isoformat(),
                "permissions": ["all"]
            }
        }

def save_users(users):
    """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¥Ù„Ù‰ Ù…Ù„Ù JSON"""
    try:
        with open(USERS_FILE, "w", encoding="utf-8") as f:
            json.dump(users, f, indent=4, ensure_ascii=False)
        return True
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù…Ù„Ù users.json: {e}")
        return False

def load_state():
    if not os.path.exists(STATE_FILE):
        with open(STATE_FILE, "w", encoding="utf-8") as f:
            json.dump({}, f, indent=4, ensure_ascii=False)
        return {}
    try:
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {}

def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, indent=4, ensure_ascii=False)

def cleanup_sessions(state):
    now = datetime.now()
    changed = False
    for user, info in list(state.items()):
        if info.get("active") and "login_time" in info:
            try:
                login_time = datetime.fromisoformat(info["login_time"])
                if now - login_time > SESSION_DURATION:
                    info["active"] = False
                    info.pop("login_time", None)
                    changed = True
            except:
                info["active"] = False
                changed = True
    if changed:
        save_state(state)
    return state

def remaining_time(state, username):
    if not username or username not in state:
        return None
    info = state.get(username)
    if not info or not info.get("active"):
        return None
    try:
        lt = datetime.fromisoformat(info["login_time"])
        remaining = SESSION_DURATION - (datetime.now() - lt)
        if remaining.total_seconds() <= 0:
            return None
        return remaining
    except:
        return None

# -------------------------------
# ğŸ” ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬
# -------------------------------
def logout_action():
    state = load_state()
    username = st.session_state.get("username")
    if username and username in state:
        state[username]["active"] = False
        state[username].pop("login_time", None)
        save_state(state)
    keys = list(st.session_state.keys())
    for k in keys:
        st.session_state.pop(k, None)
    st.rerun()

# -------------------------------
# ğŸ§  ÙˆØ§Ø¬Ù‡Ø© ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„
# -------------------------------
def login_ui():
    users = load_users()
    state = cleanup_sessions(load_state())
    if "logged_in" not in st.session_state:
        st.session_state.logged_in = False
        st.session_state.username = None
        st.session_state.user_role = None
        st.session_state.user_permissions = []

    st.title(f"{APP_CONFIG['APP_ICON']} ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ - {APP_CONFIG['APP_TITLE']}")

    # ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø§Ù„Ù…Ù„Ù
    try:
        with open(USERS_FILE, "r", encoding="utf-8") as f:
            current_users = json.load(f)
        user_list = list(current_users.keys())
    except:
        user_list = list(users.keys())

    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    username_input = st.selectbox("ğŸ‘¤ Ø§Ø®ØªØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…", user_list)
    password = st.text_input("ğŸ”‘ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±", type="password")

    active_users = [u for u, v in state.items() if v.get("active")]
    active_count = len(active_users)
    st.caption(f"ğŸ”’ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† Ø§Ù„Ù†Ø´Ø·ÙˆÙ† Ø§Ù„Ø¢Ù†: {active_count} / {MAX_ACTIVE_USERS}")

    if not st.session_state.logged_in:
        if st.button("ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„"):
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† Ø¬Ø¯ÙŠØ¯ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ø­Ø¯Ø« Ø¨ÙŠØ§Ù†Ø§Øª
            current_users = load_users()
            
            if username_input in current_users and current_users[username_input]["password"] == password:
                if username_input == "admin":
                    pass
                elif username_input in active_users:
                    st.warning("âš  Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø³Ø¬Ù„ Ø¯Ø®ÙˆÙ„ Ø¨Ø§Ù„ÙØ¹Ù„.")
                    return False
                elif active_count >= MAX_ACTIVE_USERS:
                    st.error("ğŸš« Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…ØªØµÙ„ÙŠÙ† Ø­Ø§Ù„ÙŠØ§Ù‹.")
                    return False
                
                state[username_input] = {"active": True, "login_time": datetime.now().isoformat()}
                save_state(state)
                
                st.session_state.logged_in = True
                st.session_state.username = username_input
                st.session_state.user_role = current_users[username_input].get("role", "viewer")
                st.session_state.user_permissions = current_users[username_input].get("permissions", ["view"])
                
                st.success(f"âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„: {username_input} ({st.session_state.user_role})")
                st.rerun()
            else:
                st.error("âŒ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©.")
        return False
    else:
        username = st.session_state.username
        user_role = st.session_state.user_role
        st.success(f"âœ… Ù…Ø³Ø¬Ù„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙƒÙ€: {username} ({user_role})")
        rem = remaining_time(state, username)
        if rem:
            mins, secs = divmod(int(rem.total_seconds()), 60)
            st.info(f"â³ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ: {mins:02d}:{secs:02d}")
        else:
            st.warning("â° Ø§Ù†ØªÙ‡Øª Ø§Ù„Ø¬Ù„Ø³Ø©ØŒ Ø³ÙŠØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬.")
            logout_action()
        if st.button("ğŸšª ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬"):
            logout_action()
        return True

# -------------------------------
# ğŸ”„ Ø·Ø±Ù‚ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù„Ù Ù…Ù† GitHub
# -------------------------------
def fetch_from_github_requests():
    """ØªØ­Ù…ÙŠÙ„ Ø¨Ø¥Ø³ØªØ®Ø¯Ø§Ù… Ø±Ø§Ø¨Ø· RAW (requests)"""
    try:
        response = requests.get(GITHUB_EXCEL_URL, stream=True, timeout=15)
        response.raise_for_status()
        with open(APP_CONFIG["LOCAL_FILE"], "wb") as f:
            shutil.copyfileobj(response.raw, f)
        # Ø§Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
        try:
            st.cache_data.clear()
        except:
            pass
        return True
    except Exception as e:
        st.error(f"âš  ÙØ´Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù…Ù† GitHub: {e}")
        return False

def fetch_from_github_api():
    """ØªØ­Ù…ÙŠÙ„ Ø¹Ø¨Ø± GitHub API (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyGithub token ÙÙŠ secrets)"""
    if not GITHUB_AVAILABLE:
        return fetch_from_github_requests()
    
    try:
        token = st.secrets.get("github", {}).get("token", None)
        if not token:
            return fetch_from_github_requests()
        
        g = Github(token)
        repo = g.get_repo(APP_CONFIG["REPO_NAME"])
        file_content = repo.get_contents(APP_CONFIG["FILE_PATH"], ref=APP_CONFIG["BRANCH"])
        content = b64decode(file_content.content)
        with open(APP_CONFIG["LOCAL_FILE"], "wb") as f:
            f.write(content)
        try:
            st.cache_data.clear()
        except:
            pass
        return True
    except Exception as e:
        st.error(f"âš  ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† GitHub: {e}")
        return False

# -------------------------------
# ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª (Ù…Ø®Ø¨Ø£) - Ù…Ø¹Ø¯Ù„ Ù„Ù‚Ø±Ø§Ø¡Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª
# -------------------------------
@st.cache_data(show_spinner=False)
def load_all_sheets():
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ù…Ù† Ù…Ù„Ù Excel"""
    if not os.path.exists(APP_CONFIG["LOCAL_FILE"]):
        return None
    
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª
        sheets = pd.read_excel(APP_CONFIG["LOCAL_FILE"], sheet_name=None)
        
        if not sheets:
            return None
        
        # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„ÙƒÙ„ Ø´ÙŠØª
        for name, df in sheets.items():
            df.columns = df.columns.astype(str).str.strip()
        
        return sheets
    except Exception as e:
        return None

# Ù†Ø³Ø®Ø© Ù…Ø¹ dtype=object Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ­Ø±ÙŠØ±
@st.cache_data(show_spinner=False)
def load_sheets_for_edit():
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ù„Ù„ØªØ­Ø±ÙŠØ±"""
    if not os.path.exists(APP_CONFIG["LOCAL_FILE"]):
        return None
    
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ù…Ø¹ dtype=object Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        sheets = pd.read_excel(APP_CONFIG["LOCAL_FILE"], sheet_name=None, dtype=object)
        
        if not sheets:
            return None
        
        # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„ÙƒÙ„ Ø´ÙŠØª
        for name, df in sheets.items():
            df.columns = df.columns.astype(str).str.strip()
        
        return sheets
    except Exception as e:
        return None

# -------------------------------
# ğŸ” Ø­ÙØ¸ Ù…Ø­Ù„ÙŠ + Ø±ÙØ¹ Ø¹Ù„Ù‰ GitHub + Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´ + Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„
# -------------------------------
def save_local_excel_and_push(sheets_dict, commit_message="Update from Streamlit"):
    """Ø¯Ø§Ù„Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠ ÙˆØ§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ GitHub"""
    # Ø§Ø­ÙØ¸ Ù…Ø­Ù„ÙŠØ§Ù‹
    try:
        with pd.ExcelWriter(APP_CONFIG["LOCAL_FILE"], engine="openpyxl") as writer:
            for name, sh in sheets_dict.items():
                try:
                    sh.to_excel(writer, sheet_name=name, index=False)
                except Exception:
                    sh.astype(object).to_excel(writer, sheet_name=name, index=False)
    except Exception as e:
        st.error(f"âš  Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ù„ÙŠ: {e}")
        return None

    # Ø§Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
    try:
        st.cache_data.clear()
    except:
        pass

    # Ø­Ø§ÙˆÙ„ Ø§Ù„Ø±ÙØ¹ Ø¹Ø¨Ø± PyGithub token ÙÙŠ secrets
    token = st.secrets.get("github", {}).get("token", None)
    if not token:
        st.warning("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ GitHub token. Ø³ÙŠØªÙ… Ø§Ù„Ø­ÙØ¸ Ù…Ø­Ù„ÙŠØ§Ù‹ ÙÙ‚Ø·.")
        return load_sheets_for_edit()

    if not GITHUB_AVAILABLE:
        st.warning("âš  PyGithub ØºÙŠØ± Ù…ØªÙˆÙØ±. Ø³ÙŠØªÙ… Ø§Ù„Ø­ÙØ¸ Ù…Ø­Ù„ÙŠØ§Ù‹ ÙÙ‚Ø·.")
        return load_sheets_for_edit()

    try:
        g = Github(token)
        repo = g.get_repo(APP_CONFIG["REPO_NAME"])
        with open(APP_CONFIG["LOCAL_FILE"], "rb") as f:
            content = f.read()

        try:
            contents = repo.get_contents(APP_CONFIG["FILE_PATH"], ref=APP_CONFIG["BRANCH"])
            result = repo.update_file(path=APP_CONFIG["FILE_PATH"], message=commit_message, content=content, sha=contents.sha, branch=APP_CONFIG["BRANCH"])
            st.success(f"âœ… ØªÙ… Ø§Ù„Ø­ÙØ¸ ÙˆØ§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ GitHub Ø¨Ù†Ø¬Ø§Ø­: {commit_message}")
            return load_sheets_for_edit()
        except Exception as e:
            # Ø­Ø§ÙˆÙ„ Ø±ÙØ¹ ÙƒÙ…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡
            try:
                result = repo.create_file(path=APP_CONFIG["FILE_PATH"], message=commit_message, content=content, branch=APP_CONFIG["BRANCH"])
                st.success(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ø¹Ù„Ù‰ GitHub: {commit_message}")
                return load_sheets_for_edit()
            except Exception as create_error:
                st.error(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ø¹Ù„Ù‰ GitHub: {create_error}")
                return None

    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ GitHub: {e}")
        return None

def auto_save_to_github(sheets_dict, operation_description):
    """Ø¯Ø§Ù„Ø© Ø§Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø­Ø³Ù†Ø©"""
    username = st.session_state.get("username", "unknown")
    commit_message = f"{operation_description} by {username} at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    
    result = save_local_excel_and_push(sheets_dict, commit_message)
    if result is not None:
        st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙÙŠ GitHub")
        return result
    else:
        st.error("âŒ ÙØ´Ù„ Ø§Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")
        return sheets_dict

# -------------------------------
# ğŸ§° Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„Ù†ØµÙˆØµ
# -------------------------------
def normalize_name(s):
    if s is None: return ""
    s = str(s).replace("\n", "+")
    s = re.sub(r"[^0-9a-zA-Z\u0600-\u06FF\+\s_/.-]", " ", s)
    s = re.sub(r"\s+", " ", s).strip().lower()
    return s

def split_needed_services(needed_service_str):
    if not isinstance(needed_service_str, str) or needed_service_str.strip() == "":
        return []
    parts = re.split(r"\+|,|\n|;", needed_service_str)
    return [p.strip() for p in parts if p.strip() != ""]

def highlight_cell(val, col_name):
    color_map = {
        "Service Needed": "background-color: #fff3cd; color:#856404; font-weight:bold;",
        "Service Done": "background-color: #d4edda; color:#155724; font-weight:bold;",
        "Service Didn't Done": "background-color: #f8d7da; color:#721c24; font-weight:bold;",
        "Date": "background-color: #e7f1ff; color:#004085; font-weight:bold;",
        "Tones": "background-color: #e8f8f5; color:#0d5c4a; font-weight:bold;",
        "Event": "background-color: #e2f0d9; color:#2e6f32; font-weight:bold;",
        "Correction": "background-color: #fdebd0; color:#7d6608; font-weight:bold;",
        "Servised by": "background-color: #f0f0f0; color:#333; font-weight:bold;",
        "Card Number": "background-color: #ebdef0; color:#4a235a; font-weight:bold;"
    }
    return color_map.get(col_name, "")

def style_table(row):
    return [highlight_cell(row[col], col) for col in row.index]

def get_user_permissions(user_role, user_permissions):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¯ÙˆØ± ÙˆØ§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª"""
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¯ÙˆØ± adminØŒ ÙŠØ¹Ø·Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª
    if user_role == "admin":
        return {
            "can_view": True,
            "can_edit": True,
            "can_manage_users": True,
            "can_see_tech_support": True
        }
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¯ÙˆØ± editor
    elif user_role == "editor":
        return {
            "can_view": True,
            "can_edit": True,
            "can_manage_users": False,
            "can_see_tech_support": False
        }
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¯ÙˆØ± viewer Ø£Ùˆ Ø£ÙŠ Ø¯ÙˆØ± Ø¢Ø®Ø±
    else:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„ÙØ±Ø¯ÙŠØ©
        return {
            "can_view": "view" in user_permissions or "edit" in user_permissions or "all" in user_permissions,
            "can_edit": "edit" in user_permissions or "all" in user_permissions,
            "can_manage_users": "manage_users" in user_permissions or "all" in user_permissions,
            "can_see_tech_support": "tech_support" in user_permissions or "all" in user_permissions
        }

def get_servised_by_value(row):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙŠÙ…Ø© ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø© Ù…Ù† Ø§Ù„ØµÙ"""
    # Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù„ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©
    servised_columns = [
        "Servised by", "SERVISED BY", "servised by", "Servised By",
        "Serviced by", "Service by", "Serviced By", "Service By",
        "Ø®Ø¯Ù… Ø¨ÙˆØ§Ø³Ø·Ø©", "ØªÙ… Ø§Ù„Ø®Ø¯Ù…Ø© Ø¨ÙˆØ§Ø³Ø·Ø©", "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©"
    ]
    
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
    for col in servised_columns:
        if col in row.index:
            value = str(row[col]).strip()
            if value and value.lower() not in ["nan", "none", ""]:
                return value
    
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©
    for col in row.index:
        col_normalized = normalize_name(col)
        if any(keyword in col_normalized for keyword in ["servisedby", "servicedby", "serviceby", "Ø®Ø¯Ù…Ø¨ÙˆØ§Ø³Ø·Ø©", "ÙÙ†ÙŠ"]):
            value = str(row[col]).strip()
            if value and value.lower() not in ["nan", "none", ""]:
                return value
    
    return "-"

# -------------------------------
# ğŸ–¥ Ø¯Ø§Ù„Ø© ÙØ­Øµ Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³ ÙÙ‚Ø· - Ù…Ù† Ø§Ù„Ø´ÙŠØªØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
# -------------------------------
def check_service_status(card_num, current_tons, all_sheets):
    """ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³ ÙÙ‚Ø·"""
    if not all_sheets:
        st.error("âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ø´ÙŠØªØ§Øª.")
        return
    
    if "ServicePlan" not in all_sheets:
        st.error("âŒ Ø§Ù„Ù…Ù„Ù Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø´ÙŠØª ServicePlan.")
        return
    
    service_plan_df = all_sheets["ServicePlan"]
    card_services_sheet_name = f"Card{card_num}_Services"
    
    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ Ø´ÙŠØª Ø®Ø¯Ù…Ø§Øª Ù…Ù†ÙØµÙ„ØŒ Ù†Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø´ÙŠØª Ø§Ù„Ù‚Ø¯ÙŠÙ…
    if card_services_sheet_name not in all_sheets:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø´ÙŠØª Ø§Ù„Ù‚Ø¯ÙŠÙ…
        card_old_sheet_name = f"Card{card_num}"
        if card_old_sheet_name in all_sheets:
            card_df = all_sheets[card_old_sheet_name]
            # ÙÙ„ØªØ±Ø© ÙÙ‚Ø· Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ Ù„Ù‡Ø§ Min_Tones Ùˆ Max_Tones
            services_df = card_df[
                (card_df.get("Min_Tones", pd.NA).notna()) & 
                (card_df.get("Max_Tones", pd.NA).notna()) &
                (card_df.get("Min_Tones", "") != "") & 
                (card_df.get("Max_Tones", "") != "")
            ].copy()
        else:
            st.warning(f"âš  Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø´ÙŠØª Ø¨Ø§Ø³Ù… {card_services_sheet_name} Ø£Ùˆ {card_old_sheet_name}")
            return
    else:
        card_df = all_sheets[card_services_sheet_name]
        services_df = card_df.copy()

    st.subheader("âš™ Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¹Ø±Ø¶")
    view_option = st.radio(
        "Ø§Ø®ØªØ± Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¹Ø±Ø¶:",
        ("Ø§Ù„Ø´Ø±ÙŠØ­Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙÙ‚Ø·", "ÙƒÙ„ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ø£Ù‚Ù„", "ÙƒÙ„ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ø£Ø¹Ù„Ù‰", "Ù†Ø·Ø§Ù‚ Ù…Ø®ØµØµ", "ÙƒÙ„ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­"),
        horizontal=True,
        key=f"service_view_option_{card_num}"
    )

    min_range = st.session_state.get(f"service_min_range_{card_num}", max(0, current_tons - 500))
    max_range = st.session_state.get(f"service_max_range_{card_num}", current_tons + 500)
    if view_option == "Ù†Ø·Ø§Ù‚ Ù…Ø®ØµØµ":
        col1, col2 = st.columns(2)
        with col1:
            min_range = st.number_input("Ù…Ù† (Ø·Ù†):", min_value=0, step=100, value=min_range, key=f"service_min_range_{card_num}")
        with col2:
            max_range = st.number_input("Ø¥Ù„Ù‰ (Ø·Ù†):", min_value=min_range, step=100, value=max_range, key=f"service_max_range_{card_num}")

    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø´Ø±Ø§Ø¦Ø­
    if view_option == "Ø§Ù„Ø´Ø±ÙŠØ­Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙÙ‚Ø·":
        selected_slices = service_plan_df[(service_plan_df["Min_Tones"] <= current_tons) & (service_plan_df["Max_Tones"] >= current_tons)]
    elif view_option == "ÙƒÙ„ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ø£Ù‚Ù„":
        selected_slices = service_plan_df[service_plan_df["Max_Tones"] <= current_tons]
    elif view_option == "ÙƒÙ„ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ø£Ø¹Ù„Ù‰":
        selected_slices = service_plan_df[service_plan_df["Min_Tones"] >= current_tons]
    elif view_option == "Ù†Ø·Ø§Ù‚ Ù…Ø®ØµØµ":
        selected_slices = service_plan_df[(service_plan_df["Min_Tones"] >= min_range) & (service_plan_df["Max_Tones"] <= max_range)]
    else:
        selected_slices = service_plan_df.copy()

    if selected_slices.empty:
        st.warning("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø´Ø±Ø§Ø¦Ø­ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯.")
        return

    all_results = []
    service_stats = {
        "service_counts": {},  # ØªØ¹Ø¯Ø§Ø¯ ÙƒÙ„ Ø®Ø¯Ù…Ø© Ù…Ø·Ù„ÙˆØ¨Ø©
        "service_done_counts": {},  # ØªØ¹Ø¯Ø§Ø¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ù†ÙØ°Ø©
        "total_needed_services": 0,
        "total_done_services": 0,
        "by_slice": {}  # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø´Ø±ÙŠØ­Ø©
    }
    
    for _, current_slice in selected_slices.iterrows():
        slice_min = current_slice["Min_Tones"]
        slice_max = current_slice["Max_Tones"]
        slice_key = f"{slice_min}-{slice_max}"
        
        needed_service_raw = current_slice.get("Service", "")
        needed_parts = split_needed_services(needed_service_raw)
        needed_norm = [normalize_name(p) for p in needed_parts]
        
        # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        service_stats["by_slice"][slice_key] = {
            "needed": needed_parts,
            "done": [],
            "not_done": [],
            "total_needed": len(needed_parts),
            "total_done": 0
        }
        
        for service in needed_parts:
            service_stats["service_counts"][service] = service_stats["service_counts"].get(service, 0) + 1
        service_stats["total_needed_services"] += len(needed_parts)

        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©
        mask = (services_df.get("Min_Tones", 0).fillna(0) <= slice_max) & (services_df.get("Max_Tones", 0).fillna(0) >= slice_min)
        matching_rows = services_df[mask]

        if not matching_rows.empty:
            for _, row in matching_rows.iterrows():
                done_services_set = set()
                
                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø®Ø¯Ù…Ø§Øª Ù…Ù†Ø¬Ø²Ø© (Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©)
                metadata_columns = {
                    "card", "Tones", "Min_Tones", "Max_Tones", "Date", 
                    "Other", "Servised by", "Event", "Correction",
                    "Card", "TONES", "MIN_TONES", "MAX_TONES", "DATE",
                    "OTHER", "EVENT", "CORRECTION", "SERVISED BY",
                    "servised by", "Servised By", 
                    "Serviced by", "Service by", "Serviced By", "Service By",
                    "Ø®Ø¯Ù… Ø¨ÙˆØ§Ø³Ø·Ø©", "ØªÙ… Ø§Ù„Ø®Ø¯Ù…Ø© Ø¨ÙˆØ§Ø³Ø·Ø©", "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©"
                }
                
                all_columns = set(services_df.columns)
                service_columns = all_columns - metadata_columns
                
                final_service_columns = set()
                for col in service_columns:
                    col_normalized = normalize_name(col)
                    metadata_normalized = {normalize_name(mc) for mc in metadata_columns}
                    if col_normalized not in metadata_normalized:
                        final_service_columns.add(col)
                
                for col in final_service_columns:
                    val = str(row.get(col, "")).strip()
                    if val and val.lower() not in ["nan", "none", "", "null", "0"]:
                        if val.lower() not in ["no", "false", "not done", "Ù„Ù… ØªØªÙ…", "x", "-"]:
                            done_services_set.add(col)
                            # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ù†ÙØ°Ø©
                            service_stats["service_done_counts"][col] = service_stats["service_done_counts"].get(col, 0) + 1
                            service_stats["total_done_services"] += 1

                # Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³ ÙÙ‚Ø·
                current_date = str(row.get("Date", "")).strip() if pd.notna(row.get("Date")) else "-"
                current_tones = str(row.get("Tones", "")).strip() if pd.notna(row.get("Tones")) else "-"
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©
                servised_by_value = get_servised_by_value(row)
                
                done_services = sorted(list(done_services_set))
                done_norm = [normalize_name(c) for c in done_services]
                
                # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø´Ø±ÙŠØ­Ø©
                service_stats["by_slice"][slice_key]["done"].extend(done_services)
                service_stats["by_slice"][slice_key]["total_done"] += len(done_services)
                
                # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ù†Ø¬Ø²Ø© Ù…Ø¹ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
                not_done = []
                for needed_part, needed_norm_part in zip(needed_parts, needed_norm):
                    if needed_norm_part not in done_norm:
                        not_done.append(needed_part)
                
                service_stats["by_slice"][slice_key]["not_done"].extend(not_done)

                all_results.append({
                    "Card Number": card_num,
                    "Min_Tons": slice_min,
                    "Max_Tons": slice_max,
                    "Service Needed": " + ".join(needed_parts) if needed_parts else "-",
                    "Service Done": ", ".join(done_services) if done_services else "-",
                    "Service Didn't Done": ", ".join(not_done) if not_done else "-",
                    "Tones": current_tones,
                    "Servised by": servised_by_value,
                    "Date": current_date
                })
        else:
            # Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª Ø³ÙŠØ±ÙÙŠØ³
            all_results.append({
                "Card Number": card_num,
                "Min_Tons": slice_min,
                "Max_Tons": slice_max,
                "Service Needed": " + ".join(needed_parts) if needed_parts else "-",
                "Service Done": "-",
                "Service Didn't Done": ", ".join(needed_parts) if needed_parts else "-",
                "Tones": "-",
                "Servised by": "-",
                "Date": "-"
            })
            
            # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø´Ø±ÙŠØ­Ø© (Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø®Ø¯Ù…Ø§Øª Ù…Ù†ÙØ°Ø©)
            service_stats["by_slice"][slice_key]["not_done"] = needed_parts.copy()

    result_df = pd.DataFrame(all_results).dropna(how="all").reset_index(drop=True)

    st.markdown("### ğŸ“‹ Ù†ØªØ§Ø¦Ø¬ ÙØ­Øµ Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³")
    if not result_df.empty:
        st.dataframe(result_df.style.apply(style_table, axis=1), use_container_width=True)

        # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§Ù„Ù†Ø³Ø¨
        show_service_statistics(service_stats, result_df)

        # ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        buffer = io.BytesIO()
        result_df.to_excel(buffer, index=False, engine="openpyxl")
        st.download_button(
            label="ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ€ Excel",
            data=buffer.getvalue(),
            file_name=f"Service_Report_Card{card_num}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø®Ø¯Ù…Ø§Øª Ù…Ø³Ø¬Ù„Ø© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©.")

def show_service_statistics(service_stats, result_df):
    """Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§Ù„Ù†Ø³Ø¨ Ø§Ù„Ù…Ø¦ÙˆÙŠØ© Ù„ÙØ­Øµ Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³"""
    st.markdown("---")
    st.markdown("### ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§Ù„Ù†Ø³Ø¨ Ø§Ù„Ù…Ø¦ÙˆÙŠØ©")
    
    if service_stats["total_needed_services"] == 0:
        st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø®Ø¯Ù…Ø§Øª Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯.")
        return
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
    completion_rate = (service_stats["total_done_services"] / service_stats["total_needed_services"]) * 100 if service_stats["total_needed_services"] > 0 else 0
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†Ø³Ø¨ Ø§Ù„Ø¹Ø§Ù…Ø©
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ğŸ“ˆ Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ø¹Ø§Ù…Ø©",
            value=f"{completion_rate:.1f}%",
            delta=f"{service_stats['total_done_services']}/{service_stats['total_needed_services']}"
        )
    
    with col2:
        st.metric(
            label="ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©",
            value=service_stats["total_needed_services"]
        )
    
    with col3:
        st.metric(
            label="âœ… Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ù†ÙØ°Ø©",
            value=service_stats["total_done_services"]
        )
    
    with col4:
        remaining = service_stats["total_needed_services"] - service_stats["total_done_services"]
        st.metric(
            label="â³ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©",
            value=remaining
        )
    
    st.markdown("---")
    
    # ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù„Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©
    stat_tabs = st.tabs([
        "ğŸ“ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª",
        "ğŸ“‹ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª",
        "ğŸ“Š Ø­Ø³Ø¨ Ø§Ù„Ø´Ø±ÙŠØ­Ø©"
    ])
    
    with stat_tabs[0]:
        st.markdown("#### ğŸ“ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙØµÙ„Ø© Ù„ÙƒÙ„ Ø®Ø¯Ù…Ø©")
        
        # Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ù„Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        stat_data = []
        all_services = set(service_stats["service_counts"].keys()).union(
            set(service_stats["service_done_counts"].keys())
        )
        
        for service in sorted(all_services):
            needed_count = service_stats["service_counts"].get(service, 0)
            done_count = service_stats["service_done_counts"].get(service, 0)
            completion_rate_service = (done_count / needed_count * 100) if needed_count > 0 else 0
            
            stat_data.append({
                "Ø§Ù„Ø®Ø¯Ù…Ø©": service,
                "Ù…Ø·Ù„ÙˆØ¨Ø©": needed_count,
                "Ù…Ù†ÙØ°Ø©": done_count,
                "Ù…ØªØ¨Ù‚ÙŠØ©": needed_count - done_count,
                "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²": f"{completion_rate_service:.1f}%",
                "Ø­Ø§Ù„Ø©": "âœ… Ù…Ù…ØªØ§Ø²" if completion_rate_service >= 90 else 
                       "ğŸŸ¢ Ø¬ÙŠØ¯" if completion_rate_service >= 70 else 
                       "ğŸŸ¡ Ù…ØªÙˆØ³Ø·" if completion_rate_service >= 50 else 
                       "ğŸ”´ Ø¶Ø¹ÙŠÙ"
            })
        
        if stat_data:
            stat_df = pd.DataFrame(stat_data)
            st.dataframe(stat_df, use_container_width=True, height=400)
        else:
            st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ù„Ù„Ø®Ø¯Ù…Ø§Øª.")
    
    with stat_tabs[1]:
        st.markdown("#### ğŸ“‹ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª")
        
        if service_stats["service_counts"]:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… plotly Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
            try:
                import plotly.express as px
                
                plot_data = []
                for service, needed_count in service_stats["service_counts"].items():
                    done_count = service_stats["service_done_counts"].get(service, 0)
                    
                    plot_data.append({
                        "Ø§Ù„Ø®Ø¯Ù…Ø©": service,
                        "Ø§Ù„Ù†ÙˆØ¹": "Ù…Ø·Ù„ÙˆØ¨Ø©",
                        "Ø§Ù„Ø¹Ø¯Ø¯": needed_count
                    })
                    plot_data.append({
                        "Ø§Ù„Ø®Ø¯Ù…Ø©": service,
                        "Ø§Ù„Ù†ÙˆØ¹": "Ù…Ù†ÙØ°Ø©",
                        "Ø§Ù„Ø¹Ø¯Ø¯": done_count
                    })
                
                plot_df = pd.DataFrame(plot_data)
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø®Ø·Ø·
                fig = px.bar(
                    plot_df, 
                    x="Ø§Ù„Ø®Ø¯Ù…Ø©", 
                    y="Ø§Ù„Ø¹Ø¯Ø¯", 
                    color="Ø§Ù„Ù†ÙˆØ¹",
                    barmode="group",
                    title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙˆØ§Ù„Ù…Ù†ÙØ°Ø©",
                    color_discrete_map={
                        "Ù…Ø·Ù„ÙˆØ¨Ø©": "#FF6B6B",
                        "Ù…Ù†ÙØ°Ø©": "#4ECDC4"
                    }
                )
                fig.update_layout(
                    xaxis_title="Ø§Ù„Ø®Ø¯Ù…Ø©",
                    yaxis_title="Ø§Ù„Ø¹Ø¯Ø¯",
                    showlegend=True,
                    height=500
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Ù…Ø®Ø·Ø· Ø¯Ø§Ø¦Ø±ÙŠ Ù„Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
                fig2 = px.pie(
                    names=["âœ… Ù…Ù†ÙØ°Ø©", "â³ ØºÙŠØ± Ù…Ù†ÙØ°Ø©"],
                    values=[service_stats["total_done_services"], 
                           service_stats["total_needed_services"] - service_stats["total_done_services"]],
                    title="Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ø¹Ø§Ù…Ø©",
                    color_discrete_sequence=["#4ECDC4", "#FF6B6B"]
                )
                fig2.update_traces(textposition='inside', textinfo='percent+label')
                st.plotly_chart(fig2, use_container_width=True)
                
            except ImportError:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… streamlit native charts Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† plotly
                st.info("ğŸ“Š Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ø§Ù„Ù…Ø¶Ù…Ù†Ø© ÙÙŠ Streamlit")
                
                # Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø¨Ø³ÙŠØ· Ù„Ù„ØªÙˆØ²ÙŠØ¹
                st.markdown("**ğŸ“‹ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª:**")
                
                dist_data = []
                for service, needed_count in service_stats["service_counts"].items():
                    done_count = service_stats["service_done_counts"].get(service, 0)
                    completion_rate = (done_count / needed_count * 100) if needed_count > 0 else 0
                    
                    dist_data.append({
                        "Ø§Ù„Ø®Ø¯Ù…Ø©": service,
                        "Ù…Ø·Ù„ÙˆØ¨Ø©": needed_count,
                        "Ù…Ù†ÙØ°Ø©": done_count,
                        "Ù†Ø³Ø¨Ø©": f"{completion_rate:.1f}%"
                    })
                
                if dist_data:
                    dist_df = pd.DataFrame(dist_data).sort_values("Ù†Ø³Ø¨Ø©", ascending=False)
                    st.dataframe(dist_df, use_container_width=True, height=300)
                
                # Ù…Ø®Ø·Ø· Ø´Ø±ÙŠØ·ÙŠ Ø¨Ø³ÙŠØ· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… streamlit
                st.markdown("**ğŸ“Š Ù…Ø®Ø·Ø· Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù…Ù†ÙØ°Ø©:**")
                
                # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
                chart_data = pd.DataFrame({
                    "Ø§Ù„Ø®Ø¯Ù…Ø©": list(service_stats["service_counts"].keys()),
                    "Ù…Ø·Ù„ÙˆØ¨Ø©": list(service_stats["service_counts"].values()),
                    "Ù…Ù†ÙØ°Ø©": [service_stats["service_done_counts"].get(service, 0) 
                              for service in service_stats["service_counts"].keys()]
                })
                
                # Ø£Ø®Ø° Ø£ÙˆÙ„ 10 Ø®Ø¯Ù…Ø§Øª Ù„Ø¹Ø±Ø¶Ù‡Ø§ Ø¨Ø´ÙƒÙ„ Ø£ÙˆØ¶Ø­
                if len(chart_data) > 10:
                    chart_data = chart_data.nlargest(10, "Ù…Ø·Ù„ÙˆØ¨Ø©")
                
                st.bar_chart(
                    chart_data.set_index("Ø§Ù„Ø®Ø¯Ù…Ø©"),
                    height=400
                )
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ÙƒÙ€ progress bar
                st.markdown(f"**ğŸ“ˆ Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ø¹Ø§Ù…Ø©:** {completion_rate:.1f}%")
                st.progress(completion_rate / 100)
        else:
            st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª.")
    
    with stat_tabs[2]:
        st.markdown("#### ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ø´Ø±ÙŠØ­Ø©")
        
        slice_stats_data = []
        for slice_key, slice_data in service_stats["by_slice"].items():
            completion_rate_slice = (slice_data["total_done"] / slice_data["total_needed"] * 100) if slice_data["total_needed"] > 0 else 0
            
            slice_stats_data.append({
                "Ø§Ù„Ø´Ø±ÙŠØ­Ø©": slice_key,
                "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©": slice_data["total_needed"],
                "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ù†ÙØ°Ø©": slice_data["total_done"],
                "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©": slice_data["total_needed"] - slice_data["total_done"],
                "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²": f"{completion_rate_slice:.1f}%",
                "Ø­Ø§Ù„Ø© Ø§Ù„Ø´Ø±ÙŠØ­Ø©": "âœ… Ù…Ù…ØªØ§Ø²Ø©" if completion_rate_slice >= 90 else 
                               "ğŸŸ¢ Ø¬ÙŠØ¯Ø©" if completion_rate_slice >= 70 else 
                               "ğŸŸ¡ Ù…ØªÙˆØ³Ø·Ø©" if completion_rate_slice >= 50 else 
                               "ğŸ”´ Ø¶Ø¹ÙŠÙØ©"
            })
        
        if slice_stats_data:
            slice_stats_df = pd.DataFrame(slice_stats_data)
            st.dataframe(slice_stats_df, use_container_width=True, height=400)
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… plotly Ù„Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©
            try:
                import plotly.graph_objects as go
                
                # ØªØ­Ù„ÙŠÙ„ Ù†Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ø´Ø±Ø§Ø¦Ø­
                slice_ranges = []
                completion_rates = []
                
                for slice_item in slice_stats_data:
                    slice_key = slice_item["Ø§Ù„Ø´Ø±ÙŠØ­Ø©"]
                    slice_range = slice_key.split("-")
                    if len(slice_range) == 2:
                        try:
                            mid_point = (int(slice_range[0]) + int(slice_range[1])) / 2
                            slice_ranges.append(mid_point)
                            
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Ø³Ø¨Ø© Ù…Ù† Ø§Ù„Ù†Øµ
                            rate_text = slice_item["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"]
                            rate_value = float(rate_text.replace("%", "").strip())
                            completion_rates.append(rate_value)
                        except:
                            continue
                
                if slice_ranges and completion_rates:
                    fig3 = go.Figure()
                    fig3.add_trace(go.Scatter(
                        x=slice_ranges,
                        y=completion_rates,
                        mode='lines+markers',
                        name='Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²',
                        line=dict(color='#4ECDC4', width=3),
                        marker=dict(size=10, color='#FF6B6B')
                    ))
                    
                    fig3.update_layout(
                        title="Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² Ø­Ø³Ø¨ Ù†Ø·Ø§Ù‚ Ø§Ù„Ø£Ø·Ù†Ø§Ù†",
                        xaxis_title="Ù†Ø·Ø§Ù‚ Ø§Ù„Ø£Ø·Ù†Ø§Ù† (Ù…Ù†ØªØµÙ Ø§Ù„Ø´Ø±ÙŠØ­Ø©)",
                        yaxis_title="Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø² (%)",
                        height=400,
                        showlegend=True
                    )
                    
                    st.plotly_chart(fig3, use_container_width=True)
                    
            except ImportError:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… streamlit line chart Ø¨Ø¯ÙŠÙ„
                if slice_stats_data:
                    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
                    chart_data = []
                    for slice_item in slice_stats_data:
                        slice_key = slice_item["Ø§Ù„Ø´Ø±ÙŠØ­Ø©"]
                        slice_range = slice_key.split("-")
                        if len(slice_range) == 2:
                            try:
                                mid_point = (int(slice_range[0]) + int(slice_range[1])) / 2
                                rate_text = slice_item["Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"]
                                rate_value = float(rate_text.replace("%", "").strip())
                                
                                chart_data.append({
                                    "Ù†Ø·Ø§Ù‚ Ø§Ù„Ø£Ø·Ù†Ø§Ù†": mid_point,
                                    "Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²": rate_value
                                })
                            except:
                                continue
                    
                    if chart_data:
                        chart_df = pd.DataFrame(chart_data).sort_values("Ù†Ø·Ø§Ù‚ Ø§Ù„Ø£Ø·Ù†Ø§Ù†")
                        st.line_chart(chart_df.set_index("Ù†Ø·Ø§Ù‚ Ø§Ù„Ø£Ø·Ù†Ø§Ù†"), height=400)
        else:
            st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ù„Ù„Ø´Ø±Ø§Ø¦Ø­.")

# -------------------------------
# ğŸ–¥ Ø¯Ø§Ù„Ø© ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù† - ÙˆØ§Ø¬Ù‡Ø© Ù…Ø¨Ø³Ø·Ø© ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ©
# -------------------------------
def check_events_and_corrections(all_sheets):
    """ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù† Ø¨ÙˆØ§Ø¬Ù‡Ø© Ù…Ø¨Ø³Ø·Ø© ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ©"""
    if not all_sheets:
        st.error("âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ø´ÙŠØªØ§Øª.")
        return
    
    # ØªÙ‡ÙŠØ¦Ø© session state Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
    if "search_params" not in st.session_state:
        st.session_state.search_params = {
            "card_numbers": "",
            "date_range": "",
            "tech_names": "",
            "search_text": "",
            "exact_match": False,
            "include_empty": True,
            "sort_by": "Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©"
        }
    
    if "search_triggered" not in st.session_state:
        st.session_state.search_triggered = False
    
    # Ù‚Ø³Ù… Ø§Ù„Ø¨Ø­Ø« - ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©
    with st.container():
        st.markdown("### ğŸ” Ø¨Ø­Ø« Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±")
        st.markdown("Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ø¯Ø¯. ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ù„Ø¡ ÙˆØ§Ø­Ø¯ Ø£Ùˆ Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„.")
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø´Ø§Ø´Ø© Ø¥Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø©
        col1, col2 = st.columns([1, 1])
        
        with col1:
            # Ù‚Ø³Ù… Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª
            with st.expander("ğŸ”¢ **Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª**", expanded=True):
                st.caption("Ø£Ø¯Ø®Ù„ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª (Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„ Ø£Ùˆ Ù†Ø·Ø§Ù‚Ø§Øª)")
                card_numbers = st.text_input(
                    "Ù…Ø«Ø§Ù„: 1,3,5 Ø£Ùˆ 1-5 Ø£Ùˆ 2,4,7-10",
                    value=st.session_state.search_params.get("card_numbers", ""),
                    key="input_cards",
                    placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª"
                )
                
                # Ø£Ø²Ø±Ø§Ø± Ø³Ø±ÙŠØ¹Ø© Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª
                st.caption("Ø£Ùˆ Ø§Ø®ØªØ± Ù…Ù†:")
                quick_cards_col1, quick_cards_col2, quick_cards_col3 = st.columns(3)
                with quick_cards_col1:
                    if st.button("ğŸ”Ÿ Ø£ÙˆÙ„ 10 Ù…Ø§ÙƒÙŠÙ†Ø§Øª", key="quick_10"):
                        st.session_state.search_params["card_numbers"] = "1-10"
                        st.session_state.search_triggered = True
                        st.rerun()
                with quick_cards_col2:
                    if st.button("ğŸ”Ÿ Ù…Ø§ÙƒÙŠÙ†Ø§Øª 11-20", key="quick_20"):
                        st.session_state.search_params["card_numbers"] = "11-20"
                        st.session_state.search_triggered = True
                        st.rerun()
                with quick_cards_col3:
                    if st.button("ğŸ—‘ Ù…Ø³Ø­", key="clear_cards"):
                        st.session_state.search_params["card_numbers"] = ""
                        st.rerun()
            
            # Ù‚Ø³Ù… Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
            with st.expander("ğŸ“… **Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®**", expanded=True):
                st.caption("Ø§Ø¨Ø­Ø« Ø¨Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø³Ù†Ø©ØŒ Ø´Ù‡Ø±/Ø³Ù†Ø©)")
                date_input = st.text_input(
                    "Ù…Ø«Ø§Ù„: 2024 Ø£Ùˆ 1/2024 Ø£Ùˆ 2024,2025",
                    value=st.session_state.search_params.get("date_range", ""),
                    key="input_date",
                    placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®"
                )
        
        with col2:
            # Ù‚Ø³Ù… ÙÙ†ÙŠÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©
            with st.expander("ğŸ‘¨â€ğŸ”§ **ÙÙ†ÙŠÙˆ Ø§Ù„Ø®Ø¯Ù…Ø©**", expanded=True):
                st.caption("Ø§Ø¨Ø­Ø« Ø¨Ø£Ø³Ù…Ø§Ø¡ ÙÙ†ÙŠÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©")
                tech_names = st.text_input(
                    "Ù…Ø«Ø§Ù„: Ø£Ø­Ù…Ø¯, Ù…Ø­Ù…Ø¯, Ø¹Ù„ÙŠ",
                    value=st.session_state.search_params.get("tech_names", ""),
                    key="input_techs",
                    placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„ÙÙ†ÙŠÙŠÙ†"
                )
            
            # Ù‚Ø³Ù… Ù†Øµ Ø§Ù„Ø¨Ø­Ø«
            with st.expander("ğŸ“ **Ù†Øµ Ø§Ù„Ø¨Ø­Ø«**", expanded=True):
                st.caption("Ø§Ø¨Ø­Ø« ÙÙŠ ÙˆØµÙ Ø§Ù„Ø­Ø¯Ø« Ø£Ùˆ Ø§Ù„ØªØµØ­ÙŠØ­")
                search_text = st.text_input(
                    "Ù…Ø«Ø§Ù„: ØµÙŠØ§Ù†Ø©, Ø¥ØµÙ„Ø§Ø­, ØªØºÙŠÙŠØ±",
                    value=st.session_state.search_params.get("search_text", ""),
                    key="input_text",
                    placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ"
                )
        
        # Ù‚Ø³Ù… Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        with st.expander("âš™ **Ø®ÙŠØ§Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©**", expanded=False):
            col_adv1, col_adv2, col_adv3 = st.columns(3)
            with col_adv1:
                search_mode = st.radio(
                    "ğŸ” Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¨Ø­Ø«:",
                    ["Ø¨Ø­Ø« Ø¬Ø²Ø¦ÙŠ", "Ù…Ø·Ø§Ø¨Ù‚Ø© ÙƒØ§Ù…Ù„Ø©"],
                    index=0 if not st.session_state.search_params.get("exact_match") else 1,
                    key="radio_search_mode",
                    help="Ø¨Ø­Ø« Ø¬Ø²Ø¦ÙŠ: ÙŠØ¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Øµ ÙÙŠ Ø£ÙŠ Ù…ÙƒØ§Ù†. Ù…Ø·Ø§Ø¨Ù‚Ø© ÙƒØ§Ù…Ù„Ø©: ÙŠØ¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Øµ Ù…Ø·Ø§Ø¨Ù‚ ØªÙ…Ø§Ù…Ø§Ù‹"
                )
            with col_adv2:
                include_empty = st.checkbox(
                    "ğŸ” ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ÙØ§Ø±ØºØ©",
                    value=st.session_state.search_params.get("include_empty", True),
                    key="checkbox_include_empty",
                    help="ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø­Ù‚ÙˆÙ„ ÙØ§Ø±ØºØ©"
                )
            with col_adv3:
                sort_by = st.selectbox(
                    "ğŸ“Š ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:",
                    ["Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©"],
                    index=["Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©"].index(
                        st.session_state.search_params.get("sort_by", "Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©")
                    ),
                    key="select_sort_by"
                )
        
        # Ø²Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
        st.markdown("---")
        col_btn1, col_btn2, col_btn3 = st.columns([2, 1, 1])
        with col_btn1:
            search_clicked = st.button(
                "ğŸ” **Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø­Ø«**",
                type="primary",
                use_container_width=True,
                key="main_search_btn"
            )
        with col_btn2:
            if st.button("ğŸ—‘ **Ù…Ø³Ø­ Ø§Ù„Ø­Ù‚ÙˆÙ„**", use_container_width=True, key="clear_fields"):
                st.session_state.search_params = {
                    "card_numbers": "",
                    "date_range": "",
                    "tech_names": "",
                    "search_text": "",
                    "exact_match": False,
                    "include_empty": True,
                    "sort_by": "Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©"
                }
                st.session_state.search_triggered = False
                st.rerun()
        with col_btn3:
            if st.button("ğŸ“Š **Ø¹Ø±Ø¶ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**", use_container_width=True, key="show_all"):
                st.session_state.search_params = {
                    "card_numbers": "",
                    "date_range": "",
                    "tech_names": "",
                    "search_text": "",
                    "exact_match": False,
                    "include_empty": True,
                    "sort_by": "Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©"
                }
                st.session_state.search_triggered = True
                st.rerun()
    
    # ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†Ø¯ ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ù‚ÙˆÙ„
    if card_numbers != st.session_state.search_params.get("card_numbers", ""):
        st.session_state.search_params["card_numbers"] = card_numbers
    
    if date_input != st.session_state.search_params.get("date_range", ""):
        st.session_state.search_params["date_range"] = date_input
    
    if tech_names != st.session_state.search_params.get("tech_names", ""):
        st.session_state.search_params["tech_names"] = tech_names
    
    if search_text != st.session_state.search_params.get("search_text", ""):
        st.session_state.search_params["search_text"] = search_text
    
    st.session_state.search_params["exact_match"] = (search_mode == "Ù…Ø·Ø§Ø¨Ù‚Ø© ÙƒØ§Ù…Ù„Ø©")
    st.session_state.search_params["include_empty"] = include_empty
    st.session_state.search_params["sort_by"] = sort_by
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨Ø­Ø«
    if search_clicked or st.session_state.search_triggered:
        st.session_state.search_triggered = True
        
        # Ø¬Ù…Ø¹ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«
        search_params = st.session_state.search_params.copy()
        
        # Ø¹Ø±Ø¶ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«
        show_search_params(search_params)
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø­Ø«
        show_advanced_search_results(search_params, all_sheets)

def extract_available_techs(all_sheets):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ù…Ø§Ø¡ ÙÙ†ÙŠÙŠ Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    techs_set = set()
    
    for sheet_name, df in all_sheets.items():
        if sheet_name == "ServicePlan":
            continue
            
        for _, row in df.iterrows():
            tech = get_servised_by_value(row)
            if tech != "-":
                techs_set.add(tech)
    
    return sorted(list(techs_set))

def show_search_params(search_params):
    """Ø¹Ø±Ø¶ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©"""
    with st.container():
        st.markdown("### âš™ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©")
        
        params_display = []
        if search_params["card_numbers"]:
            params_display.append(f"**ğŸ”¢ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª:** {search_params['card_numbers']}")
        if search_params["date_range"]:
            params_display.append(f"**ğŸ“… Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®:** {search_params['date_range']}")
        if search_params["tech_names"]:
            params_display.append(f"**ğŸ‘¨â€ğŸ”§ ÙÙ†ÙŠÙˆ Ø§Ù„Ø®Ø¯Ù…Ø©:** {search_params['tech_names']}")
        if search_params["search_text"]:
            params_display.append(f"**ğŸ“ Ù†Øµ Ø§Ù„Ø¨Ø­Ø«:** {search_params['search_text']}")
        
        if params_display:
            st.info(" | ".join(params_display))
        else:
            st.info("ğŸ” **Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**")

def parse_card_numbers(card_numbers_str):
    """ØªØ­Ù„ÙŠÙ„ Ø³Ù„Ø³Ù„Ø© Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø£Ø±Ù‚Ø§Ù…"""
    if not card_numbers_str:
        return set()
    
    numbers = set()
    
    try:
        parts = card_numbers_str.split(',')
        for part in parts:
            part = part.strip()
            if '-' in part:
                try:
                    start_str, end_str = part.split('-')
                    start = int(start_str.strip())
                    end = int(end_str.strip())
                    numbers.update(range(start, end + 1))
                except:
                    continue
            else:
                try:
                    num = int(part)
                    numbers.add(num)
                except:
                    continue
    except:
        return set()
    
    return numbers

def extract_event_correction(row, df):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ø¯Ø« ÙˆØ§Ù„ØªØµØ­ÙŠØ­ Ù…Ù† Ø§Ù„ØµÙ"""
    event_value = "-"
    correction_value = "-"
    
    for col in df.columns:
        col_normalized = normalize_name(col)
        if "event" in col_normalized or "Ø§Ù„Ø­Ø¯Ø«" in col_normalized:
            if col in row and pd.notna(row[col]) and str(row[col]).strip() != "":
                event_value = str(row[col]).strip()
        
        if "correction" in col_normalized or "ØªØµØ­ÙŠØ­" in col_normalized:
            if col in row and pd.notna(row[col]) and str(row[col]).strip() != "":
                correction_value = str(row[col]).strip()
    
    return event_value, correction_value

def extract_row_data(row, df, card_num):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙ Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ®"""
    card_num_value = str(row.get("card", "")).strip() if pd.notna(row.get("card")) else str(card_num)
    date_str = str(row.get("Date", "")).strip() if pd.notna(row.get("Date")) else "-"
    tones = str(row.get("Tones", "")).strip() if pd.notna(row.get("Tones")) else "-"
    
    event_value, correction_value = extract_event_correction(row, df)
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙƒÙ„ Ø§Ù„Ø­Ù‚ÙˆÙ„ ÙØ§Ø±ØºØ©ØŒ Ù†ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØµÙ
    if (event_value == "-" and correction_value == "-" and 
        date_str == "-" and tones == "-"):
        return None
    
    servised_by_value = get_servised_by_value(row)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ ÙƒØ§Ø¦Ù† datetime (Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†)
    date_parsed = None
    if date_str != "-":
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨Ø£Ø´ÙƒØ§Ù„ Ù…Ø®ØªÙ„ÙØ©
        date_formats = [
            '%d/%m/%Y', '%d-%m-%Y', '%d.%m.%Y',
            '%m/%d/%Y', '%m-%d-%Y', '%m.%d.%Y',
            '%Y/%m/%d', '%Y-%m-%d', '%Y.%m.%d'
        ]
        
        for fmt in date_formats:
            try:
                date_parsed = datetime.strptime(date_str, fmt)
                break
            except ValueError:
                continue
        
        # Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§ØªØŒ ØªØ­Ø§ÙˆÙ„ pandas
        if date_parsed is None:
            try:
                date_parsed = pd.to_datetime(date_str, dayfirst=True, errors='coerce')
                if pd.isna(date_parsed):
                    date_parsed = None
            except:
                date_parsed = None
    
    return {
        "Card Number": card_num_value,
        "Event": event_value,
        "Correction": correction_value,
        "Servised by": servised_by_value,
        "Tones": tones,
        "Date": date_str,
        "Date_parsed": date_parsed
    }

def format_time_interval(days):
    """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø¨Ø´ÙƒÙ„ Ù…Ù‚Ø±ÙˆØ¡"""
    if days < 1:
        return "Ø£Ù‚Ù„ Ù…Ù† ÙŠÙˆÙ…"
    elif days < 7:
        return f"{days} ÙŠÙˆÙ…"
    elif days < 30:
        weeks = days // 7
        remaining_days = days % 7
        if remaining_days > 0:
            return f"{weeks} Ø£Ø³Ø¨ÙˆØ¹ Ùˆ {remaining_days} ÙŠÙˆÙ…"
        return f"{weeks} Ø£Ø³Ø¨ÙˆØ¹"
    elif days < 365:
        months = days // 30
        remaining_days = days % 30
        if remaining_days > 0:
            return f"{months} Ø´Ù‡Ø± Ùˆ {remaining_days} ÙŠÙˆÙ…"
        return f"{months} Ø´Ù‡Ø±"
    else:
        years = days // 365
        remaining_days = days % 365
        if remaining_days > 0:
            months = remaining_days // 30
            return f"{years} Ø³Ù†Ø© Ùˆ {months} Ø´Ù‡Ø±"
        return f"{years} Ø³Ù†Ø©"

def analyze_time_intervals(events_data):
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«"""
    analysis = {
        "time_intervals": [],
        "stats": {
            "avg_interval_days": None,
            "min_interval_days": None,
            "max_interval_days": None,
            "total_events": 0,
            "covered_period_days": None
        },
        "by_technician": {},
        "recent_activity": []
    }
    
    if not events_data:
        return analysis
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ®
    events_sorted = sorted(
        [e for e in events_data if e.get("Date_parsed")], 
        key=lambda x: x["Date_parsed"]
    )
    
    analysis["stats"]["total_events"] = len(events_sorted)
    
    if len(events_sorted) < 2:
        return analysis
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
    intervals = []
    for i in range(1, len(events_sorted)):
        prev_date = events_sorted[i-1]["Date_parsed"]
        curr_date = events_sorted[i]["Date_parsed"]
        
        if prev_date and curr_date:
            delta = curr_date - prev_date
            days = delta.days
            
            intervals.append({
                "from_event": events_sorted[i-1].get("Event", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"),
                "to_event": events_sorted[i].get("Event", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"),
                "from_date": prev_date,
                "to_date": curr_date,
                "days": days,
                "formatted": format_time_interval(days)
            })
    
    analysis["time_intervals"] = intervals
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    if intervals:
        days_list = [interval["days"] for interval in intervals]
        analysis["stats"]["avg_interval_days"] = sum(days_list) / len(days_list)
        analysis["stats"]["min_interval_days"] = min(days_list)
        analysis["stats"]["max_interval_days"] = max(days_list)
        
        # Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„ÙƒÙ„ÙŠØ©
        first_date = events_sorted[0]["Date_parsed"]
        last_date = events_sorted[-1]["Date_parsed"]
        total_days = (last_date - first_date).days
        analysis["stats"]["covered_period_days"] = total_days
    
    # ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©
    technician_events = {}
    for event in events_sorted:
        tech = event.get("Servised by", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
        if tech not in technician_events:
            technician_events[tech] = []
        technician_events[tech].append(event)
    
    for tech, tech_events in technician_events.items():
        if len(tech_events) > 1:
            tech_events_sorted = sorted(tech_events, key=lambda x: x["Date_parsed"])
            tech_intervals = []
            
            for i in range(1, len(tech_events_sorted)):
                delta = tech_events_sorted[i]["Date_parsed"] - tech_events_sorted[i-1]["Date_parsed"]
                tech_intervals.append(delta.days)
            
            analysis["by_technician"][tech] = {
                "event_count": len(tech_events),
                "avg_interval": sum(tech_intervals) / len(tech_intervals) if tech_intervals else None,
                "intervals": tech_intervals
            }
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø£Ø®ÙŠØ±
    recent_limit = min(5, len(events_sorted))
    for i in range(recent_limit):
        event = events_sorted[-(i+1)]
        days_ago = (datetime.now() - event["Date_parsed"]).days
        analysis["recent_activity"].append({
            "event": event.get("Event", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"),
            "date": event["Date_parsed"],
            "days_ago": days_ago,
            "technician": event.get("Servised by", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
        })
    
    return analysis

def check_row_criteria(row, df, card_num, target_techs, target_dates, 
                      search_terms, search_params):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØµÙ Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«"""
    
    # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©
    if target_techs:
        row_tech = get_servised_by_value(row).lower()
        if row_tech == "-" and not search_params["include_empty"]:
            return False
        
        tech_match = False
        if row_tech != "-":
            for tech in target_techs:
                if search_params["exact_match"]:
                    if tech == row_tech:
                        tech_match = True
                        break
                else:
                    if tech in row_tech:
                        tech_match = True
                        break
        
        if not tech_match:
            return False
    
    # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ§Ø±ÙŠØ®
    if target_dates:
        row_date = str(row.get("Date", "")).strip().lower() if pd.notna(row.get("Date")) else ""
        if not row_date and not search_params["include_empty"]:
            return False
        
        date_match = False
        if row_date:
            for date_term in target_dates:
                if search_params["exact_match"]:
                    if date_term == row_date:
                        date_match = True
                        break
                else:
                    if date_term in row_date:
                        date_match = True
                        break
        
        if not date_match:
            return False
    
    # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Øµ Ø§Ù„Ø¨Ø­Ø«
    if search_terms:
        row_event, row_correction = extract_event_correction(row, df)
        row_event_lower = row_event.lower()
        row_correction_lower = row_correction.lower()
        
        if not row_event and not row_correction and not search_params["include_empty"]:
            return False
        
        text_match = False
        combined_text = f"{row_event_lower} {row_correction_lower}"
        
        for term in search_terms:
            if search_params["exact_match"]:
                if term == row_event_lower or term == row_correction_lower:
                    text_match = True
                    break
            else:
                if term in combined_text:
                    text_match = True
                    break
        
        if not text_match:
            return False
    
    return True

def show_advanced_search_results(search_params, all_sheets):
    """Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ"""
    st.markdown("### ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«")
    
    # Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    all_results = []
    total_machines = 0
    processed_machines = 0
    
    # Ø­Ø³Ø§Ø¨ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª
    for sheet_name in all_sheets.keys():
        if sheet_name != "ServicePlan" and sheet_name.startswith("Card"):
            total_machines += 1
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    target_card_numbers = parse_card_numbers(search_params["card_numbers"])
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠÙŠÙ†
    target_techs = []
    if search_params["tech_names"]:
        techs = search_params["tech_names"].split(',')
        target_techs = [tech.strip().lower() for tech in techs if tech.strip()]
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
    target_dates = []
    if search_params["date_range"]:
        dates = search_params["date_range"].split(',')
        target_dates = [date.strip().lower() for date in dates if date.strip()]
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†Øµ Ø§Ù„Ø¨Ø­Ø«
    search_terms = []
    if search_params["search_text"]:
        terms = search_params["search_text"].split(',')
        search_terms = [term.strip().lower() for term in terms if term.strip()]
    
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª
    for sheet_name in all_sheets.keys():
        if sheet_name == "ServicePlan":
            continue
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©
        card_num_match = re.search(r'Card(\d+)', sheet_name)
        if not card_num_match:
            continue
            
        card_num = int(card_num_match.group(1))
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØ­Ø¯ÙŠØ¯
        if target_card_numbers and card_num not in target_card_numbers:
            continue
        
        processed_machines += 1
        if total_machines > 0:
            progress_bar.progress(processed_machines / total_machines)
        status_text.text(f"ğŸ” Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø© {card_num}...")
        
        df = all_sheets[sheet_name].copy()
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØµÙÙˆÙ
        for _, row in df.iterrows():
            # ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«
            if not check_row_criteria(row, df, card_num, target_techs, target_dates, 
                                     search_terms, search_params):
                continue
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            result = extract_row_data(row, df, card_num)
            if result:
                all_results.append(result)
    
    # Ø¥Ø®ÙØ§Ø¡ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
    progress_bar.empty()
    status_text.empty()
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    if all_results:
        display_search_results(all_results, search_params)
    else:
        st.warning("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ ØªØ·Ø§Ø¨Ù‚ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«")
        st.info("ğŸ’¡ Ø­Ø§ÙˆÙ„ ØªØ¹Ø¯ÙŠÙ„ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø« Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØµØ·Ù„Ø­Ø§Øª Ø£ÙˆØ³Ø¹")

def display_search_results(results, search_params):
    """Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø¨Ø´ÙƒÙ„ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…Ø¹ ØªØ±ØªÙŠØ¨ Ù…ØªØ³Ù„Ø³Ù„ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ"""
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ DataFrame
    if not results:
        st.warning("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ø¹Ø±Ø¶Ù‡Ø§")
        return
    
    result_df = pd.DataFrame(results)
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if result_df.empty:
        st.warning("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¹Ø±Ø¶Ù‡Ø§")
        return
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ù„Ù„Ø¹Ø±Ø¶ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ±ØªÙŠØ¨
    display_df = result_df.copy()
    
    # ØªØ­ÙˆÙŠÙ„ Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø© Ø¥Ù„Ù‰ Ø±Ù‚Ù… ØµØ­ÙŠØ­ Ù„Ù„ØªØ±ØªÙŠØ¨ (Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†)
    display_df['Card_Number_Clean'] = pd.to_numeric(display_df['Card Number'], errors='coerce')
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ù„ØªØ±ØªÙŠØ¨ Ø²Ù…Ù†ÙŠ (Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†)
    display_df['Date_Clean'] = pd.to_datetime(display_df['Date'], errors='coerce', dayfirst=True)
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø© Ø«Ù… Ø§Ù„ØªØ§Ø±ÙŠØ®
    if search_params["sort_by"] == "Ø§Ù„ØªØ§Ø±ÙŠØ®":
        display_df = display_df.sort_values(by=['Date_Clean', 'Card_Number_Clean'], 
                                          ascending=[False, True], na_position='last')
    elif search_params["sort_by"] == "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©":
        display_df = display_df.sort_values(by=['Servised by', 'Card_Number_Clean', 'Date_Clean'], 
                                          ascending=[True, True, False], na_position='last')
    else:  # Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø© (Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ)
        display_df = display_df.sort_values(by=['Card_Number_Clean', 'Date_Clean'], 
                                          ascending=[True, False], na_position='last')
    
    # Ø¥Ø¶Ø§ÙØ© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù„ÙƒÙ„ Ù…Ø§ÙƒÙŠÙ†Ø©
    display_df['Event_Order'] = display_df.groupby('Card Number').cumcount() + 1
    display_df['Total_Events'] = display_df.groupby('Card Number')['Card Number'].transform('count')
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    st.markdown("### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“‹ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", len(display_df))
    
    with col2:
        unique_machines = display_df["Card Number"].nunique()
        st.metric("ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª", unique_machines)
    
    with col3:
        # Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ø§Ù„ØªÙŠ Ù„Ø¯ÙŠÙ‡Ø§ Ø£ÙƒØ«Ø± Ù…Ù† Ø­Ø¯Ø«
        if not display_df.empty:
            machine_counts = display_df.groupby('Card Number').size()
            multi_event_machines = (machine_counts > 1).sum()
            st.metric("ğŸ”¢ Ù…ÙƒÙ† Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", multi_event_machines)
        else:
            st.metric("ğŸ”¢ Ù…ÙƒÙ† Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", 0)
    
    with col4:
        if 'Correction' in display_df.columns:
            with_correction = display_df[display_df["Correction"] != "-"].shape[0]
            st.metric("âœ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªØµØ­ÙŠØ­", with_correction)
        else:
            st.metric("âœ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªØµØ­ÙŠØ­", 0)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø´ÙƒÙ„ Ù…ØªØ³Ù„Ø³Ù„
    st.markdown("### ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© (Ù…Ø±ØªØ¨Ø©)")
    
    # ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø§Ù„Ø¹Ø±Ø¶
    display_tabs = st.tabs(["ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", "ğŸ“‹ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©", "â± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ", "ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø²Ù…Ù†ÙŠØ©"])
    
    with display_tabs[0]:
        # Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ÙŠ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ
        # ÙÙ„ØªØ±Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        st.markdown("#### ğŸ” ÙÙ„ØªØ±Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
        filter_col1, filter_col2, filter_col3 = st.columns(3)
        
        with filter_col1:
            show_with_event = st.checkbox("ğŸ“ Ù…Ø¹ Ø­Ø¯Ø«", True, key="filter_event_1")
        with filter_col2:
            show_with_correction = st.checkbox("âœ Ù…Ø¹ ØªØµØ­ÙŠØ­", True, key="filter_correction_1")
        with filter_col3:
            show_with_tech = st.checkbox("ğŸ‘¨â€ğŸ”§ Ù…Ø¹ ÙÙ†ÙŠ Ø®Ø¯Ù…Ø©", True, key="filter_tech_1")
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ±
        filtered_df = display_df.copy()
        
        if not show_with_event and 'Event' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df["Event"] != "-"]
        if not show_with_correction and 'Correction' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df["Correction"] != "-"]
        if not show_with_tech and 'Servised by' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df["Servised by"] != "-"]
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ Ø¹Ø±Ø¶Ù‡Ø§
        columns_to_show = ['Card Number', 'Event', 'Correction', 'Servised by', 'Tones', 'Date', 'Event_Order', 'Total_Events']
        columns_to_show = [col for col in columns_to_show if col in filtered_df.columns]
        
        if not filtered_df.empty:
            st.dataframe(
                filtered_df[columns_to_show].style.apply(style_table, axis=1),
                use_container_width=True,
                height=500
            )
        else:
            st.warning("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ ØªØ·Ø§Ø¨Ù‚ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ÙÙ„ØªØ±Ø©")
    
    with display_tabs[1]:
        # Ø¹Ø±Ø¶ ØªÙØµÙŠÙ„ÙŠ Ù„ÙƒÙ„ Ù…Ø§ÙƒÙŠÙ†Ø© Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©
        unique_machines = sorted(filtered_df['Card Number'].unique(), 
                               key=lambda x: pd.to_numeric(x, errors='coerce') if str(x).isdigit() else float('inf'))
        
        for machine in unique_machines:
            machine_data = filtered_df[filtered_df['Card Number'] == machine].copy()
            machine_data = machine_data.sort_values('Event_Order')
            
            with st.expander(f"ğŸ”§ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø© {machine} - Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«: {len(machine_data)}", expanded=len(unique_machines) <= 5):
                
                # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©
                col_stats1, col_stats2, col_stats3 = st.columns(3)
                with col_stats1:
                    if not machine_data.empty and 'Date' in machine_data.columns:
                        st.metric("ğŸ“… Ø£ÙˆÙ„ Ø­Ø¯Ø«", machine_data['Date'].iloc[0] if machine_data['Date'].iloc[0] != "-" else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
                    else:
                        st.metric("ğŸ“… Ø£ÙˆÙ„ Ø­Ø¯Ø«", "-")
                with col_stats2:
                    if not machine_data.empty and 'Date' in machine_data.columns:
                        st.metric("ğŸ“… Ø¢Ø®Ø± Ø­Ø¯Ø«", machine_data['Date'].iloc[-1] if machine_data['Date'].iloc[-1] != "-" else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
                    else:
                        st.metric("ğŸ“… Ø¢Ø®Ø± Ø­Ø¯Ø«", "-")
                with col_stats3:
                    if not machine_data.empty and 'Servised by' in machine_data.columns:
                        tech_count = machine_data['Servised by'].nunique()
                        st.metric("ğŸ‘¨â€ğŸ”§ ÙÙ†ÙŠÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ†", tech_count)
                    else:
                        st.metric("ğŸ‘¨â€ğŸ”§ ÙÙ†ÙŠÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ†", 0)
                
                # Ø¹Ø±Ø¶ Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©
                for idx, row in machine_data.iterrows():
                    st.markdown("---")
                    col_event1, col_event2 = st.columns([3, 2])
                    
                    with col_event1:
                        event_order = row.get('Event_Order', '?')
                        total_events = row.get('Total_Events', '?')
                        st.markdown(f"**Ø§Ù„Ø­Ø¯Ø« #{event_order} Ù…Ù† {total_events}**")
                        if 'Date' in row:
                            st.markdown(f"**ğŸ“… Ø§Ù„ØªØ§Ø±ÙŠØ®:** {row['Date']}")
                        if 'Event' in row and row['Event'] != '-':
                            st.markdown(f"**ğŸ“ Ø§Ù„Ø­Ø¯Ø«:** {row['Event']}")
                        if 'Correction' in row and row['Correction'] != '-':
                            st.markdown(f"**âœ Ø§Ù„ØªØµØ­ÙŠØ­:** {row['Correction']}")
                    
                    with col_event2:
                        if 'Servised by' in row and row['Servised by'] != '-':
                            st.markdown(f"**ğŸ‘¨â€ğŸ”§ ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©:** {row['Servised by']}")
                        if 'Tones' in row and row['Tones'] != '-':
                            st.markdown(f"**âš–ï¸ Ø§Ù„Ø£Ø·Ù†Ø§Ù†:** {row['Tones']}")
    
    with display_tabs[2]:
        # ØªØ­Ù„ÙŠÙ„ Ø²Ù…Ù†ÙŠ Ø´Ø§Ù…Ù„ Ù„ÙƒÙ„ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª
        st.markdown("### â± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„")
        
        # Ø¬Ù…Ø¹ Ø£Ø­Ø¯Ø§Ø« Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
        all_machine_events = []
        unique_machines = sorted(filtered_df['Card Number'].unique(), 
                               key=lambda x: pd.to_numeric(x, errors='coerce') if str(x).isdigit() else float('inf'))
        
        for machine in unique_machines:
            machine_data = filtered_df[filtered_df['Card Number'] == machine].copy()
            for _, row in machine_data.iterrows():
                event_data = {
                    "Card Number": machine,
                    "Event": row.get("Event", "-"),
                    "Date": row.get("Date", "-"),
                    "Date_parsed": row.get("Date_parsed"),
                    "Servised by": row.get("Servised by", "-"),
                    "Tones": row.get("Tones", "-")
                }
                if event_data["Date_parsed"]:
                    all_machine_events.append(event_data)
        
        if len(all_machine_events) < 2:
            st.info("â„¹ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø§ ÙŠÙƒÙÙŠ Ù…Ù† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ (ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø­Ø¯Ø«ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„).")
        else:
            # ØªØ­Ù„ÙŠÙ„ Ø²Ù…Ù†ÙŠ Ø´Ø§Ù…Ù„
            time_analysis_all = analyze_time_intervals(all_machine_events)
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ğŸ”¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", time_analysis_all["stats"]["total_events"])
            
            with col2:
                if time_analysis_all["stats"]["avg_interval_days"]:
                    st.metric("â± Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø©", 
                             f"{time_analysis_all['stats']['avg_interval_days']:.1f} ÙŠÙˆÙ…")
                else:
                    st.metric("â± Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø©", "-")
            
            with col3:
                if time_analysis_all["stats"]["min_interval_days"]:
                    st.metric("â± Ø£Ù‚ØµØ± Ù…Ø¯Ø©", 
                             f"{time_analysis_all['stats']['min_interval_days']} ÙŠÙˆÙ…")
                else:
                    st.metric("â± Ø£Ù‚ØµØ± Ù…Ø¯Ø©", "-")
            
            with col4:
                if time_analysis_all["stats"]["max_interval_days"]:
                    st.metric("â± Ø£Ø·ÙˆÙ„ Ù…Ø¯Ø©", 
                             f"{time_analysis_all['stats']['max_interval_days']} ÙŠÙˆÙ…")
                else:
                    st.metric("â± Ø£Ø·ÙˆÙ„ Ù…Ø¯Ø©", "-")
            
            # ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©
            st.markdown("#### ğŸ‘¨â€ğŸ”§ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©")
            
            if time_analysis_all["by_technician"]:
                tech_data = []
                for tech, stats in time_analysis_all["by_technician"].items():
                    tech_data.append({
                        "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©": tech,
                        "Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«": stats["event_count"],
                        "Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© (ÙŠÙˆÙ…)": f"{stats['avg_interval']:.1f}" if stats["avg_interval"] else "-",
                        "Ù†Ø´Ø§Ø·": "Ù†Ø´Ø·" if stats["event_count"] > 1 else "Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©"
                    })
                
                tech_df = pd.DataFrame(tech_data)
                st.dataframe(tech_df, use_container_width=True)
            
            # Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø£Ø®ÙŠØ±
            st.markdown("#### ğŸ“… Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø£Ø®ÙŠØ±")
            
            recent_activity = []
            for activity in time_analysis_all["recent_activity"][:5]:  # Ø£ÙˆÙ„ 5 Ø£Ø­Ø¯Ø§Ø«
                recent_activity.append({
                    "Ø§Ù„Ø­Ø¯Ø«": activity["event"][:50] + "..." if len(activity["event"]) > 50 else activity["event"],
                    "Ø§Ù„ØªØ§Ø±ÙŠØ®": activity["date"].strftime("%Y-%m-%d") if activity["date"] else "-",
                    "Ù‚Ø¨Ù„ (ÙŠÙˆÙ…)": activity["days_ago"],
                    "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©": activity["technician"]
                })
            
            if recent_activity:
                recent_df = pd.DataFrame(recent_activity)
                st.dataframe(recent_df, use_container_width=True)
            
            # ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
            if time_analysis_all["time_intervals"]:
                st.markdown("#### ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©")
                
                intervals_data = [interval["days"] for interval in time_analysis_all["time_intervals"]]
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… plotly Ù„Ù„Ù…Ø®Ø·Ø·Ø§Øª
                try:
                    import plotly.express as px
                    
                    # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¯Ø¯
                    fig_dist = px.histogram(
                        x=intervals_data,
                        title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¯Ø¯ Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«",
                        labels={"x": "Ø§Ù„Ù…Ø¯Ø© (Ø£ÙŠØ§Ù…)", "y": "Ø§Ù„ØªÙƒØ±Ø§Ø±"},
                        nbins=20,
                        color_discrete_sequence=['#4ECDC4']
                    )
                    fig_dist.update_layout(
                        xaxis_title="Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« (Ø£ÙŠØ§Ù…)",
                        yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„ÙØªØ±Ø§Øª",
                        height=400
                    )
                    st.plotly_chart(fig_dist, use_container_width=True)
                    
                except ImportError:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… streamlit charts Ø¨Ø¯ÙŠÙ„
                    st.bar_chart(
                        pd.DataFrame({"Ø§Ù„Ù…Ø¯Ø© (Ø£ÙŠØ§Ù…)": intervals_data}).value_counts().sort_index(),
                        height=400
                    )
    
    with display_tabs[3]:
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø²Ù…Ù†ÙŠØ© Ù…ÙØµÙ„Ø©
        st.markdown("### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø²Ù…Ù†ÙŠØ© Ù…ÙØµÙ„Ø©")
        
        if len(filtered_df) < 2:
            st.info("â„¹ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø§ ÙŠÙƒÙÙŠ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©.")
        else:
            # Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„ÙƒÙ„ Ù…Ø§ÙƒÙŠÙ†Ø©
            machine_stats = []
            
            for machine in unique_machines[:20]:  # Ø£ÙˆÙ„ 20 Ù…Ø§ÙƒÙŠÙ†Ø© ÙÙ‚Ø·
                machine_data = filtered_df[filtered_df['Card Number'] == machine].copy()
                machine_events = []
                
                for _, row in machine_data.iterrows():
                    if row.get("Date_parsed"):
                        machine_events.append({
                            "Date_parsed": row.get("Date_parsed"),
                            "Event": row.get("Event", "-")
                        })
                
                if len(machine_events) > 1:
                    machine_events_sorted = sorted(machine_events, key=lambda x: x["Date_parsed"])
                    
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØªØ±Ø§Øª
                    intervals = []
                    for i in range(1, len(machine_events_sorted)):
                        delta = machine_events_sorted[i]["Date_parsed"] - machine_events_sorted[i-1]["Date_parsed"]
                        intervals.append(delta.days)
                    
                    if intervals:
                        machine_stats.append({
                            "Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©": machine,
                            "Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«": len(machine_events),
                            "Ø£ÙˆÙ„ Ø­Ø¯Ø«": machine_events_sorted[0]["Date_parsed"].strftime("%Y-%m-%d"),
                            "Ø¢Ø®Ø± Ø­Ø¯Ø«": machine_events_sorted[-1]["Date_parsed"].strftime("%Y-%m-%d"),
                            "Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø©": sum(intervals) / len(intervals),
                            "Ø£Ù‚ØµØ± Ù…Ø¯Ø©": min(intervals),
                            "Ø£Ø·ÙˆÙ„ Ù…Ø¯Ø©": max(intervals),
                            "Ø§Ù„ÙØªØ±Ø© Ø§Ù„ÙƒÙ„ÙŠØ©": (machine_events_sorted[-1]["Date_parsed"] - machine_events_sorted[0]["Date_parsed"]).days
                        })
            
            if machine_stats:
                stats_df = pd.DataFrame(machine_stats)
                
                # Ø¹Ø±Ø¶ Ø£ÙØ¶Ù„ 10 Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ù…Ù† Ø­ÙŠØ« Ø§Ù„Ù†Ø´Ø§Ø·
                st.markdown("#### ğŸ† Ø£ÙƒØ«Ø± 10 Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ù†Ø´Ø§Ø·Ø§Ù‹")
                top_active = stats_df.nlargest(10, "Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«")
                st.dataframe(top_active, use_container_width=True)
                
                st.markdown("#### â± Ø£ÙƒØ«Ø± 10 Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ù…Ù† Ø­ÙŠØ« Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«")
                top_intervals = stats_df.nlargest(10, "Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø©")
                st.dataframe(top_intervals, use_container_width=True)
                
                st.markdown("#### âš¡ Ø£ÙƒØ«Ø± 10 Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ù…Ù† Ø­ÙŠØ« Ø§Ù„ØªÙƒØ±Ø§Ø± (Ø£Ù‚ØµØ± Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«)")
                top_frequent = stats_df.nsmallest(10, "Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø©")
                st.dataframe(top_frequent, use_container_width=True)
            else:
                st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©.")
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ±
    st.markdown("---")
    st.markdown("### ğŸ’¾ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ±")
    
    export_col1, export_col2 = st.columns(2)
    
    with export_col1:
        # ØªØµØ¯ÙŠØ± Excel - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙˆØªØ±ØªÙŠØ¨Ù‡Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
        if not result_df.empty:
            buffer_excel = io.BytesIO()
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ù„Ù„ØªØµØ¯ÙŠØ± Ù…Ø¹ ØªØ±ØªÙŠØ¨ ØµØ­ÙŠØ­
            export_df = result_df.copy()
            
            # Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ù„Ù„ØªØ±ØªÙŠØ¨
            export_df['Card_Number_Clean_Export'] = pd.to_numeric(export_df['Card Number'], errors='coerce')
            export_df['Date_Clean_Export'] = pd.to_datetime(export_df['Date'], errors='coerce', dayfirst=True)
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            export_df = export_df.sort_values(by=['Card_Number_Clean_Export', 'Date_Clean_Export'], 
                                             ascending=[True, False], na_position='last')
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            export_df = export_df.drop(['Card_Number_Clean_Export', 'Date_Clean_Export'], axis=1, errors='ignore')
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
            export_df.to_excel(buffer_excel, index=False, engine="openpyxl")
            
            st.download_button(
                label="ğŸ“Š Ø­ÙØ¸ ÙƒÙ…Ù„Ù Excel",
                data=buffer_excel.getvalue(),
                file_name=f"Ø¨Ø­Ø«_Ø£Ø­Ø¯Ø§Ø«_Ù…Ø±ØªØ¨_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        else:
            st.info("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØµØ¯ÙŠØ±")
    
    with export_col2:
        # ØªØµØ¯ÙŠØ± CSV
        if not result_df.empty:
            buffer_csv = io.BytesIO()
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ù„Ù„ØªØµØ¯ÙŠØ± Ù…Ø¹ ØªØ±ØªÙŠØ¨ ØµØ­ÙŠØ­
            export_csv = result_df.copy()
            
            # Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ù„Ù„ØªØ±ØªÙŠØ¨
            export_csv['Card_Number_Clean_Export'] = pd.to_numeric(export_csv['Card Number'], errors='coerce')
            export_csv['Date_Clean_Export'] = pd.to_datetime(export_csv['Date'], errors='coerce', dayfirst=True)
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            export_csv = export_csv.sort_values(by=['Card_Number_Clean_Export', 'Date_Clean_Export'], 
                                               ascending=[True, False], na_position='last')
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            export_csv = export_csv.drop(['Card_Number_Clean_Export', 'Date_Clean_Export'], axis=1, errors='ignore')
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
            export_csv.to_csv(buffer_csv, index=False, encoding='utf-8-sig')
            
            st.download_button(
                label="ğŸ“„ Ø­ÙØ¸ ÙƒÙ…Ù„Ù CSV",
                data=buffer_csv.getvalue(),
                file_name=f"Ø¨Ø­Ø«_Ø£Ø­Ø¯Ø§Ø«_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        else:
            st.info("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØµØ¯ÙŠØ±")

# -------------------------------
# ğŸ–¥ Ø¯Ø§Ù„Ø© Ø¥Ø¶Ø§ÙØ© Ø¥ÙŠÙÙŠÙ†Øª Ø¬Ø¯ÙŠØ¯ - ÙÙŠ Ø§Ù„Ø´ÙŠØª Ø§Ù„Ù…Ù†ÙØµÙ„
# -------------------------------
def add_new_event(sheets_edit):
    """Ø¥Ø¶Ø§ÙØ© Ø¥ÙŠÙÙŠÙ†Øª Ø¬Ø¯ÙŠØ¯ ÙÙŠ Ø´ÙŠØª Ù…Ù†ÙØµÙ„"""
    st.subheader("â• Ø¥Ø¶Ø§ÙØ© Ø­Ø¯Ø« Ø¬Ø¯ÙŠØ¯")
    
    sheet_name = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØª:", list(sheets_edit.keys()), key="add_event_sheet")
    df = sheets_edit[sheet_name].astype(str)
    
    st.markdown("Ø£Ø¯Ø®Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø¯Ø« Ø§Ù„Ø¬Ø¯ÙŠØ¯:")
    
    col1, col2 = st.columns(2)
    with col1:
        card_num = st.text_input("Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©:", key="new_event_card")
        event_text = st.text_area("Ø§Ù„Ø­Ø¯Ø«:", key="new_event_text")
    with col2:
        correction_text = st.text_area("Ø§Ù„ØªØµØ­ÙŠØ­:", key="new_correction_text")
        serviced_by = st.text_input("ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©:", key="new_serviced_by")
    
    event_date = st.text_input("Ø§Ù„ØªØ§Ø±ÙŠØ® (Ù…Ø«Ø§Ù„: 20\\5\\2025):", key="new_event_date")
    
    if st.button("ğŸ’¾ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø­Ø¯Ø« Ø§Ù„Ø¬Ø¯ÙŠØ¯", key="add_new_event_btn"):
        if not card_num.strip():
            st.warning("âš  Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©.")
            return
        
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙ Ø¬Ø¯ÙŠØ¯
        new_row = {}
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø£Ø­Ø¯Ø§Ø«
        new_row["card"] = card_num.strip()
        if event_date.strip():
            new_row["Date"] = event_date.strip()
        
        # Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†
        event_columns = [col for col in df.columns if normalize_name(col) in ["event", "events", "Ø§Ù„Ø­Ø¯Ø«", "Ø§Ù„Ø£Ø­Ø¯Ø§Ø«"]]
        if event_columns and event_text.strip():
            new_row[event_columns[0]] = event_text.strip()
        elif not event_columns and event_text.strip():
            new_row["Event"] = event_text.strip()
        
        correction_columns = [col for col in df.columns if normalize_name(col) in ["correction", "correct", "ØªØµØ­ÙŠØ­", "ØªØµÙˆÙŠØ¨"]]
        if correction_columns and correction_text.strip():
            new_row[correction_columns[0]] = correction_text.strip()
        elif not correction_columns and correction_text.strip():
            new_row["Correction"] = correction_text.strip()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Servised by
        servised_col = None
        servised_columns = [col for col in df.columns if normalize_name(col) in ["servisedby", "servicedby", "serviceby", "Ø®Ø¯Ù…Ø¨ÙˆØ§Ø³Ø·Ø©"]]
            with col_btn2:
        if st.button("ğŸ—‘ Ù…Ø³Ø­", key=f"clear_col_{sheet_name_col}"):
            st.rerun()

# Tab 4: Ø¥Ø¶Ø§ÙØ© Ø¥ÙŠÙÙŠÙ†Øª Ø¬Ø¯ÙŠØ¯
with tab4:
    add_new_event(sheets_edit)

# Tab 5: ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†
with tab5:
    edit_events_and_corrections(sheets_edit)
