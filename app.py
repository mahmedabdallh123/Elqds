import streamlit as st
import pandas as pd
import json
import os
import io
import requests
import shutil
import re
import numpy as np
from datetime import datetime, timedelta
from base64 import b64decode
from typing import List, Dict, Any, Optional

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ PyGithub (Ù„Ø±ÙØ¹ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª)
try:
    from github import Github
    GITHUB_AVAILABLE = True
except Exception:
    GITHUB_AVAILABLE = False

# ===============================
# âš™ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ - ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ Ø¨Ø³Ù‡ÙˆÙ„Ø©
# ===============================
APP_CONFIG = {
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ø§Ù…Ø©
    "APP_TITLE": "CMMS - bel",
    "APP_ICON": "ğŸ­",
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª GitHub
    "REPO_NAME": "mahmedabdallh123/Elqds",
    "BRANCH": "main",
    "FILE_PATH": "l4.xlsx",
    "LOCAL_FILE": "l4.xlsx",
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†
    "MAX_ACTIVE_USERS": 2,
    "SESSION_DURATION_MINUTES": 15,
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
    "SHOW_TECH_SUPPORT_TO_ALL": False,
    "CUSTOM_TABS": ["ğŸ“Š ÙØ­Øµ Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³", "ğŸ“‹ ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†", "ğŸ›  ØªØ¹Ø¯ÙŠÙ„ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "ğŸ‘¥ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†", "ğŸ“ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ"]
}

# ===============================
# ğŸ—‚ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª
# ===============================
USERS_FILE = "users.json"
STATE_FILE = "state.json"
SESSION_DURATION = timedelta(minutes=APP_CONFIG["SESSION_DURATION_MINUTES"])
MAX_ACTIVE_USERS = APP_CONFIG["MAX_ACTIVE_USERS"]

# Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· GitHub ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
GITHUB_EXCEL_URL = f"https://github.com/{APP_CONFIG['REPO_NAME'].split('/')[0]}/{APP_CONFIG['REPO_NAME'].split('/')[1]}/raw/{APP_CONFIG['BRANCH']}/{APP_CONFIG['FILE_PATH']}"

# ===============================
# ğŸ§  ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
# ===============================
def load_users():
    """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† Ù…Ù„Ù JSON - Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø©"""
    if not os.path.exists(USERS_FILE):
        default_users = {
            "admin": {
                "password": "admin123", 
                "role": "admin", 
                "created_at": datetime.now().isoformat(),
                "permissions": ["all"]
            }
        }
        with open(USERS_FILE, "w", encoding="utf-8") as f:
            json.dump(default_users, f, indent=4, ensure_ascii=False)
        return default_users
    
    try:
        with open(USERS_FILE, "r", encoding="utf-8") as f:
            users = json.load(f)
        
        if "admin" not in users:
            users["admin"] = {
                "password": "admin123", 
                "role": "admin", 
                "created_at": datetime.now().isoformat(),
                "permissions": ["all"]
            }
            with open(USERS_FILE, "w", encoding="utf-8") as f:
                json.dump(users, f, indent=4, ensure_ascii=False)
        
        for username, user_data in users.items():
            if "role" not in user_data:
                user_data["role"] = "admin" if username == "admin" else "viewer"
                user_data["permissions"] = ["all"] if username == "admin" else ["view"]
                    
            if "created_at" not in user_data:
                user_data["created_at"] = datetime.now().isoformat()
        
        with open(USERS_FILE, "w", encoding="utf-8") as f:
            json.dump(users, f, indent=4, ensure_ascii=False)
        
        return users
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ù„Ù users.json: {e}")
        return {
            "admin": {
                "password": "admin123", 
                "role": "admin", 
                "created_at": datetime.now().isoformat(),
                "permissions": ["all"]
            }
        }

def save_users(users):
    """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¥Ù„Ù‰ Ù…Ù„Ù JSON"""
    try:
        with open(USERS_FILE, "w", encoding="utf-8") as f:
            json.dump(users, f, indent=4, ensure_ascii=False)
        return True
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù…Ù„Ù users.json: {e}")
        return False

def load_state():
    if not os.path.exists(STATE_FILE):
        with open(STATE_FILE, "w", encoding="utf-8") as f:
            json.dump({}, f, indent=4, ensure_ascii=False)
        return {}
    try:
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {}

def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, indent=4, ensure_ascii=False)

def cleanup_sessions(state):
    now = datetime.now()
    changed = False
    for user, info in list(state.items()):
        if info.get("active") and "login_time" in info:
            try:
                login_time = datetime.fromisoformat(info["login_time"])
                if now - login_time > SESSION_DURATION:
                    info["active"] = False
                    info.pop("login_time", None)
                    changed = True
            except:
                info["active"] = False
                changed = True
    if changed:
        save_state(state)
    return state

def remaining_time(state, username):
    if not username or username not in state:
        return None
    info = state.get(username)
    if not info or not info.get("active"):
        return None
    try:
        lt = datetime.fromisoformat(info["login_time"])
        remaining = SESSION_DURATION - (datetime.now() - lt)
        if remaining.total_seconds() <= 0:
            return None
        return remaining
    except:
        return None

def logout_action():
    state = load_state()
    username = st.session_state.get("username")
    if username and username in state:
        state[username]["active"] = False
        state[username].pop("login_time", None)
        save_state(state)
    keys = list(st.session_state.keys())
    for k in keys:
        st.session_state.pop(k, None)
    st.rerun()

def login_ui():
    users = load_users()
    state = cleanup_sessions(load_state())
    if "logged_in" not in st.session_state:
        st.session_state.logged_in = False
        st.session_state.username = None
        st.session_state.user_role = None
        st.session_state.user_permissions = []

    st.title(f"{APP_CONFIG['APP_ICON']} ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ - {APP_CONFIG['APP_TITLE']}")

    try:
        with open(USERS_FILE, "r", encoding="utf-8") as f:
            current_users = json.load(f)
        user_list = list(current_users.keys())
    except:
        user_list = list(users.keys())

    username_input = st.selectbox("ğŸ‘¤ Ø§Ø®ØªØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…", user_list)
    password = st.text_input("ğŸ”‘ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±", type="password")

    active_users = [u for u, v in state.items() if v.get("active")]
    active_count = len(active_users)
    st.caption(f"ğŸ”’ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† Ø§Ù„Ù†Ø´Ø·ÙˆÙ† Ø§Ù„Ø¢Ù†: {active_count} / {MAX_ACTIVE_USERS}")

    if not st.session_state.logged_in:
        if st.button("ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„"):
            current_users = load_users()
            
            if username_input in current_users and current_users[username_input]["password"] == password:
                if username_input == "admin":
                    pass
                elif username_input in active_users:
                    st.warning("âš  Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø³Ø¬Ù„ Ø¯Ø®ÙˆÙ„ Ø¨Ø§Ù„ÙØ¹Ù„.")
                    return False
                elif active_count >= MAX_ACTIVE_USERS:
                    st.error("ğŸš« Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…ØªØµÙ„ÙŠÙ† Ø­Ø§Ù„ÙŠØ§Ù‹.")
                    return False
                
                state[username_input] = {"active": True, "login_time": datetime.now().isoformat()}
                save_state(state)
                
                st.session_state.logged_in = True
                st.session_state.username = username_input
                st.session_state.user_role = current_users[username_input].get("role", "viewer")
                st.session_state.user_permissions = current_users[username_input].get("permissions", ["view"])
                
                st.success(f"âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„: {username_input} ({st.session_state.user_role})")
                st.rerun()
            else:
                st.error("âŒ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©.")
        return False
    else:
        username = st.session_state.username
        user_role = st.session_state.user_role
        st.success(f"âœ… Ù…Ø³Ø¬Ù„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙƒÙ€: {username} ({user_role})")
        rem = remaining_time(state, username)
        if rem:
            mins, secs = divmod(int(rem.total_seconds()), 60)
            st.info(f"â³ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ: {mins:02d}:{secs:02d}")
        else:
            st.warning("â° Ø§Ù†ØªÙ‡Øª Ø§Ù„Ø¬Ù„Ø³Ø©ØŒ Ø³ÙŠØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬.")
            logout_action()
        if st.button("ğŸšª ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬"):
            logout_action()
        return True

# ===============================
# ğŸ“ ÙˆØ¸Ø§Ø¦Ù Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆGitHub
# ===============================
def fetch_from_github_requests():
    """ØªØ­Ù…ÙŠÙ„ Ø¨Ø¥Ø³ØªØ®Ø¯Ø§Ù… Ø±Ø§Ø¨Ø· RAW (requests)"""
    try:
        response = requests.get(GITHUB_EXCEL_URL, stream=True, timeout=15)
        response.raise_for_status()
        with open(APP_CONFIG["LOCAL_FILE"], "wb") as f:
            shutil.copyfileobj(response.raw, f)
        try:
            st.cache_data.clear()
        except:
            pass
        return True
    except Exception as e:
        st.error(f"âš  ÙØ´Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù…Ù† GitHub: {e}")
        return False

def fetch_from_github_api():
    """ØªØ­Ù…ÙŠÙ„ Ø¹Ø¨Ø± GitHub API (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyGithub token ÙÙŠ secrets)"""
    if not GITHUB_AVAILABLE:
        return fetch_from_github_requests()
    
    try:
        token = st.secrets.get("github", {}).get("token", None)
        if not token:
            return fetch_from_github_requests()
        
        g = Github(token)
        repo = g.get_repo(APP_CONFIG["REPO_NAME"])
        file_content = repo.get_contents(APP_CONFIG["FILE_PATH"], ref=APP_CONFIG["BRANCH"])
        content = b64decode(file_content.content)
        with open(APP_CONFIG["LOCAL_FILE"], "wb") as f:
            f.write(content)
        try:
            st.cache_data.clear()
        except:
            pass
        return True
    except Exception as e:
        st.error(f"âš  ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† GitHub: {e}")
        return False

@st.cache_data(show_spinner=False)
def load_all_sheets():
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ù…Ù† Ù…Ù„Ù Excel"""
    if not os.path.exists(APP_CONFIG["LOCAL_FILE"]):
        return None
    
    try:
        sheets = pd.read_excel(APP_CONFIG["LOCAL_FILE"], sheet_name=None)
        
        if not sheets:
            return None
        
        for name, df in sheets.items():
            df.columns = df.columns.astype(str).str.strip()
        
        return sheets
    except Exception as e:
        return None

@st.cache_data(show_spinner=False)
def load_sheets_for_edit():
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ù„Ù„ØªØ­Ø±ÙŠØ±"""
    if not os.path.exists(APP_CONFIG["LOCAL_FILE"]):
        return None
    
    try:
        sheets = pd.read_excel(APP_CONFIG["LOCAL_FILE"], sheet_name=None, dtype=object)
        
        if not sheets:
            return None
        
        for name, df in sheets.items():
            df.columns = df.columns.astype(str).str.strip()
        
        return sheets
    except Exception as e:
        return None

def save_local_excel_and_push(sheets_dict, commit_message="Update from Streamlit"):
    """Ø¯Ø§Ù„Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠ ÙˆØ§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ GitHub"""
    try:
        with pd.ExcelWriter(APP_CONFIG["LOCAL_FILE"], engine="openpyxl") as writer:
            for name, sh in sheets_dict.items():
                try:
                    sh.to_excel(writer, sheet_name=name, index=False)
                except Exception:
                    sh.astype(object).to_excel(writer, sheet_name=name, index=False)
    except Exception as e:
        st.error(f"âš  Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ù„ÙŠ: {e}")
        return None

    try:
        st.cache_data.clear()
    except:
        pass

    token = st.secrets.get("github", {}).get("token", None)
    if not token:
        st.warning("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ GitHub token. Ø³ÙŠØªÙ… Ø§Ù„Ø­ÙØ¸ Ù…Ø­Ù„ÙŠØ§Ù‹ ÙÙ‚Ø·.")
        return load_sheets_for_edit()

    if not GITHUB_AVAILABLE:
        st.warning("âš  PyGithub ØºÙŠØ± Ù…ØªÙˆÙØ±. Ø³ÙŠØªÙ… Ø§Ù„Ø­ÙØ¸ Ù…Ø­Ù„ÙŠØ§Ù‹ ÙÙ‚Ø·.")
        return load_sheets_for_edit()

    try:
        g = Github(token)
        repo = g.get_repo(APP_CONFIG["REPO_NAME"])
        with open(APP_CONFIG["LOCAL_FILE"], "rb") as f:
            content = f.read()

        try:
            contents = repo.get_contents(APP_CONFIG["FILE_PATH"], ref=APP_CONFIG["BRANCH"])
            result = repo.update_file(path=APP_CONFIG["FILE_PATH"], message=commit_message, content=content, sha=contents.sha, branch=APP_CONFIG["BRANCH"])
            st.success(f"âœ… ØªÙ… Ø§Ù„Ø­ÙØ¸ ÙˆØ§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ GitHub Ø¨Ù†Ø¬Ø§Ø­: {commit_message}")
            return load_sheets_for_edit()
        except Exception as e:
            try:
                result = repo.create_file(path=APP_CONFIG["FILE_PATH"], message=commit_message, content=content, branch=APP_CONFIG["BRANCH"])
                st.success(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ø¹Ù„Ù‰ GitHub: {commit_message}")
                return load_sheets_for_edit()
            except Exception as create_error:
                st.error(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ø¹Ù„Ù‰ GitHub: {create_error}")
                return None

    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ GitHub: {e}")
        return None

def auto_save_to_github(sheets_dict, operation_description):
    """Ø¯Ø§Ù„Ø© Ø§Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø­Ø³Ù†Ø©"""
    username = st.session_state.get("username", "unknown")
    commit_message = f"{operation_description} by {username} at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    
    result = save_local_excel_and_push(sheets_dict, commit_message)
    if result is not None:
        st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙÙŠ GitHub")
        return result
    else:
        st.error("âŒ ÙØ´Ù„ Ø§Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")
        return sheets_dict

# ===============================
# ğŸ›  ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
# ===============================
def normalize_name(s):
    if s is None: return ""
    s = str(s).replace("\n", "+")
    s = re.sub(r"[^0-9a-zA-Z\u0600-\u06FF\+\s_/.-]", " ", s)
    s = re.sub(r"\s+", " ", s).strip().lower()
    return s

def split_needed_services(needed_service_str):
    if not isinstance(needed_service_str, str) or needed_service_str.strip() == "":
        return []
    parts = re.split(r"\+|,|\n|;", needed_service_str)
    return [p.strip() for p in parts if p.strip() != ""]

def highlight_cell(val, col_name):
    color_map = {
        "Service Needed": "background-color: #fff3cd; color:#856404; font-weight:bold;",
        "Service Done": "background-color: #d4edda; color:#155724; font-weight:bold;",
        "Service Didn't Done": "background-color: #f8d7da; color:#721c24; font-weight:bold;",
        "Date": "background-color: #e7f1ff; color:#004085; font-weight:bold;",
        "Tones": "background-color: #e8f8f5; color:#0d5c4a; font-weight:bold;",
        "Event": "background-color: #e2f0d9; color:#2e6f32; font-weight:bold;",
        "Correction": "background-color: #fdebd0; color:#7d6608; font-weight:bold;",
        "Servised by": "background-color: #f0f0f0; color:#333; font-weight:bold;",
        "Card Number": "background-color: #ebdef0; color:#4a235a; font-weight:bold;"
    }
    return color_map.get(col_name, "")

def style_table(row):
    return [highlight_cell(row[col], col) for col in row.index]

def get_user_permissions(user_role, user_permissions):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¯ÙˆØ± ÙˆØ§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª"""
    if user_role == "admin":
        return {
            "can_view": True,
            "can_edit": True,
            "can_manage_users": True,
            "can_see_tech_support": True
        }
    elif user_role == "editor":
        return {
            "can_view": True,
            "can_edit": True,
            "can_manage_users": False,
            "can_see_tech_support": False
        }
    else:
        return {
            "can_view": "view" in user_permissions or "edit" in user_permissions or "all" in user_permissions,
            "can_edit": "edit" in user_permissions or "all" in user_permissions,
            "can_manage_users": "manage_users" in user_permissions or "all" in user_permissions,
            "can_see_tech_support": "tech_support" in user_permissions or "all" in user_permissions
        }

def get_servised_by_value(row):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙŠÙ…Ø© ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø© Ù…Ù† Ø§Ù„ØµÙ"""
    servised_columns = [
        "Servised by", "SERVISED BY", "servised by", "Servised By",
        "Serviced by", "Service by", "Serviced By", "Service By",
        "Ø®Ø¯Ù… Ø¨ÙˆØ§Ø³Ø·Ø©", "ØªÙ… Ø§Ù„Ø®Ø¯Ù…Ø© Ø¨ÙˆØ§Ø³Ø·Ø©", "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©"
    ]
    
    for col in servised_columns:
        if col in row.index:
            value = str(row[col]).strip()
            if value and value.lower() not in ["nan", "none", ""]:
                return value
    
    for col in row.index:
        col_normalized = normalize_name(col)
        if any(keyword in col_normalized for keyword in ["servisedby", "servicedby", "serviceby", "Ø®Ø¯Ù…Ø¨ÙˆØ§Ø³Ø·Ø©", "ÙÙ†ÙŠ"]):
            value = str(row[col]).strip()
            if value and value.lower() not in ["nan", "none", ""]:
                return value
    
    return "-"

# ===============================
# ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ Ù„Ù„Ø£Ø­Ø¯Ø§Ø«
# ===============================
class EventTimeAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ù„Ø£Ø­Ø¯Ø§Ø«"""
    
    @staticmethod
    def parse_date(date_str: str) -> Optional[datetime]:
        """ØªØ­ÙˆÙŠÙ„ Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ ÙƒØ§Ø¦Ù† datetime"""
        if not date_str or str(date_str).lower() in ["nan", "none", "null", "", "-"]:
            return None
        
        date_str = str(date_str).strip()
        date_formats = [
            '%d/%m/%Y', '%d-%m-%Y', '%Y-%m-%d',
            '%d/%m/%y', '%d-%m-%y', '%Y/%m/%d',
            '%d.%m.%Y', '%d.%m.%y'
        ]
        
        for fmt in date_formats:
            try:
                return datetime.strptime(date_str, fmt)
            except:
                continue
        
        try:
            return pd.to_datetime(date_str, dayfirst=True)
        except:
            return None
    
    @staticmethod
    def analyze_event_time_intervals(results_df: pd.DataFrame, event_name: str) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø¨ÙŠÙ† ØªÙƒØ±Ø§Ø±Ø§Øª Ø­Ø¯Ø« Ù…Ø¹ÙŠÙ†
        """
        if results_df.empty or 'Date' not in results_df.columns:
            return {}
        
        event_mask = results_df['Event'].str.contains(event_name, case=False, na=False)
        filtered_df = results_df[event_mask].copy()
        
        if filtered_df.empty:
            return {}
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
        filtered_df['Parsed_Date'] = filtered_df['Date'].apply(EventTimeAnalyzer.parse_date)
        filtered_df = filtered_df[filtered_df['Parsed_Date'].notna()]
        
        if filtered_df.empty:
            return {}
        
        filtered_df = filtered_df.sort_values('Parsed_Date')
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
        time_intervals = EventTimeAnalyzer.calculate_time_intervals(filtered_df)
        
        return {
            'event_name': event_name,
            'total_occurrences': len(filtered_df),
            'machines_count': filtered_df['Card Number'].nunique(),
            'time_intervals': time_intervals,
            'filtered_df': filtered_df,
            'statistics': EventTimeAnalyzer.calculate_statistics(time_intervals) if time_intervals else {}
        }
    
    @staticmethod
    def calculate_time_intervals(df: pd.DataFrame) -> List[Dict[str, Any]]:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«"""
        intervals = []
        
        machines = df['Card Number'].unique()
        
        for machine in machines:
            machine_events = df[df['Card Number'] == machine].sort_values('Parsed_Date')
            
            if len(machine_events) > 1:
                for i in range(len(machine_events) - 1):
                    current_event = machine_events.iloc[i]
                    next_event = machine_events.iloc[i + 1]
                    
                    current_date = current_event['Parsed_Date']
                    next_date = next_event['Parsed_Date']
                    
                    if current_date and next_date:
                        time_diff = next_date - current_date
                        days_between = time_diff.days
                        
                        intervals.append({
                            'machine': str(machine),
                            'current_event': EventTimeAnalyzer.truncate_text(str(current_event['Event']), 50),
                            'next_event': EventTimeAnalyzer.truncate_text(str(next_event['Event']), 50),
                            'current_date': current_event['Date'],
                            'next_date': next_event['Date'],
                            'current_parsed_date': current_date,
                            'next_parsed_date': next_date,
                            'days_between': days_between,
                            'weeks_between': days_between / 7,
                            'months_between': days_between / 30,
                            'current_tones': current_event.get('Tones', '-'),
                            'next_tones': next_event.get('Tones', '-'),
                            'current_tech': current_event.get('Servised by', '-'),
                            'next_tech': next_event.get('Servised by', '-')
                        })
        
        return intervals
    
    @staticmethod
    def calculate_statistics(intervals: List[Dict[str, Any]]) -> Dict[str, float]:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
        if not intervals:
            return {}
        
        days_list = [interval['days_between'] for interval in intervals]
        
        return {
            'min_days': min(days_list),
            'max_days': max(days_list),
            'mean_days': np.mean(days_list),
            'median_days': np.median(days_list),
            'std_days': np.std(days_list),
            'total_intervals': len(days_list),
            'machines_count': len(set([interval['machine'] for interval in intervals]))
        }
    
    @staticmethod
    def truncate_text(text: str, max_length: int) -> str:
        """Ù‚Øµ Ø§Ù„Ù†Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹"""
        if len(text) <= max_length:
            return text
        return text[:max_length] + "..."
    
    @staticmethod
    def analyze_multiple_events(results_df: pd.DataFrame, event_names: List[str]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù‚Ø§Ø±Ù† Ù„Ø¹Ø¯Ø© Ø£Ø­Ø¯Ø§Ø«"""
        if results_df.empty:
            return {}
        
        comparison_data = []
        
        for event_name in event_names:
            analysis = EventTimeAnalyzer.analyze_event_time_intervals(results_df, event_name)
            if analysis and analysis.get('statistics'):
                stats = analysis['statistics']
                comparison_data.append({
                    'Ø§Ù„Ø­Ø¯Ø«': event_name,
                    'Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª': analysis['total_occurrences'],
                    'Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª': analysis['machines_count'],
                    'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£ÙŠØ§Ù…': stats['mean_days'],
                    'Ø§Ù„ÙˆØ³ÙŠØ·': stats['median_days'],
                    'Ø£Ù‚ØµØ± ÙØªØ±Ø©': stats['min_days'],
                    'Ø£Ø·ÙˆÙ„ ÙØªØ±Ø©': stats['max_days'],
                    'Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ': stats['std_days']
                })
        
        return {
            'comparison_data': comparison_data,
            'total_events_analyzed': len(comparison_data)
        }

# ===============================
# ğŸ–¥ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ù„Ø£Ø­Ø¯Ø§Ø«
# ===============================
def display_time_analysis(analysis_result: Dict[str, Any]):
    """Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ"""
    if not analysis_result:
        return
    
    event_name = analysis_result['event_name']
    stats = analysis_result['statistics']
    intervals = analysis_result['time_intervals']
    filtered_df = analysis_result['filtered_df']
    
    st.markdown(f"### â±ï¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ø­Ø¯Ø«: **{event_name}**")
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ”„ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª", analysis_result['total_occurrences'])
    
    with col2:
        st.metric("ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª", analysis_result['machines_count'])
    
    with col3:
        if stats:
            st.metric("ğŸ“Š Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£ÙŠØ§Ù…", f"{stats['mean_days']:.1f}")
    
    with col4:
        if stats:
            st.metric("ğŸ“ˆ Ø¹Ø¯Ø¯ Ø§Ù„ÙØªØ±Ø§Øª", stats['total_intervals'])
    
    st.markdown("---")
    
    if not intervals:
        st.info(f"â„¹ï¸ Ø­Ø¯Ø« '{event_name}' ÙˆÙØ¬Ø¯ ÙÙŠ {analysis_result['total_occurrences']} Ù…Ù†Ø§Ø³Ø¨Ø§ØªØŒ Ù„ÙƒÙ† Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©.")
        display_events_table(filtered_df)
        return
    
    # ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§ØµÙŠÙ„
    tabs = st.tabs(["ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©", "ğŸ“ˆ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©", "ğŸ“‹ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©", "ğŸ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª"])
    
    with tabs[0]:
        display_detailed_statistics(stats, intervals)
    
    with tabs[1]:
        display_time_charts(intervals, event_name)
    
    with tabs[2]:
        display_intervals_table(intervals)
    
    with tabs[3]:
        display_recommendations(analysis_result)

def display_detailed_statistics(stats: Dict[str, float], intervals: List[Dict[str, Any]]):
    """Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©"""
    if not stats:
        return
    
    st.markdown("#### ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©")
    
    stat_data = {
        "Ø§Ù„Ù…Ù‚ÙŠØ§Ø³": [
            "Ø£Ù‚ØµØ± ÙØªØ±Ø© (Ø£ÙŠØ§Ù…)",
            "Ø£Ø·ÙˆÙ„ ÙØªØ±Ø© (Ø£ÙŠØ§Ù…)",
            "Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠ (Ø£ÙŠØ§Ù…)",
            "Ø§Ù„ÙˆØ³ÙŠØ· (Ø£ÙŠØ§Ù…)",
            "Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ (Ø£ÙŠØ§Ù…)",
            "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹",
            "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø´Ù‡Ø±"
        ],
        "Ø§Ù„Ù‚ÙŠÙ…Ø©": [
            f"{stats['min_days']:.1f}",
            f"{stats['max_days']:.1f}",
            f"{stats['mean_days']:.1f}",
            f"{stats['median_days']:.1f}",
            f"{stats['std_days']:.1f}",
            f"{stats['mean_days'] / 7:.1f}",
            f"{stats['mean_days'] / 30:.1f}"
        ]
    }
    
    stat_df = pd.DataFrame(stat_data)
    st.dataframe(stat_df, use_container_width=True)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹
    st.markdown("#### ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹")
    
    days_list = [interval['days_between'] for interval in intervals]
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        short_intervals = len([d for d in days_list if d < 30])
        st.metric("â³ ÙØªØ±Ø§Øª Ù‚ØµÙŠØ±Ø© (<30 ÙŠÙˆÙ…)", short_intervals)
    
    with col2:
        medium_intervals = len([d for d in days_list if 30 <= d <= 90])
        st.metric("ğŸ• ÙØªØ±Ø§Øª Ù…ØªÙˆØ³Ø·Ø© (30-90 ÙŠÙˆÙ…)", medium_intervals)
    
    with col3:
        long_intervals = len([d for d in days_list if d > 90])
        st.metric("â° ÙØªØ±Ø§Øª Ø·ÙˆÙŠÙ„Ø© (>90 ÙŠÙˆÙ…)", long_intervals)

def display_time_charts(intervals: List[Dict[str, Any]], event_name: str):
    """Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
    if not intervals:
        return
    
    try:
        import plotly.express as px
        import plotly.graph_objects as go
        
        intervals_df = pd.DataFrame(intervals)
        
        # Ù…Ø®Ø·Ø· ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØªØ±Ø§Øª
        st.markdown("#### ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©")
        
        fig1 = px.histogram(
            intervals_df,
            x='days_between',
            nbins=20,
            title=f'ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø¨ÙŠÙ† ØªÙƒØ±Ø§Ø±Ø§Øª Ø­Ø¯Ø« "{event_name}"',
            labels={'days_between': 'Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ø¨ÙŠÙ† Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª'},
            color_discrete_sequence=['#4ECDC4']
        )
        fig1.update_layout(
            xaxis_title="Ø§Ù„Ø£ÙŠØ§Ù…",
            yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„ÙØªØ±Ø§Øª",
            showlegend=False
        )
        st.plotly_chart(fig1, use_container_width=True)
        
        # Ù…Ø®Ø·Ø· Ù…Ø±Ø¨Ø¹Ø§Øª (Box Plot)
        st.markdown("#### ğŸ“¦ Ù…Ø®Ø·Ø· Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØªØ±Ø§Øª")
        
        fig2 = px.box(
            intervals_df,
            y='days_between',
            title='ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© (Ù…Ø®Ø·Ø· Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª)',
            labels={'days_between': 'Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù…'}
        )
        fig2.update_layout(
            yaxis_title="Ø§Ù„Ø£ÙŠØ§Ù… Ø¨ÙŠÙ† Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª",
            showlegend=False
        )
        st.plotly_chart(fig2, use_container_width=True)
        
        # Ù…Ø®Ø·Ø· Ø´Ø±ÙŠØ·ÙŠ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©
        if len(intervals_df['machine'].unique()) <= 20:
            st.markdown("#### ğŸ­ Ù…ØªÙˆØ³Ø· Ø§Ù„ÙØªØ±Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©")
            
            machine_avg = intervals_df.groupby('machine')['days_between'].mean().reset_index()
            machine_avg = machine_avg.sort_values('days_between', ascending=True)
            
            fig3 = px.bar(
                machine_avg,
                x='days_between',
                y='machine',
                orientation='h',
                title='Ù…ØªÙˆØ³Ø· Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©',
                labels={'days_between': 'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£ÙŠØ§Ù…', 'machine': 'Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©'},
                color='days_between',
                color_continuous_scale='Viridis'
            )
            st.plotly_chart(fig3, use_container_width=True)
        
    except ImportError:
        st.info("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙƒØªØ¨Ø© plotly. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ«Ø¨ÙŠØªÙ‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…: pip install plotly")
        
        # Ø¹Ø±Ø¶ Ø¨Ø¯ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… streamlit charts
        intervals_df = pd.DataFrame(intervals)
        
        st.markdown("#### ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© (Ø¨Ø¯ÙŠÙ„)")
        st.bar_chart(intervals_df['days_between'].value_counts().sort_index())
        
        st.markdown("#### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙØªØ±Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©")
        if 'machine' in intervals_df.columns and 'days_between' in intervals_df.columns:
            machine_stats = intervals_df.groupby('machine')['days_between'].agg(['mean', 'min', 'max']).round(1)
            st.dataframe(machine_stats, use_container_width=True)

def display_intervals_table(intervals: List[Dict[str, Any]]):
    """Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
    if not intervals:
        return
    
    st.markdown("#### ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…ÙØµÙ„Ø©")
    
    display_data = []
    for interval in intervals:
        display_data.append({
            'Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©': interval['machine'],
            'Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø£ÙˆÙ„': interval['current_date'],
            'Ø§Ù„Ø­Ø¯Ø« Ø§Ù„Ø£ÙˆÙ„': interval['current_event'],
            'Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ§Ù„ÙŠ': interval['next_date'],
            'Ø§Ù„Ø­Ø¯Ø« Ø§Ù„ØªØ§Ù„ÙŠ': interval['next_event'],
            'Ø§Ù„Ø£ÙŠØ§Ù… Ø¨ÙŠÙ†Ù‡Ù…Ø§': interval['days_between'],
            'Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø¨ÙŠÙ†Ù‡Ù…Ø§': f"{interval['weeks_between']:.1f}",
            'Ø§Ù„Ø£Ø´Ù‡Ø± Ø¨ÙŠÙ†Ù‡Ù…Ø§': f"{interval['months_between']:.1f}",
            'ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø© (Ø§Ù„Ø£ÙˆÙ„)': interval.get('current_tech', '-'),
            'ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø© (Ø§Ù„ØªØ§Ù„ÙŠ)': interval.get('next_tech', '-')
        })
    
    intervals_df = pd.DataFrame(display_data)
    
    # Ø¥Ø¶Ø§ÙØ© ÙÙ„ØªØ±Ø©
    st.markdown("##### ğŸ” ÙÙ„ØªØ±Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    col1, col2 = st.columns(2)
    
    with col1:
        min_days = st.number_input("Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø£ÙŠØ§Ù…:", min_value=0, value=0, step=1)
    
    with col2:
        max_days = st.number_input("Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø£ÙŠØ§Ù…:", min_value=min_days, value=365, step=1)
    
    filtered_df = intervals_df[
        (intervals_df['Ø§Ù„Ø£ÙŠØ§Ù… Ø¨ÙŠÙ†Ù‡Ù…Ø§'] >= min_days) & 
        (intervals_df['Ø§Ù„Ø£ÙŠØ§Ù… Ø¨ÙŠÙ†Ù‡Ù…Ø§'] <= max_days)
    ]
    
    st.dataframe(
        filtered_df.sort_values('Ø§Ù„Ø£ÙŠØ§Ù… Ø¨ÙŠÙ†Ù‡Ù…Ø§'),
        use_container_width=True,
        height=400
    )
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ±
    st.markdown("---")
    buffer = io.BytesIO()
    filtered_df.to_excel(buffer, index=False, engine='openpyxl')
    
    st.download_button(
        label="ğŸ“Š Ø­ÙØ¸ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© ÙƒÙ€ Excel",
        data=buffer.getvalue(),
        file_name=f"ÙØªØ±Ø§Øª_Ø²Ù…Ù†ÙŠØ©_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

def display_recommendations(analysis_result: Dict[str, Any]):
    """Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
    if not analysis_result or not analysis_result.get('statistics'):
        return
    
    stats = analysis_result['statistics']
    event_name = analysis_result['event_name']
    total_occurrences = analysis_result['total_occurrences']
    
    st.markdown("#### ğŸ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª")
    
    recommendations = []
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
    mean_days = stats['mean_days']
    std_days = stats['std_days']
    
    if mean_days < 30:
        recommendations.append({
            "Ø§Ù„ØªØµÙ†ÙŠÙ": "ğŸ”„ ØªÙƒØ±Ø§Ø± Ø³Ø±ÙŠØ¹",
            "Ø§Ù„ÙˆØµÙ": f"Ø­Ø¯Ø« '{event_name}' ÙŠØªÙƒØ±Ø± ÙƒÙ„ {mean_days:.1f} ÙŠÙˆÙ… ÙÙŠ Ø§Ù„Ù…ØªÙˆØ³Ø·",
            "Ø§Ù„ØªÙˆØµÙŠØ©": f"""â€¢ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„ÙˆÙ‚Ø§Ø¦ÙŠØ© ÙƒÙ„ {mean_days:.0f} ÙŠÙˆÙ…
â€¢ ÙØ­Øµ Ø¬ÙˆØ¯Ø© Ø§Ù„ØªÙ†ÙÙŠØ°
â€¢ ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ÙØªØ±Ø§Øª Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†"""
        })
    elif mean_days < 90:
        recommendations.append({
            "Ø§Ù„ØªØµÙ†ÙŠÙ": "âš–ï¸ ØªÙƒØ±Ø§Ø± Ù…ØªÙˆØ³Ø·",
            "Ø§Ù„ÙˆØµÙ": f"Ø­Ø¯Ø« '{event_name}' ÙŠØªÙƒØ±Ø± ÙƒÙ„ {mean_days:.1f} ÙŠÙˆÙ… ÙÙŠ Ø§Ù„Ù…ØªÙˆØ³Ø·",
            "Ø§Ù„ØªÙˆØµÙŠØ©": f"""â€¢ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¯ÙˆØ±ÙŠØ© ÙƒÙ„ {mean_days/7:.1f} Ø£Ø³Ø§Ø¨ÙŠØ¹
â€¢ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ø´Ù‡Ø±ÙŠØ©
â€¢ Ù…Ø±Ø§Ø¬Ø¹Ø© Ù‚Ø·Ø¹ Ø§Ù„ØºÙŠØ§Ø±"""
        })
    else:
        recommendations.append({
            "Ø§Ù„ØªØµÙ†ÙŠÙ": "â° ØªÙƒØ±Ø§Ø± Ø·ÙˆÙŠÙ„",
            "Ø§Ù„ÙˆØµÙ": f"Ø­Ø¯Ø« '{event_name}' ÙŠØªÙƒØ±Ø± ÙƒÙ„ {mean_days:.1f} ÙŠÙˆÙ… ÙÙŠ Ø§Ù„Ù…ØªÙˆØ³Ø·",
            "Ø§Ù„ØªÙˆØµÙŠØ©": f"""â€¢ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø³ÙŠØ§Ø³Ø© Ø§Ù„ØµÙŠØ§Ù†Ø© ÙƒÙ„ {mean_days/30:.1f} Ø£Ø´Ù‡Ø±
â€¢ ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ø·ÙˆÙŠÙ„
â€¢ ØªØ®Ø·ÙŠØ· Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø³Ù†ÙˆÙŠØ©"""
        })
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¨Ø§ÙŠÙ†
    if std_days > mean_days * 0.5:
        recommendations.append({
            "Ø§Ù„ØªØµÙ†ÙŠÙ": "ğŸ“Š ØªØ¨Ø§ÙŠÙ† ÙƒØ¨ÙŠØ±",
            "Ø§Ù„ÙˆØµÙ": f"Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ ({std_days:.1f} ÙŠÙˆÙ…) ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ ØªØ¨Ø§ÙŠÙ† ÙƒØ¨ÙŠØ± ÙÙŠ Ø§Ù„ÙØªØ±Ø§Øª",
            "Ø§Ù„ØªÙˆØµÙŠØ©": """â€¢ ØªÙˆØ­ÙŠØ¯ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ØµÙŠØ§Ù†Ø©
â€¢ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙÙ†ÙŠÙŠÙ†
â€¢ ØªØ·ÙˆÙŠØ± Ù…Ø¹Ø§ÙŠÙŠØ± Ù…ÙˆØ­Ø¯Ø©"""
        })
    
    # Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
    if total_occurrences > 10:
        recommendations.append({
            "Ø§Ù„ØªØµÙ†ÙŠÙ": "ğŸ”¢ ØªÙƒØ±Ø§Ø±Ø§Øª Ø¹Ø§Ù„ÙŠØ©",
            "Ø§Ù„ÙˆØµÙ": f"Ø§Ù„Ø­Ø¯Ø« ØªÙƒØ±Ø± {total_occurrences} Ù…Ø±Ø©",
            "Ø§Ù„ØªÙˆØµÙŠØ©": """â€¢ ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¹Ø§Ù„ÙŠ
â€¢ Ø¯Ø±Ø§Ø³Ø© Ø¬Ø¯ÙˆÙ‰ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª
â€¢ ØªÙ‚ÙŠÙŠÙ… ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù…Ø¹Ø¯Ø§Øª"""
        })
    
    # Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª
    for i, rec in enumerate(recommendations, 1):
        with st.expander(f"{rec['Ø§Ù„ØªØµÙ†ÙŠÙ']} - {rec['Ø§Ù„ÙˆØµÙ']}", expanded=True):
            st.markdown(f"**Ø§Ù„ØªÙˆØµÙŠØ©:**")
            st.write(rec['Ø§Ù„ØªÙˆØµÙŠØ©'])
    
    # Ø¥Ø¶Ø§ÙØ© ØªØ­Ù„ÙŠÙ„ ØªÙ†Ø¨Ø¤ÙŠ
    st.markdown("#### ğŸ”® ØªØ­Ù„ÙŠÙ„ ØªÙ†Ø¨Ø¤ÙŠ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        next_occurrence = st.number_input(
            "Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© Ù„Ù„ØªÙ†Ø¨Ø¤:",
            min_value=30,
            max_value=365,
            value=90,
            step=30
        )
    
    with col2:
        machines_count = analysis_result['machines_count']
        expected_occurrences = (next_occurrence / mean_days) * machines_count if mean_days > 0 else 0
        
        st.metric(
            "ğŸ“ˆ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©",
            f"{expected_occurrences:.1f}",
            f"Ø®Ù„Ø§Ù„ {next_occurrence} ÙŠÙˆÙ…"
        )

def display_events_table(filtered_df: pd.DataFrame):
    """Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù…Ø¨Ø§Ø´Ø±Ø©"""
    if filtered_df.empty:
        return
    
    display_cols = ['Card Number', 'Event', 'Date', 'Servised by', 'Tones']
    display_cols = [col for col in display_cols if col in filtered_df.columns]
    
    st.dataframe(
        filtered_df[display_cols].sort_values('Date'),
        use_container_width=True,
        height=300
    )

# ===============================
# ğŸ” ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù† Ù…Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ
# ===============================
def check_events_and_corrections(all_sheets):
    """ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù† Ø¨ÙˆØ§Ø¬Ù‡Ø© Ù…Ø¨Ø³Ø·Ø© ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ© Ù…Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ"""
    if not all_sheets:
        st.error("âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ø´ÙŠØªØ§Øª.")
        return
    
    # ØªÙ‡ÙŠØ¦Ø© session state
    if "search_params" not in st.session_state:
        st.session_state.search_params = {
            "card_numbers": "",
            "date_range": "",
            "tech_names": "",
            "search_text": "",
            "exact_match": False,
            "include_empty": True,
            "sort_by": "Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©"
        }
    
    if "search_triggered" not in st.session_state:
        st.session_state.search_triggered = False
    
    # Ù‚Ø³Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    with st.container():
        st.markdown("### ğŸ” Ø¨Ø­Ø« Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            with st.expander("ğŸ”¢ **Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª**", expanded=True):
                card_numbers = st.text_input(
                    "Ù…Ø«Ø§Ù„: 1,3,5 Ø£Ùˆ 1-5 Ø£Ùˆ 2,4,7-10",
                    value=st.session_state.search_params.get("card_numbers", ""),
                    key="input_cards",
                    placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª"
                )
            
            with st.expander("ğŸ“… **Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®**", expanded=True):
                date_input = st.text_input(
                    "Ù…Ø«Ø§Ù„: 2024 Ø£Ùˆ 1/2024 Ø£Ùˆ 2024,2025",
                    value=st.session_state.search_params.get("date_range", ""),
                    key="input_date",
                    placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®"
                )
        
        with col2:
            with st.expander("ğŸ‘¨â€ğŸ”§ **ÙÙ†ÙŠÙˆ Ø§Ù„Ø®Ø¯Ù…Ø©**", expanded=True):
                tech_names = st.text_input(
                    "Ù…Ø«Ø§Ù„: Ø£Ø­Ù…Ø¯, Ù…Ø­Ù…Ø¯, Ø¹Ù„ÙŠ",
                    value=st.session_state.search_params.get("tech_names", ""),
                    key="input_techs",
                    placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„ÙÙ†ÙŠÙŠÙ†"
                )
            
            with st.expander("ğŸ“ **Ù†Øµ Ø§Ù„Ø¨Ø­Ø«**", expanded=True):
                search_text = st.text_input(
                    "Ù…Ø«Ø§Ù„: ØµÙŠØ§Ù†Ø©, Ø¥ØµÙ„Ø§Ø­, ØªØºÙŠÙŠØ±",
                    value=st.session_state.search_params.get("search_text", ""),
                    key="input_text",
                    placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ"
                )
        
        # Ø®ÙŠØ§Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
        with st.expander("âš™ **Ø®ÙŠØ§Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©**", expanded=False):
            col_adv1, col_adv2, col_adv3 = st.columns(3)
            with col_adv1:
                search_mode = st.radio(
                    "ğŸ” Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¨Ø­Ø«:",
                    ["Ø¨Ø­Ø« Ø¬Ø²Ø¦ÙŠ", "Ù…Ø·Ø§Ø¨Ù‚Ø© ÙƒØ§Ù…Ù„Ø©"],
                    index=0 if not st.session_state.search_params.get("exact_match") else 1,
                    key="radio_search_mode"
                )
            with col_adv2:
                include_empty = st.checkbox(
                    "ğŸ” ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ÙØ§Ø±ØºØ©",
                    value=st.session_state.search_params.get("include_empty", True),
                    key="checkbox_include_empty"
                )
            with col_adv3:
                sort_by = st.selectbox(
                    "ğŸ“Š ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:",
                    ["Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©"],
                    index=["Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©"].index(
                        st.session_state.search_params.get("sort_by", "Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©")
                    ),
                    key="select_sort_by"
                )
        
        # Ø£Ø²Ø±Ø§Ø± Ø§Ù„Ø¨Ø­Ø«
        st.markdown("---")
        col_btn1, col_btn2, col_btn3 = st.columns([2, 1, 1])
        with col_btn1:
            search_clicked = st.button(
                "ğŸ” **Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø­Ø«**",
                type="primary",
                use_container_width=True,
                key="main_search_btn"
            )
        with col_btn2:
            if st.button("ğŸ—‘ **Ù…Ø³Ø­ Ø§Ù„Ø­Ù‚ÙˆÙ„**", use_container_width=True, key="clear_fields"):
                st.session_state.search_params = {
                    "card_numbers": "",
                    "date_range": "",
                    "tech_names": "",
                    "search_text": "",
                    "exact_match": False,
                    "include_empty": True,
                    "sort_by": "Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©"
                }
                st.session_state.search_triggered = False
                st.rerun()
        with col_btn3:
            if st.button("ğŸ“Š **Ø¹Ø±Ø¶ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**", use_container_width=True, key="show_all"):
                st.session_state.search_params = {
                    "card_numbers": "",
                    "date_range": "",
                    "tech_names": "",
                    "search_text": "",
                    "exact_match": False,
                    "include_empty": True,
                    "sort_by": "Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©"
                }
                st.session_state.search_triggered = True
                st.rerun()
    
    # ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«
    if card_numbers != st.session_state.search_params.get("card_numbers", ""):
        st.session_state.search_params["card_numbers"] = card_numbers
    
    if date_input != st.session_state.search_params.get("date_range", ""):
        st.session_state.search_params["date_range"] = date_input
    
    if tech_names != st.session_state.search_params.get("tech_names", ""):
        st.session_state.search_params["tech_names"] = tech_names
    
    if search_text != st.session_state.search_params.get("search_text", ""):
        st.session_state.search_params["search_text"] = search_text
    
    st.session_state.search_params["exact_match"] = (search_mode == "Ù…Ø·Ø§Ø¨Ù‚Ø© ÙƒØ§Ù…Ù„Ø©")
    st.session_state.search_params["include_empty"] = include_empty
    st.session_state.search_params["sort_by"] = sort_by
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨Ø­Ø«
    if search_clicked or st.session_state.search_triggered:
        st.session_state.search_triggered = True
        
        search_params = st.session_state.search_params.copy()
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø­Ø«
        search_results = perform_advanced_search(search_params, all_sheets)
        
        if search_results is not None and not search_results.empty:
            display_search_results(search_results, search_params)
            
            # Ø¥Ø¶Ø§ÙØ© Ù‚Ø³Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ
            add_time_analysis_section(search_results)
        else:
            st.warning("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ ØªØ·Ø§Ø¨Ù‚ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«")

def perform_advanced_search(search_params, all_sheets):
    """ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    all_results = []
    
    for sheet_name in all_sheets.keys():
        if sheet_name == "ServicePlan":
            continue
        
        card_num_match = re.search(r'Card(\d+)', sheet_name)
        if not card_num_match:
            continue
            
        card_num = int(card_num_match.group(1))
        
        target_card_numbers = parse_card_numbers(search_params["card_numbers"])
        if target_card_numbers and card_num not in target_card_numbers:
            continue
        
        df = all_sheets[sheet_name].copy()
        
        target_techs = []
        if search_params["tech_names"]:
            techs = search_params["tech_names"].split(',')
            target_techs = [tech.strip().lower() for tech in techs if tech.strip()]
        
        target_dates = []
        if search_params["date_range"]:
            dates = search_params["date_range"].split(',')
            target_dates = [date.strip().lower() for date in dates if date.strip()]
        
        search_terms = []
        if search_params["search_text"]:
            terms = search_params["search_text"].split(',')
            search_terms = [term.strip().lower() for term in terms if term.strip()]
        
        for _, row in df.iterrows():
            if not check_row_criteria(row, df, card_num, target_techs, target_dates, search_terms, search_params):
                continue
            
            result = extract_row_data(row, df, card_num)
            if result:
                all_results.append(result)
    
    if all_results:
        result_df = pd.DataFrame(all_results)
        return result_df
    return pd.DataFrame()

def parse_card_numbers(card_numbers_str):
    """ØªØ­Ù„ÙŠÙ„ Ø³Ù„Ø³Ù„Ø© Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø£Ø±Ù‚Ø§Ù…"""
    if not card_numbers_str:
        return set()
    
    numbers = set()
    
    try:
        parts = card_numbers_str.split(',')
        for part in parts:
            part = part.strip()
            if '-' in part:
                try:
                    start_str, end_str = part.split('-')
                    start = int(start_str.strip())
                    end = int(end_str.strip())
                    numbers.update(range(start, end + 1))
                except:
                    continue
            else:
                try:
                    num = int(part)
                    numbers.add(num)
                except:
                    continue
    except:
        return set()
    
    return numbers

def check_row_criteria(row, df, card_num, target_techs, target_dates, search_terms, search_params):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØµÙ Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«"""
    
    if target_techs:
        row_tech = get_servised_by_value(row).lower()
        if row_tech == "-" and not search_params["include_empty"]:
            return False
        
        tech_match = False
        if row_tech != "-":
            for tech in target_techs:
                if search_params["exact_match"]:
                    if tech == row_tech:
                        tech_match = True
                        break
                else:
                    if tech in row_tech:
                        tech_match = True
                        break
        
        if not tech_match:
            return False
    
    if target_dates:
        row_date = str(row.get("Date", "")).strip().lower() if pd.notna(row.get("Date")) else ""
        if not row_date and not search_params["include_empty"]:
            return False
        
        date_match = False
        if row_date:
            for date_term in target_dates:
                if search_params["exact_match"]:
                    if date_term == row_date:
                        date_match = True
                        break
                else:
                    if date_term in row_date:
                        date_match = True
                        break
        
        if not date_match:
            return False
    
    if search_terms:
        row_event, row_correction = extract_event_correction(row, df)
        row_event_lower = row_event.lower()
        row_correction_lower = row_correction.lower()
        
        if not row_event and not row_correction and not search_params["include_empty"]:
            return False
        
        text_match = False
        combined_text = f"{row_event_lower} {row_correction_lower}"
        
        for term in search_terms:
            if search_params["exact_match"]:
                if term == row_event_lower or term == row_correction_lower:
                    text_match = True
                    break
            else:
                if term in combined_text:
                    text_match = True
                    break
        
        if not text_match:
            return False
    
    return True

def extract_event_correction(row, df):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ø¯Ø« ÙˆØ§Ù„ØªØµØ­ÙŠØ­ Ù…Ù† Ø§Ù„ØµÙ"""
    event_value = "-"
    correction_value = "-"
    
    for col in df.columns:
        col_normalized = normalize_name(col)
        if "event" in col_normalized or "Ø§Ù„Ø­Ø¯Ø«" in col_normalized:
            if col in row and pd.notna(row[col]) and str(row[col]).strip() != "":
                event_value = str(row[col]).strip()
        
        if "correction" in col_normalized or "ØªØµØ­ÙŠØ­" in col_normalized:
            if col in row and pd.notna(row[col]) and str(row[col]).strip() != "":
                correction_value = str(row[col]).strip()
    
    return event_value, correction_value

def extract_row_data(row, df, card_num):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙ"""
    card_num_value = str(row.get("card", "")).strip() if pd.notna(row.get("card")) else str(card_num)
    date = str(row.get("Date", "")).strip() if pd.notna(row.get("Date")) else "-"
    tones = str(row.get("Tones", "")).strip() if pd.notna(row.get("Tones")) else "-"
    
    event_value, correction_value = extract_event_correction(row, df)
    
    if (event_value == "-" and correction_value == "-" and date == "-" and tones == "-"):
        return None
    
    servised_by_value = get_servised_by_value(row)
    
    return {
        "Card Number": card_num_value,
        "Event": event_value,
        "Correction": correction_value,
        "Servised by": servised_by_value,
        "Tones": tones,
        "Date": date
    }

def display_search_results(results, search_params):
    """Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø¨Ø´ÙƒÙ„ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…Ø¹ ØªØ±ØªÙŠØ¨ Ù…ØªØ³Ù„Ø³Ù„"""
    if results.empty:
        st.warning("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ø¹Ø±Ø¶Ù‡Ø§")
        return
    
    display_df = results.copy()
    
    display_df['Card_Number_Clean'] = pd.to_numeric(display_df['Card Number'], errors='coerce')
    display_df['Date_Clean'] = pd.to_datetime(display_df['Date'], errors='coerce', dayfirst=True)
    
    if search_params["sort_by"] == "Ø§Ù„ØªØ§Ø±ÙŠØ®":
        display_df = display_df.sort_values(by=['Date_Clean', 'Card_Number_Clean'], 
                                          ascending=[False, True], na_position='last')
    elif search_params["sort_by"] == "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©":
        display_df = display_df.sort_values(by=['Servised by', 'Card_Number_Clean', 'Date_Clean'], 
                                          ascending=[True, True, False], na_position='last')
    else:
        display_df = display_df.sort_values(by=['Card_Number_Clean', 'Date_Clean'], 
                                          ascending=[True, False], na_position='last')
    
    display_df['Event_Order'] = display_df.groupby('Card Number').cumcount() + 1
    display_df['Total_Events'] = display_df.groupby('Card Number')['Card Number'].transform('count')
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    st.markdown("### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“‹ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", len(display_df))
    
    with col2:
        unique_machines = display_df["Card Number"].nunique()
        st.metric("ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª", unique_machines)
    
    with col3:
        if not display_df.empty:
            machine_counts = display_df.groupby('Card Number').size()
            multi_event_machines = (machine_counts > 1).sum()
            st.metric("ğŸ”¢ Ù…ÙƒÙ† Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", multi_event_machines)
        else:
            st.metric("ğŸ”¢ Ù…ÙƒÙ† Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", 0)
    
    with col4:
        if 'Correction' in display_df.columns:
            with_correction = display_df[display_df["Correction"] != "-"].shape[0]
            st.metric("âœ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªØµØ­ÙŠØ­", with_correction)
        else:
            st.metric("âœ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªØµØ­ÙŠØ­", 0)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    st.markdown("### ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© (Ù…Ø±ØªØ¨Ø©)")
    
    if not display_df.empty:
        display_tabs = st.tabs(["ğŸ“Š Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ÙŠ", "ğŸ“‹ Ø¹Ø±Ø¶ ØªÙØµÙŠÙ„ÙŠ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©"])
        
        with display_tabs[0]:
            columns_to_show = ['Card Number', 'Event', 'Correction', 'Servised by', 'Tones', 'Date', 'Event_Order', 'Total_Events']
            columns_to_show = [col for col in columns_to_show if col in display_df.columns]
            
            st.dataframe(
                display_df[columns_to_show].style.apply(style_table, axis=1),
                use_container_width=True,
                height=500
            )
        
        with display_tabs[1]:
            unique_machines = sorted(display_df['Card Number'].unique(), 
                                   key=lambda x: pd.to_numeric(x, errors='coerce') if str(x).isdigit() else float('inf'))
            
            for machine in unique_machines:
                machine_data = display_df[display_df['Card Number'] == machine].copy()
                machine_data = machine_data.sort_values('Event_Order')
                
                with st.expander(f"ğŸ”§ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø© {machine} - Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«: {len(machine_data)}", expanded=len(unique_machines) <= 5):
                    
                    col_stats1, col_stats2, col_stats3 = st.columns(3)
                    with col_stats1:
                        if not machine_data.empty and 'Date' in machine_data.columns:
                            st.metric("ğŸ“… Ø£ÙˆÙ„ Ø­Ø¯Ø«", machine_data['Date'].iloc[0] if machine_data['Date'].iloc[0] != "-" else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
                        else:
                            st.metric("ğŸ“… Ø£ÙˆÙ„ Ø­Ø¯Ø«", "-")
                    with col_stats2:
                        if not machine_data.empty and 'Date' in machine_data.columns:
                            st.metric("ğŸ“… Ø¢Ø®Ø± Ø­Ø¯Ø«", machine_data['Date'].iloc[-1] if machine_data['Date'].iloc[-1] != "-" else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
                        else:
                            st.metric("ğŸ“… Ø¢Ø®Ø± Ø­Ø¯Ø«", "-")
                    with col_stats3:
                        if not machine_data.empty and 'Servised by' in machine_data.columns:
                            tech_count = machine_data['Servised by'].nunique()
                            st.metric("ğŸ‘¨â€ğŸ”§ ÙÙ†ÙŠÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ†", tech_count)
                        else:
                            st.metric("ğŸ‘¨â€ğŸ”§ ÙÙ†ÙŠÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ†", 0)
                    
                    for idx, row in machine_data.iterrows():
                        st.markdown("---")
                        col_event1, col_event2 = st.columns([3, 2])
                        
                        with col_event1:
                            event_order = row.get('Event_Order', '?')
                            total_events = row.get('Total_Events', '?')
                            st.markdown(f"**Ø§Ù„Ø­Ø¯Ø« #{event_order} Ù…Ù† {total_events}**")
                            if 'Date' in row:
                                st.markdown(f"**ğŸ“… Ø§Ù„ØªØ§Ø±ÙŠØ®:** {row['Date']}")
                            if 'Event' in row and row['Event'] != '-':
                                st.markdown(f"**ğŸ“ Ø§Ù„Ø­Ø¯Ø«:** {row['Event']}")
                            if 'Correction' in row and row['Correction'] != '-':
                                st.markdown(f"**âœ Ø§Ù„ØªØµØ­ÙŠØ­:** {row['Correction']}")
                        
                        with col_event2:
                            if 'Servised by' in row and row['Servised by'] != '-':
                                st.markdown(f"**ğŸ‘¨â€ğŸ”§ ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©:** {row['Servised by']}")
                            if 'Tones' in row and row['Tones'] != '-':
                                st.markdown(f"**âš–ï¸ Ø§Ù„Ø£Ø·Ù†Ø§Ù†:** {row['Tones']}")
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ±
    st.markdown("---")
    st.markdown("### ğŸ’¾ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ±")
    
    export_col1, export_col2 = st.columns(2)
    
    with export_col1:
        if not results.empty:
            buffer_excel = io.BytesIO()
            export_df = results.copy()
            
            export_df['Card_Number_Clean_Export'] = pd.to_numeric(export_df['Card Number'], errors='coerce')
            export_df['Date_Clean_Export'] = pd.to_datetime(export_df['Date'], errors='coerce', dayfirst=True)
            
            export_df = export_df.sort_values(by=['Card_Number_Clean_Export', 'Date_Clean_Export'], 
                                             ascending=[True, False], na_position='last')
            
            export_df = export_df.drop(['Card_Number_Clean_Export', 'Date_Clean_Export'], axis=1, errors='ignore')
            
            export_df.to_excel(buffer_excel, index=False, engine="openpyxl")
            
            st.download_button(
                label="ğŸ“Š Ø­ÙØ¸ ÙƒÙ…Ù„Ù Excel",
                data=buffer_excel.getvalue(),
                file_name=f"Ø¨Ø­Ø«_Ø£Ø­Ø¯Ø§Ø«_Ù…Ø±ØªØ¨_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        else:
            st.info("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØµØ¯ÙŠØ±")
    
    with export_col2:
        if not results.empty:
            buffer_csv = io.BytesIO()
            export_csv = results.copy()
            
            export_csv['Card_Number_Clean_Export'] = pd.to_numeric(export_csv['Card Number'], errors='coerce')
            export_csv['Date_Clean_Export'] = pd.to_datetime(export_csv['Date'], errors='coerce', dayfirst=True)
            
            export_csv = export_csv.sort_values(by=['Card_Number_Clean_Export', 'Date_Clean_Export'], 
                                               ascending=[True, False], na_position='last')
            
            export_csv = export_csv.drop(['Card_Number_Clean_Export', 'Date_Clean_Export'], axis=1, errors='ignore')
            
            export_csv.to_csv(buffer_csv, index=False, encoding='utf-8-sig')
            
            st.download_button(
                label="ğŸ“„ Ø­ÙØ¸ ÙƒÙ…Ù„Ù CSV",
                data=buffer_csv.getvalue(),
                file_name=f"Ø¨Ø­Ø«_Ø£Ø­Ø¯Ø§Ø«_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        else:
            st.info("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØµØ¯ÙŠØ±")

def add_time_analysis_section(results_df: pd.DataFrame):
    """Ø¥Ø¶Ø§ÙØ© Ù‚Ø³Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ"""
    st.markdown("---")
    st.markdown("## â±ï¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ Ù„Ù„Ø£Ø­Ø¯Ø§Ø«")
    
    analysis_tabs = st.tabs([
        "ğŸ” ØªØ­Ù„ÙŠÙ„ Ø­Ø¯Ø« Ù…Ø­Ø¯Ø¯",
        "ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø¹Ø¯Ø© Ø£Ø­Ø¯Ø§Ø«",
        "ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©"
    ])
    
    with analysis_tabs[0]:
        analyze_single_event(results_df)
    
    with analysis_tabs[1]:
        compare_multiple_events(results_df)
    
    with analysis_tabs[2]:
        show_general_statistics(results_df)

def analyze_single_event(results_df: pd.DataFrame):
    """ØªØ­Ù„ÙŠÙ„ Ø­Ø¯Ø« Ù…Ø¹ÙŠÙ†"""
    st.markdown("#### ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ø­Ø¯Ø« Ù…Ø¹ÙŠÙ†")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        event_name = st.text_input(
            "Ø§Ø³Ù… Ø§Ù„Ø­Ø¯Ø« Ù„Ù„ØªØ­Ù„ÙŠÙ„:",
            placeholder="Ø£Ø¯Ø®Ù„ ÙƒÙ„Ù…Ø© Ø£Ùˆ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø­Ø¯Ø« (Ù…Ø«Ø§Ù„: Ø³ÙŠØ±ØŒ Ù…Ø­Ø±ÙƒØŒ ØµÙŠØ§Ù†Ø©)",
            key="event_name_input"
        )
    
    with col2:
        if st.button("ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©", key="extract_common_events"):
            common_events = extract_common_events(results_df)
            if common_events:
                st.session_state.common_events = common_events
                st.rerun()
    
    if 'common_events' in st.session_state:
        st.markdown("##### ğŸ“‹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©:")
        common_cols = st.columns(3)
        for idx, (event, count) in enumerate(st.session_state.common_events[:6]):
            with common_cols[idx % 3]:
                if st.button(f"{event} ({count})", key=f"common_{idx}"):
                    st.session_state.event_name_input = event
                    st.rerun()
    
    if event_name and st.button("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©", type="primary"):
        with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©..."):
            analysis_result = EventTimeAnalyzer.analyze_event_time_intervals(results_df, event_name)
            st.session_state.event_analysis = analysis_result
    
    if st.session_state.get("event_analysis"):
        display_time_analysis(st.session_state.event_analysis)

def extract_common_events(results_df: pd.DataFrame, top_n: int = 10) -> List[tuple]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹"""
    if results_df.empty or 'Event' not in results_df.columns:
        return []
    
    all_events = results_df['Event'].dropna().astype(str)
    word_counts = {}
    
    for event in all_events:
        words = re.findall(r'[\u0600-\u06FFa-zA-Z]+', event)
        for word in words:
            if len(word) > 2:
                word_counts[word] = word_counts.get(word, 0) + 1
    
    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
    return sorted_words[:top_n]

def compare_multiple_events(results_df: pd.DataFrame):
    """Ù…Ù‚Ø§Ø±Ù†Ø© Ø¹Ø¯Ø© Ø£Ø­Ø¯Ø§Ø«"""
    st.markdown("#### ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ø¹Ø¯Ø© Ø£Ø­Ø¯Ø§Ø«")
    
    events_input = st.text_area(
        "Ø£Ø¯Ø®Ù„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© (Ù…ÙØµÙˆÙ„Ø© Ø¨ÙØ§ØµÙ„Ø©):",
        placeholder="Ù…Ø«Ø§Ù„: Ø³ÙŠØ±, Ù…Ø­Ø±Ùƒ, ØµÙŠØ§Ù†Ø©, ØªØºÙŠÙŠØ± Ø²ÙŠØª",
        height=100,
        key="multiple_events_input"
    )
    
    if events_input and st.button("ğŸ“ˆ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", type="primary"):
        event_list = [e.strip() for e in events_input.split(',') if e.strip()]
        
        if len(event_list) >= 2:
            with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ ÙˆÙ…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø­Ø¯Ø§Ø«..."):
                comparison_result = EventTimeAnalyzer.analyze_multiple_events(results_df, event_list)
                
                if comparison_result and comparison_result.get('comparison_data'):
                    display_comparison_results(comparison_result, results_df)
                else:
                    st.warning("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
        else:
            st.warning("âš  Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø­Ø¯Ø«ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")

def display_comparison_results(comparison_result: Dict[str, Any], results_df: pd.DataFrame):
    """Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©"""
    comparison_data = comparison_result['comparison_data']
    
    st.markdown(f"##### ğŸ“‹ Ù†ØªØ§Ø¦Ø¬ Ù…Ù‚Ø§Ø±Ù†Ø© {len(comparison_data)} Ø­Ø¯Ø«")
    
    comp_df = pd.DataFrame(comparison_data)
    st.dataframe(
        comp_df.sort_values('Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£ÙŠØ§Ù…'),
        use_container_width=True
    )
    
    # Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    try:
        import plotly.express as px
        
        fig = px.bar(
            comp_df,
            x='Ø§Ù„Ø­Ø¯Ø«',
            y='Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£ÙŠØ§Ù…',
            color='Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª',
            title='Ù…Ù‚Ø§Ø±Ù†Ø© Ù…ØªÙˆØ³Ø· Ø§Ù„ÙØªØ±Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ù„Ø£Ø­Ø¯Ø§Ø«',
            labels={'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£ÙŠØ§Ù…': 'Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£ÙŠØ§Ù… Ø¨ÙŠÙ† Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª', 'Ø§Ù„Ø­Ø¯Ø«': 'Ø§Ù„Ø­Ø¯Ø«'},
            hover_data=['Ø£Ù‚ØµØ± ÙØªØ±Ø©', 'Ø£Ø·ÙˆÙ„ ÙØªØ±Ø©', 'Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ']
        )
        fig.update_layout(
            xaxis_title="Ø§Ù„Ø­Ø¯Ø«",
            yaxis_title="Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£ÙŠØ§Ù…",
            showlegend=True
        )
        st.plotly_chart(fig, use_container_width=True)
        
    except ImportError:
        st.info("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙƒØªØ¨Ø© plotly. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ«Ø¨ÙŠØªÙ‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…: pip install plotly")

def show_general_statistics(results_df: pd.DataFrame):
    """Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©"""
    st.markdown("#### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø© Ù„Ù„Ø£Ø­Ø¯Ø§Ø«")
    
    if results_df.empty:
        st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª")
        return
    
    total_events = len(results_df)
    unique_machines = results_df['Card Number'].nunique()
    events_with_dates = results_df['Date'].notna().sum()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“‹ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", total_events)
    
    with col2:
        st.metric("ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª", unique_machines)
    
    with col3:
        events_per_machine = total_events / unique_machines if unique_machines > 0 else 0
        st.metric("ğŸ“Š Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø­Ø¯Ø§Ø«/Ù…Ø§ÙƒÙŠÙ†Ø©", f"{events_per_machine:.1f}")
    
    with col4:
        st.metric("ğŸ“… Ø£Ø­Ø¯Ø§Ø« Ø¨ØªØ§Ø±ÙŠØ®", events_with_dates)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹
    st.markdown("##### ğŸ”„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹")
    
    if 'Event' in results_df.columns:
        top_events = results_df['Event'].value_counts().head(10).reset_index()
        top_events.columns = ['Ø§Ù„Ø­Ø¯Ø«', 'Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª']
        
        st.dataframe(top_events, use_container_width=True)

# ===============================
# ğŸ–¥ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ===============================
def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚"""
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
    st.set_page_config(page_title=APP_CONFIG["APP_TITLE"], layout="wide")
    
    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        render_sidebar()
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    all_sheets = load_all_sheets()
    sheets_edit = load_sheets_for_edit()
    
    # Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
    st.title(f"{APP_CONFIG['APP_ICON']} {APP_CONFIG['APP_TITLE']}")
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª
    username = st.session_state.get("username")
    user_role = st.session_state.get("user_role", "viewer")
    user_permissions = st.session_state.get("user_permissions", ["view"])
    permissions = get_user_permissions(user_role, user_permissions)
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª
    render_tabs_based_on_permissions(all_sheets, sheets_edit, permissions)

def render_sidebar():
    """Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ"""
    st.header("ğŸ‘¤ Ø§Ù„Ø¬Ù„Ø³Ø©")
    
    if not st.session_state.get("logged_in"):
        if not login_ui():
            st.stop()
    else:
        state = cleanup_sessions(load_state())
        username = st.session_state.username
        user_role = st.session_state.user_role
        rem = remaining_time(state, username)
        
        if rem:
            mins, secs = divmod(int(rem.total_seconds()), 60)
            st.success(f"ğŸ‘‹ {username} | Ø§Ù„Ø¯ÙˆØ±: {user_role} | â³ {mins:02d}:{secs:02d}")
        else:
            logout_action()
    
    st.markdown("---")
    st.write("ğŸ”§ Ø£Ø¯ÙˆØ§Øª:")
    
    if st.button("ğŸ”„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„Ù Ù…Ù† GitHub", key="refresh_github"):
        if fetch_from_github_requests():
            st.rerun()
    
    if st.button("ğŸ—‘ Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´", key="clear_cache"):
        try:
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´: {e}")
    
    if st.button("ğŸ”„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ù„Ø³Ø©", key="refresh_session"):
        users = load_users()
        username = st.session_state.get("username")
        if username and username in users:
            st.session_state.user_role = users[username].get("role", "viewer")
            st.session_state.user_permissions = users[username].get("permissions", ["view"])
            st.success("âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©!")
            st.rerun()
        else:
            st.warning("âš  Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ù„Ø³Ø©.")
    
    if st.session_state.get("unsaved_changes", {}):
        unsaved_count = sum(1 for v in st.session_state.unsaved_changes.values() if v)
        if unsaved_count > 0:
            st.markdown("---")
            st.warning(f"âš  Ù„Ø¯ÙŠÙƒ {unsaved_count} Ø´ÙŠØª Ø¨Ù‡ ØªØºÙŠÙŠØ±Ø§Øª ØºÙŠØ± Ù…Ø­ÙÙˆØ¸Ø©")
            if st.button("ğŸ’¾ Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª", key="save_all_changes", type="primary"):
                st.session_state["save_all_requested"] = True
                st.rerun()
    
    st.markdown("---")
    if st.button("ğŸšª ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬", key="logout_btn"):
        logout_action()

def render_tabs_based_on_permissions(all_sheets, sheets_edit, permissions):
    """Ø¹Ø±Ø¶ Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª"""
    if permissions["can_manage_users"]:  # admin
        tabs = st.tabs(APP_CONFIG["CUSTOM_TABS"])
        
        # Tab 1: ÙØ­Øµ Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³
        with tabs[0]:
            render_service_check_tab(all_sheets)
        
        # Tab 2: ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†
        with tabs[1]:
            render_event_check_tab(all_sheets)
        
        # Tab 3: ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        with tabs[2]:
            render_data_management_tab(sheets_edit, permissions)
        
        # Tab 4: Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
        with tabs[3]:
            render_user_management_tab()
        
        # Tab 5: Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ
        if APP_CONFIG["SHOW_TECH_SUPPORT_TO_ALL"] or permissions["can_manage_users"]:
            with tabs[4]:
                render_tech_support_tab()
    
    elif permissions["can_edit"]:  # editor
        tabs = st.tabs([
            "ğŸ“Š ÙØ­Øµ Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³", 
            "ğŸ“‹ ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†", 
            "ğŸ›  ØªØ¹Ø¯ÙŠÙ„ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
        ])
        
        with tabs[0]:
            render_service_check_tab(all_sheets)
        
        with tabs[1]:
            render_event_check_tab(all_sheets)
        
        with tabs[2]:
            render_data_management_tab(sheets_edit, permissions)
    
    else:  # viewer
        tabs = st.tabs([
            "ğŸ“Š ÙØ­Øµ Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³", 
            "ğŸ“‹ ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†"
        ])
        
        with tabs[0]:
            render_service_check_tab(all_sheets)
        
        with tabs[1]:
            render_event_check_tab(all_sheets)

def render_service_check_tab(all_sheets):
    """Ø¹Ø±Ø¶ ØªØ¨ÙˆÙŠØ¨ ÙØ­Øµ Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³"""
    st.header("ğŸ“Š ÙØ­Øµ Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³")
    
    if all_sheets is None:
        st.warning("â— Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ø³ØªØ®Ø¯Ù… Ø²Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† GitHub.")
    else:
        col1, col2 = st.columns(2)
        with col1:
            card_num = st.number_input("Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©:", min_value=1, step=1, key="card_num_service")
        with col2:
            current_tons = st.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ù†Ø§Ù† Ø§Ù„Ø­Ø§Ù„ÙŠØ©:", min_value=0, step=100, key="current_tons_service")

        if st.button("Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙŠØ±ÙÙŠØ³", key="show_service"):
            st.session_state["show_service_results"] = True

        if st.session_state.get("show_service_results", False):
            check_service_status(card_num, current_tons, all_sheets)

def render_event_check_tab(all_sheets):
    """Ø¹Ø±Ø¶ ØªØ¨ÙˆÙŠØ¨ ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†"""
    st.header("ğŸ“‹ ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†")
    
    if all_sheets is None:
        st.warning("â— Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ø³ØªØ®Ø¯Ù… Ø²Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† GitHub.")
    else:
        check_events_and_corrections(all_sheets)

def render_data_management_tab(sheets_edit, permissions):
    """Ø¹Ø±Ø¶ ØªØ¨ÙˆÙŠØ¨ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    st.header("ğŸ›  ØªØ¹Ø¯ÙŠÙ„ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    token_exists = bool(st.secrets.get("github", {}).get("token", None))
    can_push = token_exists and GITHUB_AVAILABLE

    if sheets_edit is None:
        st.warning("â— Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ø¶ØºØ· ØªØ­Ø¯ÙŠØ« Ù…Ù† GitHub ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ø£ÙˆÙ„Ù‹Ø§.")
    else:
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "Ø¹Ø±Ø¶ ÙˆØªØ¹Ø¯ÙŠÙ„ Ø´ÙŠØª",
            "Ø¥Ø¶Ø§ÙØ© ØµÙ Ø¬Ø¯ÙŠØ¯", 
            "Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯",
            "â• Ø¥Ø¶Ø§ÙØ© Ø­Ø¯Ø« Ø¬Ø¯ÙŠØ¯",
            "âœ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø­Ø¯Ø«"
        ])

        with tab1:
            if st.session_state.get("save_all_requested", False):
                st.info("ğŸ’¾ Ø¬Ø§Ø±ÙŠ Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª...")
                st.session_state["save_all_requested"] = False
            
            sheets_edit = edit_sheet_with_save_button(sheets_edit)

        with tab2:
            st.subheader("â• Ø¥Ø¶Ø§ÙØ© ØµÙ Ø¬Ø¯ÙŠØ¯")
            sheet_name_add = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØª Ù„Ø¥Ø¶Ø§ÙØ© ØµÙ:", list(sheets_edit.keys()), key="add_sheet")
            df_add = sheets_edit[sheet_name_add].astype(str).reset_index(drop=True)
            
            st.markdown("Ø£Ø¯Ø®Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯:")

            new_data = {}
            cols = st.columns(3)
            for i, col in enumerate(df_add.columns):
                with cols[i % 3]:
                    new_data[col] = st.text_input(f"{col}", key=f"add_{sheet_name_add}_{col}")

            col_btn1, col_btn2 = st.columns(2)
            with col_btn1:
                if st.button("ğŸ’¾ Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯", key=f"add_row_{sheet_name_add}", type="primary"):
                    new_row_df = pd.DataFrame([new_data]).astype(str)
                    df_new = pd.concat([df_add, new_row_df], ignore_index=True)
                    
                    sheets_edit[sheet_name_add] = df_new.astype(object)

                    new_sheets = auto_save_to_github(
                        sheets_edit,
                        f"Ø¥Ø¶Ø§ÙØ© ØµÙ Ø¬Ø¯ÙŠØ¯ ÙÙŠ {sheet_name_add}"
                    )
                    if new_sheets is not None:
                        sheets_edit = new_sheets
                        st.success("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­!")
                        st.rerun()
            
            with col_btn2:
                if st.button("ğŸ—‘ Ù…Ø³Ø­ Ø§Ù„Ø­Ù‚ÙˆÙ„", key=f"clear_{sheet_name_add}"):
                    st.rerun()

        with tab3:
            st.subheader("ğŸ†• Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯")
            sheet_name_col = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØª Ù„Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯:", list(sheets_edit.keys()), key="add_col_sheet")
            df_col = sheets_edit[sheet_name_col].astype(str)
            
            new_col_name = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯:", key="new_col_name")
            default_value = st.text_input("Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„ÙƒÙ„ Ø§Ù„ØµÙÙˆÙ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ):", "", key="default_value")

            col_btn1, col_btn2 = st.columns(2)
            with col_btn1:
                if st.button("ğŸ’¾ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯", key=f"add_col_{sheet_name_col}", type="primary"):
                    if new_col_name:
                        df_col[new_col_name] = default_value
                        sheets_edit[sheet_name_col] = df_col.astype(object)
                        
                        new_sheets = auto_save_to_github(
                            sheets_edit,
                            f"Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯ '{new_col_name}' Ø¥Ù„Ù‰ {sheet_name_col}"
                        )
                        if new_sheets is not None:
                            sheets_edit = new_sheets
                            st.success("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­!")
                            st.rerun()
                    else:
                        st.warning("âš  Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯.")
            
            with col_btn2:
                if st.button("ğŸ—‘ Ù…Ø³Ø­", key=f"clear_col_{sheet_name_col}"):
                    st.rerun()

        with tab4:
            add_new_event(sheets_edit)

        with tab5:
            edit_events_and_corrections(sheets_edit)
    
    return sheets_edit

def render_user_management_tab():
    """Ø¹Ø±Ø¶ ØªØ¨ÙˆÙŠØ¨ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"""
    st.header("ğŸ‘¥ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†")
    manage_users()

def render_tech_support_tab():
    """Ø¹Ø±Ø¶ ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ"""
    st.header("ğŸ“ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ")
    tech_support()

# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
if __name__ == "__main__":
    main()
