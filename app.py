import streamlit as st
import pandas as pd
import json
import os
import io
import requests
import shutil
import re
from datetime import datetime, timedelta
from base64 import b64decode
import uuid

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ PyGithub (Ù„Ø±ÙØ¹ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª)
try:
    from github import Github
    GITHUB_AVAILABLE = True
except Exception:
    GITHUB_AVAILABLE = False

# ===============================
# âš™ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ - ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ Ø¨Ø³Ù‡ÙˆÙ„Ø©
# ===============================
APP_CONFIG = {
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ø§Ù…Ø©
    "APP_TITLE": "CMMS - Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø´Ø§Ù…Ù„",
    "APP_ICON": "ğŸ­",
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª GitHub
    "REPO_NAME": "mahmedabdallh123/Elqds",
    "BRANCH": "main",
    "FILE_PATH": "l4.xlsx",
    "LOCAL_FILE": "l4.xlsx",
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†
    "MAX_ACTIVE_USERS": 5,
    "SESSION_DURATION_MINUTES": 60,
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
    "SHOW_TECH_SUPPORT_TO_ALL": True,
    "CUSTOM_TABS": ["ğŸ“‹ ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†", "ğŸ›  ØªØ¹Ø¯ÙŠÙ„ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "ğŸ“Š ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"],
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØ±
    "IMAGES_FOLDER": "event_images",
    "ALLOWED_IMAGE_TYPES": ["jpg", "jpeg", "png", "gif", "bmp", "webp"],
    "MAX_IMAGE_SIZE_MB": 10,
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    "DEFAULT_COLUMNS": [
        "card", "Date", "Event", "Correction", "Servised by", "Tones", "Images"
    ],
}

# ===============================
# ğŸ—‚ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª
# ===============================
USERS_FILE = "users.json"
STATE_FILE = "state.json"
SESSION_DURATION = timedelta(minutes=APP_CONFIG["SESSION_DURATION_MINUTES"])
MAX_ACTIVE_USERS = APP_CONFIG["MAX_ACTIVE_USERS"]
IMAGES_FOLDER = APP_CONFIG["IMAGES_FOLDER"]

# Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· GitHub ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
GITHUB_EXCEL_URL = f"https://github.com/{APP_CONFIG['REPO_NAME'].split('/')[0]}/{APP_CONFIG['REPO_NAME'].split('/')[1]}/raw/{APP_CONFIG['BRANCH']}/{APP_CONFIG['FILE_PATH']}"
GITHUB_USERS_URL = "https://raw.githubusercontent.com/mahmedabdallh123/Elqds/refs/heads/main/users.json"
GITHUB_REPO_USERS = "mahmedabdallh123/Elqds"

# -------------------------------
# ğŸ§© Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„ØµÙˆØ±
# -------------------------------
def setup_images_folder():
    """Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ±"""
    if not os.path.exists(IMAGES_FOLDER):
        os.makedirs(IMAGES_FOLDER)
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù .gitkeep Ù„Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙØ§Ø±ØºØ§Ù‹ ÙÙŠ GitHub
        with open(os.path.join(IMAGES_FOLDER, ".gitkeep"), "w") as f:
            pass

def save_uploaded_images(uploaded_files):
    """Ø­ÙØ¸ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø© ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª"""
    if not uploaded_files:
        return []
    
    saved_files = []
    for uploaded_file in uploaded_files:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
        file_extension = uploaded_file.name.split('.')[-1].lower()
        if file_extension not in APP_CONFIG["ALLOWED_IMAGE_TYPES"]:
            st.warning(f"âš  ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ù„Ù {uploaded_file.name} Ù„Ø£Ù† Ù†ÙˆØ¹Ù‡ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…")
            continue
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
        file_size_mb = len(uploaded_file.getvalue()) / (1024 * 1024)
        if file_size_mb > APP_CONFIG["MAX_IMAGE_SIZE_MB"]:
            st.warning(f"âš  ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ù„Ù {uploaded_file.name} Ù„Ø£Ù† Ø­Ø¬Ù…Ù‡ ({file_size_mb:.2f}MB) ÙŠØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ ({APP_CONFIG['MAX_IMAGE_SIZE_MB']}MB)")
            continue
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… ÙØ±ÙŠØ¯ Ù„Ù„Ù…Ù„Ù
        unique_id = str(uuid.uuid4())[:8]
        original_name = uploaded_file.name.split('.')[0]
        safe_name = re.sub(r'[^\w\-_]', '_', original_name)
        new_filename = f"{safe_name}_{unique_id}.{file_extension}"
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
        file_path = os.path.join(IMAGES_FOLDER, new_filename)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        saved_files.append(new_filename)
    
    return saved_files

def delete_image_file(image_filename):
    """Ø­Ø°Ù Ù…Ù„Ù ØµÙˆØ±Ø©"""
    try:
        file_path = os.path.join(IMAGES_FOLDER, image_filename)
        if os.path.exists(file_path):
            os.remove(file_path)
            return True
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø§Ù„ØµÙˆØ±Ø© {image_filename}: {e}")
    return False

def get_image_url(image_filename):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ø¹Ø±Ø¶"""
    if not image_filename:
        return None
    
    file_path = os.path.join(IMAGES_FOLDER, image_filename)
    if os.path.exists(file_path):
        return file_path
    return None

def display_images(image_filenames, caption="Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±ÙÙ‚Ø©"):
    """Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± ÙÙŠ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    if not image_filenames:
        return
    
    st.markdown(f"**{caption}:**")
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø©
    images_per_row = 3
    images = image_filenames.split(',') if isinstance(image_filenames, str) else image_filenames
    
    for i in range(0, len(images), images_per_row):
        cols = st.columns(images_per_row)
        for j in range(images_per_row):
            idx = i + j
            if idx < len(images):
                image_filename = images[idx].strip()
                with cols[j]:
                    image_path = get_image_url(image_filename)
                    if image_path and os.path.exists(image_path):
                        try:
                            st.image(image_path, caption=image_filename, use_column_width=True)
                        except:
                            st.write(f"ğŸ“· {image_filename}")
                    else:
                        st.write(f"ğŸ“· {image_filename} (ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯)")

# -------------------------------
# ğŸ§© Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ø­Ø§Ù„Ø©
# -------------------------------
def download_users_from_github():
    """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† GitHub"""
    try:
        response = requests.get(GITHUB_USERS_URL, timeout=10)
        response.raise_for_status()
        users_data = response.json()
        
        # Ø­ÙØ¸ Ù†Ø³Ø®Ø© Ù…Ø­Ù„ÙŠØ©
        with open(USERS_FILE, "w", encoding="utf-8") as f:
            json.dump(users_data, f, indent=4, ensure_ascii=False)
        
        return users_data
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† GitHub: {e}")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
        if os.path.exists(USERS_FILE):
            try:
                with open(USERS_FILE, "r", encoding="utf-8") as f:
                    users_data = json.load(f)
                return users_data
            except:
                pass
        
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        return {
            "admin": {
                "password": "admin123", 
                "role": "admin", 
                "created_at": datetime.now().isoformat(),
                "permissions": ["all"],
                "active": False
            }
        }

def upload_users_to_github(users_data):
    """Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¥Ù„Ù‰ GitHub"""
    try:
        token = st.secrets.get("github", {}).get("token", None)
        if not token:
            st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ GitHub token")
            return False
        
        g = Github(token)
        repo = g.get_repo(GITHUB_REPO_USERS)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ JSON
        users_json = json.dumps(users_data, indent=4, ensure_ascii=False, sort_keys=True)
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„Ù Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        try:
            contents = repo.get_contents("users.json", ref="main")
            result = repo.update_file(
                path="users.json",
                message=f"ØªØ­Ø¯ÙŠØ« Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨ÙˆØ§Ø³Ø·Ø© {st.session_state.get('username', 'admin')} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                content=users_json,
                sha=contents.sha,
                branch="main"
            )
            return True
        except Exception as e:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ Ø£Ù† Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ (404) Ø£Ùˆ SHA ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯
            error_msg = str(e)
            if "404" in error_msg or "sha" in error_msg.lower() or "not found" in error_msg.lower():
                # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
                try:
                    result = repo.create_file(
                        path="users.json",
                        message=f"Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨ÙˆØ§Ø³Ø·Ø© {st.session_state.get('username', 'admin')} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                        content=users_json,
                        branch="main"
                    )
                    return True
                except Exception as create_error:
                    st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¹Ù„Ù‰ GitHub: {create_error}")
                    return False
            else:
                st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¹Ù„Ù‰ GitHub: {e}")
                return False
                
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¥Ù„Ù‰ GitHub: {e}")
        return False

def load_users():
    """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† GitHub"""
    try:
        # Ø£ÙˆÙ„Ø§Ù‹: ØªØ­Ù…ÙŠÙ„ Ù…Ù† GitHub
        users_data = download_users_from_github()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… admin
        if "admin" not in users_data:
            users_data["admin"] = {
                "password": "admin123", 
                "role": "admin", 
                "created_at": datetime.now().isoformat(),
                "permissions": ["all"],
                "active": False
            }
            # Ø­ÙØ¸ Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙÙŠ GitHub
            upload_users_to_github(users_data)
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ù„ÙƒÙ„ Ù…Ø³ØªØ®Ø¯Ù…
        for username, user_data in users_data.items():
            required_fields = ["password", "role", "created_at", "permissions", "active"]
            for field in required_fields:
                if field not in user_data:
                    if field == "password" and username == "admin":
                        user_data[field] = "admin123"
                    elif field == "role" and username == "admin":
                        user_data[field] = "admin"
                    elif field == "role":
                        user_data[field] = "viewer"
                    elif field == "permissions" and username == "admin":
                        user_data[field] = ["all"]
                    elif field == "permissions" and user_data.get("role") == "editor":
                        user_data[field] = ["view", "edit"]
                    elif field == "permissions":
                        user_data[field] = ["view"]
                    elif field == "created_at":
                        user_data[field] = datetime.now().isoformat()
                    elif field == "active":
                        user_data[field] = False
        
        # Ø­ÙØ¸ Ø£ÙŠ ØªØ­Ø¯ÙŠØ«Ø§Øª ÙÙŠ GitHub
        upload_users_to_github(users_data)
        
        return users_data
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†: {e}")
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
        return {
            "admin": {
                "password": "admin123", 
                "role": "admin", 
                "created_at": datetime.now().isoformat(),
                "permissions": ["all"],
                "active": False
            }
        }

def save_users_to_github(users_data):
    """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¥Ù„Ù‰ GitHub"""
    return upload_users_to_github(users_data)

def update_user_in_github(username, user_data):
    """ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø­Ø¯Ø¯ ÙÙŠ GitHub"""
    try:
        users = load_users()
        users[username] = user_data
        return save_users_to_github(users)
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {username}: {e}")
        return False

def add_user_to_github(username, user_data):
    """Ø¥Ø¶Ø§ÙØ© Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯ Ø¥Ù„Ù‰ GitHub"""
    try:
        users = load_users()
        if username in users:
            st.warning(f"âš  Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… '{username}' Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„")
            return False
        users[username] = user_data
        return save_users_to_github(users)
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {username}: {e}")
        return False

def delete_user_from_github(username):
    """Ø­Ø°Ù Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† GitHub"""
    try:
        users = load_users()
        if username in users:
            del users[username]
            return save_users_to_github(users)
        return False
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… {username}: {e}")
        return False

def load_state():
    if not os.path.exists(STATE_FILE):
        with open(STATE_FILE, "w", encoding="utf-8") as f:
            json.dump({}, f, indent=4, ensure_ascii=False)
        return {}
    try:
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {}

def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, indent=4, ensure_ascii=False)

def cleanup_sessions(state):
    now = datetime.now()
    changed = False
    for user, info in list(state.items()):
        if info.get("active") and "login_time" in info:
            try:
                login_time = datetime.fromisoformat(info["login_time"])
                if now - login_time > SESSION_DURATION:
                    info["active"] = False
                    info.pop("login_time", None)
                    changed = True
            except:
                info["active"] = False
                changed = True
    if changed:
        save_state(state)
    return state

def remaining_time(state, username):
    if not username or username not in state:
        return None
    info = state.get(username)
    if not info or not info.get("active"):
        return None
    try:
        lt = datetime.fromisoformat(info["login_time"])
        remaining = SESSION_DURATION - (datetime.now() - lt)
        if remaining.total_seconds() <= 0:
            return None
        return remaining
    except:
        return None

# -------------------------------
# ğŸ” ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬
# -------------------------------
def logout_action():
    state = load_state()
    username = st.session_state.get("username")
    if username and username in state:
        state[username]["active"] = False
        state[username].pop("login_time", None)
        save_state(state)
    keys = list(st.session_state.keys())
    for k in keys:
        st.session_state.pop(k, None)
    st.rerun()

# -------------------------------
# ğŸ§  ÙˆØ§Ø¬Ù‡Ø© ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„
# -------------------------------
def login_ui():
    users = load_users()
    state = cleanup_sessions(load_state())
    if "logged_in" not in st.session_state:
        st.session_state.logged_in = False
        st.session_state.username = None
        st.session_state.user_role = None
        st.session_state.user_permissions = []

    st.title(f"{APP_CONFIG['APP_ICON']} ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ - {APP_CONFIG['APP_TITLE']}")

    # ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† GitHub
    try:
        user_list = list(users.keys())
    except:
        user_list = list(users.keys())

    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    username_input = st.selectbox("ğŸ‘¤ Ø§Ø®ØªØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…", user_list)
    password = st.text_input("ğŸ”‘ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±", type="password")

    active_users = [u for u, v in state.items() if v.get("active")]
    active_count = len(active_users)
    st.caption(f"ğŸ”’ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† Ø§Ù„Ù†Ø´Ø·ÙˆÙ† Ø§Ù„Ø¢Ù†: {active_count} / {MAX_ACTIVE_USERS}")

    if not st.session_state.logged_in:
        if st.button("ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„"):
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† GitHub
            current_users = load_users()
            
            if username_input in current_users and current_users[username_input]["password"] == password:
                if username_input == "admin":
                    pass
                elif username_input in active_users:
                    st.warning("âš  Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø³Ø¬Ù„ Ø¯Ø®ÙˆÙ„ Ø¨Ø§Ù„ÙØ¹Ù„.")
                    return False
                elif active_count >= MAX_ACTIVE_USERS:
                    st.error("ğŸš« Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…ØªØµÙ„ÙŠÙ† Ø­Ø§Ù„ÙŠØ§Ù‹.")
                    return False
                
                state[username_input] = {"active": True, "login_time": datetime.now().isoformat()}
                save_state(state)
                
                st.session_state.logged_in = True
                st.session_state.username = username_input
                st.session_state.user_role = current_users[username_input].get("role", "viewer")
                st.session_state.user_permissions = current_users[username_input].get("permissions", ["view"])
                
                st.success(f"âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„: {username_input} ({st.session_state.user_role})")
                st.rerun()
            else:
                st.error("âŒ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©.")
        return False
    else:
        username = st.session_state.username
        user_role = st.session_state.user_role
        st.success(f"âœ… Ù…Ø³Ø¬Ù„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙƒÙ€: {username} ({user_role})")
        rem = remaining_time(state, username)
        if rem:
            mins, secs = divmod(int(rem.total_seconds()), 60)
            st.info(f"â³ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ: {mins:02d}:{secs:02d}")
        else:
            st.warning("â° Ø§Ù†ØªÙ‡Øª Ø§Ù„Ø¬Ù„Ø³Ø©ØŒ Ø³ÙŠØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬.")
            logout_action()
        if st.button("ğŸšª ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬"):
            logout_action()
        return True

# -------------------------------
# ğŸ”„ Ø·Ø±Ù‚ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù„Ù Ù…Ù† GitHub
# -------------------------------
def fetch_from_github_requests():
    """ØªØ­Ù…ÙŠÙ„ Ø¨Ø¥Ø³ØªØ®Ø¯Ø§Ù… Ø±Ø§Ø¨Ø· RAW (requests)"""
    try:
        response = requests.get(GITHUB_EXCEL_URL, stream=True, timeout=15)
        response.raise_for_status()
        with open(APP_CONFIG["LOCAL_FILE"], "wb") as f:
            shutil.copyfileobj(response.raw, f)
        # Ø§Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
        try:
            st.cache_data.clear()
        except:
            pass
        return True
    except Exception as e:
        st.error(f"âš  ÙØ´Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù…Ù† GitHub: {e}")
        return False

def fetch_from_github_api():
    """ØªØ­Ù…ÙŠÙ„ Ø¹Ø¨Ø± GitHub API (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyGithub token ÙÙŠ secrets)"""
    if not GITHUB_AVAILABLE:
        return fetch_from_github_requests()
    
    try:
        token = st.secrets.get("github", {}).get("token", None)
        if not token:
            return fetch_from_github_requests()
        
        g = Github(token)
        repo = g.get_repo(APP_CONFIG["REPO_NAME"])
        file_content = repo.get_contents(APP_CONFIG["FILE_PATH"], ref=APP_CONFIG["BRANCH"])
        content = b64decode(file_content.content)
        with open(APP_CONFIG["LOCAL_FILE"], "wb") as f:
            f.write(content)
        try:
            st.cache_data.clear()
        except:
            pass
        return True
    except Exception as e:
        st.error(f"âš  ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† GitHub: {e}")
        return False

# -------------------------------
# ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª (Ù…Ø®Ø¨Ø£) - Ù…Ø¹Ø¯Ù„ Ù„Ù‚Ø±Ø§Ø¡Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ø¨Ø´ÙƒÙ„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
# -------------------------------
@st.cache_data(show_spinner=False)
def load_all_sheets():
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ù…Ù† Ù…Ù„Ù Excel Ø¨Ø´ÙƒÙ„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ"""
    if not os.path.exists(APP_CONFIG["LOCAL_FILE"]):
        return None
    
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª
        sheets = pd.read_excel(APP_CONFIG["LOCAL_FILE"], sheet_name=None)
        
        if not sheets:
            return None
        
        # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„ÙƒÙ„ Ø´ÙŠØª
        for name, df in sheets.items():
            if df.empty:
                continue
            df.columns = df.columns.astype(str).str.strip()
            # ØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ù‚ÙŠÙ… NaN Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
            df = df.fillna('')
            sheets[name] = df
        
        return sheets
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª: {e}")
        return None

# Ù†Ø³Ø®Ø© Ù…Ø¹ dtype=object Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ­Ø±ÙŠØ±
@st.cache_data(show_spinner=False)
def load_sheets_for_edit():
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ù„Ù„ØªØ­Ø±ÙŠØ±"""
    if not os.path.exists(APP_CONFIG["LOCAL_FILE"]):
        return None
    
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ù…Ø¹ dtype=object Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        sheets = pd.read_excel(APP_CONFIG["LOCAL_FILE"], sheet_name=None, dtype=object)
        
        if not sheets:
            return None
        
        # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„ÙƒÙ„ Ø´ÙŠØª
        for name, df in sheets.items():
            df.columns = df.columns.astype(str).str.strip()
            # ØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ù‚ÙŠÙ… NaN
            df = df.fillna('')
            sheets[name] = df
        
        return sheets
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª Ù„Ù„ØªØ­Ø±ÙŠØ±: {e}")
        return None

# -------------------------------
# ğŸ” Ø­ÙØ¸ Ù…Ø­Ù„ÙŠ + Ø±ÙØ¹ Ø¹Ù„Ù‰ GitHub + Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´ + Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„
# -------------------------------
def save_local_excel_and_push(sheets_dict, commit_message="Update from Streamlit"):
    """Ø¯Ø§Ù„Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠ ÙˆØ§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ GitHub"""
    # Ø§Ø­ÙØ¸ Ù…Ø­Ù„ÙŠØ§Ù‹
    try:
        with pd.ExcelWriter(APP_CONFIG["LOCAL_FILE"], engine="openpyxl") as writer:
            for name, sh in sheets_dict.items():
                try:
                    sh.to_excel(writer, sheet_name=name, index=False)
                except Exception:
                    sh.astype(object).to_excel(writer, sheet_name=name, index=False)
    except Exception as e:
        st.error(f"âš  Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ù„ÙŠ: {e}")
        return None

    # Ø§Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
    try:
        st.cache_data.clear()
    except:
        pass

    # Ø­Ø§ÙˆÙ„ Ø§Ù„Ø±ÙØ¹ Ø¹Ø¨Ø± PyGithub token ÙÙŠ secrets
    token = st.secrets.get("github", {}).get("token", None)
    if not token:
        st.warning("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ GitHub token. Ø³ÙŠØªÙ… Ø§Ù„Ø­ÙØ¸ Ù…Ø­Ù„ÙŠØ§Ù‹ ÙÙ‚Ø·.")
        return load_sheets_for_edit()

    if not GITHUB_AVAILABLE:
        st.warning("âš  PyGithub ØºÙŠØ± Ù…ØªÙˆÙØ±. Ø³ÙŠØªÙ… Ø§Ù„Ø­ÙØ¸ Ù…Ø­Ù„ÙŠØ§Ù‹ ÙÙ‚Ø·.")
        return load_sheets_for_edit()

    try:
        g = Github(token)
        repo = g.get_repo(APP_CONFIG["REPO_NAME"])
        with open(APP_CONFIG["LOCAL_FILE"], "rb") as f:
            content = f.read()

        try:
            contents = repo.get_contents(APP_CONFIG["FILE_PATH"], ref=APP_CONFIG["BRANCH"])
            result = repo.update_file(path=APP_CONFIG["FILE_PATH"], message=commit_message, content=content, sha=contents.sha, branch=APP_CONFIG["BRANCH"])
            st.success(f"âœ… ØªÙ… Ø§Ù„Ø­ÙØ¸ ÙˆØ§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ GitHub Ø¨Ù†Ø¬Ø§Ø­: {commit_message}")
            return load_sheets_for_edit()
        except Exception as e:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ Ù‡Ù†Ø§Ùƒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ SHA
            error_msg = str(e)
            if "404" in error_msg or "sha" in error_msg.lower():
                try:
                    # Ø­Ø§ÙˆÙ„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯
                    result = repo.create_file(path=APP_CONFIG["FILE_PATH"], message=commit_message, content=content, branch=APP_CONFIG["BRANCH"])
                    st.success(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ø¹Ù„Ù‰ GitHub: {commit_message}")
                    return load_sheets_for_edit()
                except Exception as create_error:
                    st.error(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ø¹Ù„Ù‰ GitHub: {create_error}")
                    return None
            else:
                st.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ GitHub: {e}")
                return None

    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ GitHub: {e}")
        return None

def auto_save_to_github(sheets_dict, operation_description):
    """Ø¯Ø§Ù„Ø© Ø§Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø­Ø³Ù†Ø©"""
    username = st.session_state.get("username", "unknown")
    commit_message = f"{operation_description} by {username} at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    
    result = save_local_excel_and_push(sheets_dict, commit_message)
    if result is not None:
        st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙÙŠ GitHub")
        return result
    else:
        st.error("âŒ ÙØ´Ù„ Ø§Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")
        return sheets_dict

# -------------------------------
# ğŸ§° Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„Ù†ØµÙˆØµ
# -------------------------------
def normalize_name(s):
    if s is None: return ""
    s = str(s).replace("\n", "+")
    s = re.sub(r"[^0-9a-zA-Z\u0600-\u06FF\+\s_/.-]", " ", s)
    s = re.sub(r"\s+", " ", s).strip().lower()
    return s

def split_needed_services(needed_service_str):
    if not isinstance(needed_service_str, str) or needed_service_str.strip() == "":
        return []
    parts = re.split(r"\+|,|\n|;", needed_service_str)
    return [p.strip() for p in parts if p.strip() != ""]

def highlight_cell(val, col_name):
    color_map = {
        "Service Needed": "background-color: #fff3cd; color:#856404; font-weight:bold;",
        "Service Done": "background-color: #d4edda; color:#155724; font-weight:bold;",
        "Service Didn't Done": "background-color: #f8d7da; color:#721c24; font-weight:bold;",
        "Date": "background-color: #e7f1ff; color:#004085; font-weight:bold;",
        "Tones": "background-color: #e8f8f5; color:#0d5c4a; font-weight:bold;",
        "Event": "background-color: #e2f0d9; color:#2e6f32; font-weight:bold;",
        "Correction": "background-color: #fdebd0; color:#7d6608; font-weight:bold;",
        "Servised by": "background-color: #f0f0f0; color:#333; font-weight:bold;",
        "Card Number": "background-color: #ebdef0; color:#4a235a; font-weight:bold;",
        "Images": "background-color: #d6eaf8; color:#1b4f72; font-weight:bold;"
    }
    return color_map.get(col_name, "")

def style_table(row):
    return [highlight_cell(row[col], col) for col in row.index]

def get_user_permissions(user_role, user_permissions):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¯ÙˆØ± ÙˆØ§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª"""
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¯ÙˆØ± adminØŒ ÙŠØ¹Ø·Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª
    if user_role == "admin":
        return {
            "can_view": True,
            "can_edit": True,
            "can_manage_users": True,
            "can_see_tech_support": True,
            "can_manage_sheets": True
        }
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¯ÙˆØ± editor
    elif user_role == "editor":
        return {
            "can_view": True,
            "can_edit": True,
            "can_manage_users": False,
            "can_see_tech_support": False,
            "can_manage_sheets": True
        }
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¯ÙˆØ± viewer Ø£Ùˆ Ø£ÙŠ Ø¯ÙˆØ± Ø¢Ø®Ø±
    else:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„ÙØ±Ø¯ÙŠØ©
        return {
            "can_view": "view" in user_permissions or "edit" in user_permissions or "all" in user_permissions,
            "can_edit": "edit" in user_permissions or "all" in user_permissions,
            "can_manage_users": "manage_users" in user_permissions or "all" in user_permissions,
            "can_see_tech_support": "tech_support" in user_permissions or "all" in user_permissions,
            "can_manage_sheets": "manage_sheets" in user_permissions or "all" in user_permissions
        }

# ===============================
# ğŸ”§ Ø¯ÙˆØ§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©
# ===============================
def extract_sheet_data(df, sheet_name):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø£ÙŠ Ø´ÙŠØª Ø¨Ø´ÙƒÙ„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ"""
    if df.empty:
        return []
    
    results = []
    
    # ØªØ­Ø¯ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù‡Ø§Ù…Ø©
    card_column = None
    date_column = None
    event_column = None
    correction_column = None
    tech_column = None
    images_column = None
    tones_column = None
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    for col in df.columns:
        col_lower = str(col).lower().strip()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©
        if card_column is None and any(keyword in col_lower for keyword in ['card', 'machine', 'Ø±Ù‚Ù…', 'Ù…Ø§ÙƒÙŠÙ†Ø©', 'Ø¬Ù‡Ø§Ø²']):
            card_column = col
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ®
        elif date_column is None and any(keyword in col_lower for keyword in ['date', 'ØªØ§Ø±ÙŠØ®', 'time']):
            date_column = col
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø­Ø¯Ø«
        elif event_column is None and any(keyword in col_lower for keyword in ['event', 'Ø­Ø¯Ø«', 'issue', 'Ù…Ø´ÙƒÙ„Ø©']):
            event_column = col
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØµØ­ÙŠØ­
        elif correction_column is None and any(keyword in col_lower for keyword in ['correction', 'ØªØµØ­ÙŠØ­', 'solution', 'Ø­Ù„']):
            correction_column = col
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ†ÙŠ
        elif tech_column is None and any(keyword in col_lower for keyword in ['servised', 'serviced', 'service', 'technician', 'ÙÙ†ÙŠ', 'Ø®Ø¯Ù…', 'ØªÙ… Ø¨ÙˆØ§Ø³Ø·Ø©']):
            tech_column = col
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„ØµÙˆØ±
        elif images_column is None and any(keyword in col_lower for keyword in ['images', 'pictures', 'ØµÙˆØ±', 'Ù…Ø±ÙÙ‚Ø§Øª']):
            images_column = col
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£Ø·Ù†Ø§Ù†
        elif tones_column is None and any(keyword in col_lower for keyword in ['tones', 'Ø·Ù†', 'Ø£Ø·Ù†Ø§Ù†', 'ton', 'tone']):
            tones_column = col
    
    # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© Ù…Ø¹ÙŠÙ†Ø©ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø§Ù„Ù…ØªØ§Ø­Ø©
    if not card_column and len(df.columns) > 0:
        card_column = df.columns[0]
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† ÙƒÙ„ ØµÙ
    for idx, row in df.iterrows():
        try:
            result = {
                "Sheet Name": sheet_name,
                "Row Index": idx,
                "Card Number": str(row[card_column]) if card_column and card_column in row and pd.notna(row[card_column]) else sheet_name,
                "Date": str(row[date_column]) if date_column and date_column in row and pd.notna(row[date_column]) else "-",
                "Event": str(row[event_column]) if event_column and event_column in row and pd.notna(row[event_column]) else "-",
                "Correction": str(row[correction_column]) if correction_column and correction_column in row and pd.notna(row[correction_column]) else "-",
                "Servised by": str(row[tech_column]) if tech_column and tech_column in row and pd.notna(row[tech_column]) else "-",
                "Tones": str(row[tones_column]) if tones_column and tones_column in row and pd.notna(row[tones_column]) else "-",
                "Images": str(row[images_column]) if images_column and images_column in row and pd.notna(row[images_column]) else ""
            }
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª
            if result["Event"] != "-" or result["Correction"] != "-" or result["Date"] != "-":
                results.append(result)
        except Exception as e:
            # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ Ø¨Ù‡Ø§ Ø£Ø®Ø·Ø§Ø¡
            continue
    
    return results

def check_dynamic_row_criteria(result, target_techs, target_dates, 
                              search_terms, search_params):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«"""
    
    # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©
    if target_techs:
        row_tech = result.get("Servised by", "").lower()
        if row_tech == "-" and not search_params["include_empty"]:
            return False
        
        tech_match = False
        if row_tech != "-":
            for tech in target_techs:
                if search_params["exact_match"]:
                    if tech == row_tech:
                        tech_match = True
                        break
                else:
                    if tech in row_tech:
                        tech_match = True
                        break
        
        if not tech_match:
            return False
    
    # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ§Ø±ÙŠØ®
    if target_dates:
        row_date = str(result.get("Date", "")).lower()
        if not row_date and not search_params["include_empty"]:
            return False
        
        date_match = False
        if row_date:
            for date_term in target_dates:
                if search_params["exact_match"]:
                    if date_term == row_date:
                        date_match = True
                        break
                else:
                    if date_term in row_date:
                        date_match = True
                        break
        
        if not date_match:
            return False
    
    # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Øµ Ø§Ù„Ø¨Ø­Ø«
    if search_terms:
        row_event = result.get("Event", "").lower()
        row_correction = result.get("Correction", "").lower()
        
        if not row_event and not row_correction and not search_params["include_empty"]:
            return False
        
        text_match = False
        combined_text = f"{row_event} {row_correction}"
        
        for term in search_terms:
            if search_params["exact_match"]:
                if term == row_event or term == row_correction:
                    text_match = True
                    break
            else:
                if term in combined_text:
                    text_match = True
                    break
        
        if not text_match:
            return False
    
    return True

def parse_card_numbers(card_numbers_str):
    """ØªØ­Ù„ÙŠÙ„ Ø³Ù„Ø³Ù„Ø© Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø£Ø±Ù‚Ø§Ù…"""
    if not card_numbers_str:
        return set()
    
    numbers = set()
    
    try:
        parts = card_numbers_str.split(',')
        for part in parts:
            part = part.strip()
            if '-' in part:
                try:
                    start_str, end_str = part.split('-')
                    start = int(start_str.strip())
                    end = int(end_str.strip())
                    numbers.update(range(start, end + 1))
                except:
                    continue
            else:
                try:
                    num = int(part)
                    numbers.add(num)
                except:
                    continue
    except:
        return set()
    
    return numbers

def calculate_durations_between_events(events_data, duration_type="Ø£ÙŠØ§Ù…", group_by_type=False):
    """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù„Ù†ÙØ³ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©"""
    if not events_data:
        return events_data
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ DataFrame
    df = pd.DataFrame(events_data)
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ datetime
    def parse_date(date_str):
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù„ÙŠÙ„ ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ù…Ø®ØªÙ„ÙØ©
            date_str = str(date_str).strip()
            if not date_str or date_str.lower() in ["nan", "none", "-", ""]:
                return None
            
            # ØªØ¬Ø±Ø¨Ø© ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ù…Ø®ØªÙ„ÙØ©
            formats = [
                "%d/%m/%Y", "%d-%m-%Y", "%d.%m.%Y",
                "%Y/%m/%d", "%Y-%m-%d", "%Y.%m.%d",
                "%m/%d/%Y", "%m-%d-%Y", "%m.%d.%Y"
            ]
            
            for fmt in formats:
                try:
                    return datetime.strptime(date_str, fmt)
                except:
                    continue
            
            # Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
            return None
        except:
            return None
    
    df['Date_Parsed'] = df['Date'].apply(parse_date)
    
    # ÙØ±Ø² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø© Ø«Ù… Ø§Ù„ØªØ§Ø±ÙŠØ®
    df = df.sort_values(['Card Number', 'Date_Parsed'])
    
    # Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¯Ø©
    df['Previous_Date'] = None
    df['Duration'] = None
    df['Duration_Unit'] = None
    df['Event_Type'] = None
    
    # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø­Ø¯Ø« (Ø­Ø¯Ø« Ø£Ùˆ ØªØµØ­ÙŠØ­)
    def determine_event_type(event, correction):
        event_str = str(event).strip().lower()
        correction_str = str(correction).strip().lower()
        
        if event_str not in ['-', 'nan', 'none', ''] and correction_str not in ['-', 'nan', 'none', '']:
            return "ØªØµØ­ÙŠØ­"
        elif event_str not in ['-', 'nan', 'none', '']:
            return "Ø­Ø¯Ø«"
        elif correction_str not in ['-', 'nan', 'none', '']:
            return "ØªØµØ­ÙŠØ­"
        else:
            return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
    
    df['Event_Type'] = df.apply(lambda row: determine_event_type(row.get('Event', '-'), row.get('Correction', '-')), axis=1)
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù„ÙƒÙ„ Ù…Ø§ÙƒÙŠÙ†Ø©
    durations_data = []
    
    for card_num in df['Card Number'].unique():
        card_events = df[df['Card Number'] == card_num].copy()
        
        if len(card_events) > 1:
            for i in range(1, len(card_events)):
                current_event = card_events.iloc[i]
                previous_event = card_events.iloc[i-1]
                
                current_date = current_event['Date_Parsed']
                previous_date = previous_event['Date_Parsed']
                
                if current_date and previous_date:
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø¨Ø§Ù„Ø£ÙŠØ§Ù…
                    duration_days = (current_date - previous_date).days
                    
                    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
                    if duration_type == "Ø£Ø³Ø§Ø¨ÙŠØ¹":
                        duration_value = duration_days / 7
                        duration_unit = "Ø£Ø³Ø¨ÙˆØ¹"
                    elif duration_type == "Ø£Ø´Ù‡Ø±":
                        duration_value = duration_days / 30.44  # Ù…ØªÙˆØ³Ø· Ø£ÙŠØ§Ù… Ø§Ù„Ø´Ù‡Ø±
                        duration_unit = "Ø´Ù‡Ø±"
                    else:  # Ø£ÙŠØ§Ù…
                        duration_value = duration_days
                        duration_unit = "ÙŠÙˆÙ…"
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
                    if group_by_type:
                        current_type = current_event['Event_Type']
                        previous_type = previous_event['Event_Type']
                        
                        if current_type == previous_type:
                            duration_info = {
                                'Card Number': card_num,
                                'Current_Event_Date': current_event['Date'],
                                'Previous_Event_Date': previous_event['Date'],
                                'Duration': round(duration_value, 1),
                                'Duration_Unit': duration_unit,
                                'Event_Type': current_type,
                                'Current_Event': current_event.get('Event', '-'),
                                'Previous_Event': previous_event.get('Event', '-'),
                                'Current_Correction': current_event.get('Correction', '-'),
                                'Previous_Correction': previous_event.get('Correction', '-'),
                                'Technician': current_event.get('Servised by', '-')
                            }
                            durations_data.append(duration_info)
                    else:
                        duration_info = {
                            'Card Number': card_num,
                            'Current_Event_Date': current_event['Date'],
                            'Previous_Event_Date': previous_event['Date'],
                            'Duration': round(duration_value, 1),
                            'Duration_Unit': duration_unit,
                            'Event_Type': f"{previous_event['Event_Type']} â†’ {current_event['Event_Type']}",
                            'Current_Event': current_event.get('Event', '-'),
                            'Previous_Event': previous_event.get('Event', '-'),
                            'Current_Correction': current_event.get('Correction', '-'),
                            'Previous_Correction': previous_event.get('Correction', '-'),
                            'Technician': current_event.get('Servised by', '-')
                        }
                        durations_data.append(duration_info)
    
    return durations_data

# ===============================
# ğŸ–¥ Ø¯Ø§Ù„Ø© ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù† - Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©
# ===============================
def check_events_and_corrections(all_sheets):
    """ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù† Ù…Ø¹ Ø®Ø§ØµÙŠØ© Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«"""
    if not all_sheets:
        st.error("âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ø´ÙŠØªØ§Øª.")
        return
    
    # ØªÙ‡ÙŠØ¦Ø© session state
    if "search_params" not in st.session_state:
        st.session_state.search_params = {
            "card_numbers": "",
            "date_range": "",
            "tech_names": "",
            "search_text": "",
            "exact_match": False,
            "include_empty": True,
            "sort_by": "Ø§Ù„Ø´ÙŠØª",
            "calculate_duration": False,
            "duration_type": "Ø£ÙŠØ§Ù…",
            "duration_filter_min": 0,
            "duration_filter_max": 365,
            "group_by_type": False,
            "show_images": True
        }
    
    if "search_triggered" not in st.session_state:
        st.session_state.search_triggered = False
    
    # Ù‚Ø³Ù… Ø§Ù„Ø¨Ø­Ø« - Ù…Ø¹ Ø¥Ø¶Ø§ÙØ© Ø®ÙŠØ§Ø±Ø§Øª Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø©
    with st.container():
        st.markdown("### ğŸ” Ø¨Ø­Ø« Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±")
        st.markdown("Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ø¯Ø¯. ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ù„Ø¡ ÙˆØ§Ø­Ø¯ Ø£Ùˆ Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„.")
        
        # ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù„Ù„Ø¨Ø­Ø« ÙˆØ®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…Ø¯Ø©
        main_tabs = st.tabs(["ğŸ” Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«", "â±ï¸ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…Ø¯Ø©", "ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø²Ù…Ù†ÙŠ"])
        
        with main_tabs[0]:
            col1, col2 = st.columns(2)
            
            with col1:
                # Ù‚Ø³Ù… Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª
                with st.expander("ğŸ”¢ **Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª/Ø§Ù„Ø´ÙŠØªØ§Øª**", expanded=True):
                    st.caption("Ø£Ø¯Ø®Ù„ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ø£Ùˆ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´ÙŠØªØ§Øª (Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„)")
                    card_numbers = st.text_input(
                        "Ù…Ø«Ø§Ù„: 1,3,5 Ø£Ùˆ Card1,Card3 Ø£Ùˆ Machine,Service",
                        value=st.session_state.search_params.get("card_numbers", ""),
                        key="input_cards",
                        placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª"
                    )
                    
                    # Ø£Ø²Ø±Ø§Ø± Ø³Ø±ÙŠØ¹Ø© Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª
                    st.caption("Ø£Ùˆ Ø§Ø®ØªØ± Ù…Ù†:")
                    quick_cards_col1, quick_cards_col2, quick_cards_col3 = st.columns(3)
                    with quick_cards_col1:
                        if st.button("ğŸ”Ÿ Ø´ÙŠØªØ§Øª Card", key="quick_cards"):
                            st.session_state.search_params["card_numbers"] = "Card"
                            st.session_state.search_triggered = True
                            st.rerun()
                    with quick_cards_col2:
                        if st.button("ğŸ“‹ ÙƒÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª", key="quick_all"):
                            st.session_state.search_params["card_numbers"] = ""
                            st.session_state.search_triggered = True
                            st.rerun()
                    with quick_cards_col3:
                        if st.button("ğŸ—‘ Ù…Ø³Ø­", key="clear_cards"):
                            st.session_state.search_params["card_numbers"] = ""
                            st.rerun()
                
                # Ù‚Ø³Ù… Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
                with st.expander("ğŸ“… **Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®**", expanded=True):
                    st.caption("Ø§Ø¨Ø­Ø« Ø¨Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø³Ù†Ø©ØŒ Ø´Ù‡Ø±/Ø³Ù†Ø©)")
                    date_input = st.text_input(
                        "Ù…Ø«Ø§Ù„: 2024 Ø£Ùˆ 1/2024 Ø£Ùˆ 2024,2025",
                        value=st.session_state.search_params.get("date_range", ""),
                        key="input_date",
                        placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®"
                    )
            
            with col2:
                # Ù‚Ø³Ù… ÙÙ†ÙŠÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©
                with st.expander("ğŸ‘¨â€ğŸ”§ **ÙÙ†ÙŠÙˆ Ø§Ù„Ø®Ø¯Ù…Ø©**", expanded=True):
                    st.caption("Ø§Ø¨Ø­Ø« Ø¨Ø£Ø³Ù…Ø§Ø¡ ÙÙ†ÙŠÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©")
                    tech_names = st.text_input(
                        "Ù…Ø«Ø§Ù„: Ø£Ø­Ù…Ø¯, Ù…Ø­Ù…Ø¯, Ø¹Ù„ÙŠ",
                        value=st.session_state.search_params.get("tech_names", ""),
                        key="input_techs",
                        placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„ÙÙ†ÙŠÙŠÙ†"
                    )
                
                # Ù‚Ø³Ù… Ù†Øµ Ø§Ù„Ø¨Ø­Ø«
                with st.expander("ğŸ“ **Ù†Øµ Ø§Ù„Ø¨Ø­Ø«**", expanded=True):
                    st.caption("Ø§Ø¨Ø­Ø« ÙÙŠ ÙˆØµÙ Ø§Ù„Ø­Ø¯Ø« Ø£Ùˆ Ø§Ù„ØªØµØ­ÙŠØ­")
                    search_text = st.text_input(
                        "Ù…Ø«Ø§Ù„: ØµÙŠØ§Ù†Ø©, Ø¥ØµÙ„Ø§Ø­, ØªØºÙŠÙŠØ±",
                        value=st.session_state.search_params.get("search_text", ""),
                        key="input_text",
                        placeholder="Ø§ØªØ±ÙƒÙ‡ ÙØ§Ø±ØºØ§Ù‹ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ"
                    )
            
            # Ù‚Ø³Ù… Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
            with st.expander("âš™ **Ø®ÙŠØ§Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©**", expanded=False):
                col_adv1, col_adv2, col_adv3 = st.columns(3)
                with col_adv1:
                    search_mode = st.radio(
                        "ğŸ” Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¨Ø­Ø«:",
                        ["Ø¨Ø­Ø« Ø¬Ø²Ø¦ÙŠ", "Ù…Ø·Ø§Ø¨Ù‚Ø© ÙƒØ§Ù…Ù„Ø©"],
                        index=0 if not st.session_state.search_params.get("exact_match") else 1,
                        key="radio_search_mode",
                        help="Ø¨Ø­Ø« Ø¬Ø²Ø¦ÙŠ: ÙŠØ¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Øµ ÙÙŠ Ø£ÙŠ Ù…ÙƒØ§Ù†. Ù…Ø·Ø§Ø¨Ù‚Ø© ÙƒØ§Ù…Ù„Ø©: ÙŠØ¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Øµ Ù…Ø·Ø§Ø¨Ù‚ ØªÙ…Ø§Ù…Ø§Ù‹"
                    )
                with col_adv2:
                    include_empty = st.checkbox(
                        "ğŸ” ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ÙØ§Ø±ØºØ©",
                        value=st.session_state.search_params.get("include_empty", True),
                        key="checkbox_include_empty",
                        help="ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø­Ù‚ÙˆÙ„ ÙØ§Ø±ØºØ©"
                    )
                with col_adv3:
                    sort_by = st.selectbox(
                        "ğŸ“Š ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:",
                        ["Ø§Ù„Ø´ÙŠØª", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©", "Ù…Ø¯Ø© Ø§Ù„Ø­Ø¯Ø«"],
                        index=["Ø§Ù„Ø´ÙŠØª", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©", "Ù…Ø¯Ø© Ø§Ù„Ø­Ø¯Ø«"].index(
                            st.session_state.search_params.get("sort_by", "Ø§Ù„Ø´ÙŠØª")
                        ),
                        key="select_sort_by"
                    )
        
        with main_tabs[1]:
            st.markdown("#### â±ï¸ Ø®ÙŠØ§Ø±Ø§Øª Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«")
            
            col_dur1, col_dur2 = st.columns(2)
            
            with col_dur1:
                calculate_duration = st.checkbox(
                    "ğŸ“… Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«",
                    value=st.session_state.search_params.get("calculate_duration", False),
                    key="checkbox_calculate_duration",
                    help="Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù„Ù†ÙØ³ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©"
                )
                
                if calculate_duration:
                    duration_type = st.selectbox(
                        "ÙˆØ­Ø¯Ø© Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø©:",
                        ["Ø£ÙŠØ§Ù…", "Ø£Ø³Ø§Ø¨ÙŠØ¹", "Ø£Ø´Ù‡Ø±"],
                        index=["Ø£ÙŠØ§Ù…", "Ø£Ø³Ø§Ø¨ÙŠØ¹", "Ø£Ø´Ù‡Ø±"].index(
                            st.session_state.search_params.get("duration_type", "Ø£ÙŠØ§Ù…")
                        ),
                        key="select_duration_type"
                    )
                    
                    group_by_type = st.checkbox(
                        "ğŸ“Š ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø­Ø¯Ø«",
                        value=st.session_state.search_params.get("group_by_type", False),
                        key="checkbox_group_by_type",
                        help="ÙØµÙ„ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø­Ø¯Ø« (Ø­Ø¯Ø«/ØªØµØ­ÙŠØ­)"
                    )
            
            with col_dur2:
                if calculate_duration:
                    st.markdown("#### ğŸ” ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¯Ø©")
                    
                    duration_filter_min = st.number_input(
                        "Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù…Ø¯Ø©:",
                        min_value=0,
                        value=st.session_state.search_params.get("duration_filter_min", 0),
                        step=1,
                        key="input_duration_min"
                    )
                    
                    duration_filter_max = st.number_input(
                        "Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ø¯Ø©:",
                        min_value=duration_filter_min,
                        value=st.session_state.search_params.get("duration_filter_max", 365),
                        step=1,
                        key="input_duration_max"
                    )
                    
                    st.caption(f"Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„ØªÙŠ ØªØªØ±Ø§ÙˆØ­ Ù…Ø¯ØªÙ‡Ø§ Ø¨ÙŠÙ† {duration_filter_min} Ùˆ {duration_filter_max} {duration_type}")
        
        with main_tabs[2]:
            st.markdown("#### ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø²Ù…Ù†ÙŠ Ù…ØªÙ‚Ø¯Ù…")
            
            analysis_options = st.multiselect(
                "Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„:",
                ["Ù…Ø¹Ø¯Ù„ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¯Ø© Ø­Ø³Ø¨ Ø§Ù„ÙÙ†ÙŠ", "ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø²Ù…Ù†ÙŠØ§Ù‹", "Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø­Ø¯Ø« ÙˆØ§Ù„ØªØµØ­ÙŠØ­"],
                default=[],
                key="select_analysis_options"
            )
            
            if "Ù…Ø¹Ø¯Ù„ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø§Ø«" in analysis_options:
                st.info("ğŸ“ˆ Ø³ÙŠØªÙ… Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù„ÙƒÙ„ Ù…Ø§ÙƒÙŠÙ†Ø©")
            
            if "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¯Ø© Ø­Ø³Ø¨ Ø§Ù„ÙÙ†ÙŠ" in analysis_options:
                st.info("ğŸ‘¨â€ğŸ”§ Ø³ÙŠØªÙ… Ù…Ù‚Ø§Ø±Ù†Ø© Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© Ø§Ù„ØªÙŠ ÙŠØ³ØªØºØ±Ù‚Ù‡Ø§ ÙƒÙ„ ÙÙ†ÙŠ")
            
            if "ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø²Ù…Ù†ÙŠØ§Ù‹" in analysis_options:
                st.info("ğŸ“… Ø³ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø¹Ù„Ù‰ Ù…Ø¯Ø§Ø± Ø§Ù„Ø³Ù†Ø©")
            
            if "Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø­Ø¯Ø« ÙˆØ§Ù„ØªØµØ­ÙŠØ­" in analysis_options:
                st.info("âš–ï¸ Ø³ÙŠØªÙ… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© ÙˆØ§Ù„ØªØµØ­ÙŠØ­Ø§Øª")
        
        # ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«
        st.session_state.search_params.update({
            "card_numbers": card_numbers,
            "date_range": date_input,
            "tech_names": tech_names,
            "search_text": search_text,
            "exact_match": search_mode == "Ù…Ø·Ø§Ø¨Ù‚Ø© ÙƒØ§Ù…Ù„Ø©",
            "include_empty": include_empty,
            "sort_by": sort_by,
            "calculate_duration": calculate_duration,
            "duration_type": duration_type if calculate_duration else "Ø£ÙŠØ§Ù…",
            "duration_filter_min": duration_filter_min if calculate_duration else 0,
            "duration_filter_max": duration_filter_max if calculate_duration else 365,
            "group_by_type": group_by_type if calculate_duration else False,
            "analysis_options": analysis_options,
            "show_images": True
        })
        
        # Ø²Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
        st.markdown("---")
        col_btn1, col_btn2, col_btn3 = st.columns([2, 1, 1])
        with col_btn1:
            search_clicked = st.button(
                "ğŸ” **Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„**",
                type="primary",
                use_container_width=True,
                key="main_search_btn"
            )
        with col_btn2:
            if st.button("ğŸ—‘ **Ù…Ø³Ø­ Ø§Ù„Ø­Ù‚ÙˆÙ„**", use_container_width=True, key="clear_fields"):
                st.session_state.search_params = {
                    "card_numbers": "",
                    "date_range": "",
                    "tech_names": "",
                    "search_text": "",
                    "exact_match": False,
                    "include_empty": True,
                    "sort_by": "Ø§Ù„Ø´ÙŠØª",
                    "calculate_duration": False,
                    "duration_type": "Ø£ÙŠØ§Ù…",
                    "duration_filter_min": 0,
                    "duration_filter_max": 365,
                    "group_by_type": False,
                    "analysis_options": [],
                    "show_images": True
                }
                st.session_state.search_triggered = False
                st.rerun()
        with col_btn3:
            if st.button("ğŸ“Š **Ø¹Ø±Ø¶ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**", use_container_width=True, key="show_all"):
                st.session_state.search_params = {
                    "card_numbers": "",
                    "date_range": "",
                    "tech_names": "",
                    "search_text": "",
                    "exact_match": False,
                    "include_empty": True,
                    "sort_by": "Ø§Ù„Ø´ÙŠØª",
                    "calculate_duration": True,
                    "duration_type": "Ø£ÙŠØ§Ù…",
                    "duration_filter_min": 0,
                    "duration_filter_max": 365,
                    "group_by_type": True,
                    "analysis_options": ["Ù…Ø¹Ø¯Ù„ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", "ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø²Ù…Ù†ÙŠØ§Ù‹"],
                    "show_images": True
                }
                st.session_state.search_triggered = True
                st.rerun()
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨Ø­Ø«
    if search_clicked or st.session_state.search_triggered:
        st.session_state.search_triggered = True
        
        # Ø¬Ù…Ø¹ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«
        search_params = st.session_state.search_params.copy()
        
        # Ø¹Ø±Ø¶ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«
        show_search_params(search_params)
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø­Ø«
        show_advanced_search_results_with_duration(search_params, all_sheets)

def show_search_params(search_params):
    """Ø¹Ø±Ø¶ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©"""
    with st.container():
        st.markdown("### âš™ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©")
        
        params_display = []
        if search_params["card_numbers"]:
            params_display.append(f"**ğŸ”¢ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª/Ø§Ù„Ø´ÙŠØªØ§Øª:** {search_params['card_numbers']}")
        if search_params["date_range"]:
            params_display.append(f"**ğŸ“… Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®:** {search_params['date_range']}")
        if search_params["tech_names"]:
            params_display.append(f"**ğŸ‘¨â€ğŸ”§ ÙÙ†ÙŠÙˆ Ø§Ù„Ø®Ø¯Ù…Ø©:** {search_params['tech_names']}")
        if search_params["search_text"]:
            params_display.append(f"**ğŸ“ Ù†Øµ Ø§Ù„Ø¨Ø­Ø«:** {search_params['search_text']}")
        
        if params_display:
            st.info(" | ".join(params_display))
        else:
            st.info("ğŸ” **Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**")

def show_advanced_search_results_with_duration(search_params, all_sheets):
    """Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ù…Ø¹ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø©"""
    st.markdown("### ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«")
    
    # Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    all_results = []
    total_sheets = len(all_sheets)
    processed_sheets = 0
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª/Ø§Ù„Ø´ÙŠØªØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    target_sheets = []
    if search_params["card_numbers"]:
        target_text = search_params["card_numbers"].lower()
        target_sheets = [sheet_name for sheet_name in all_sheets.keys() if target_text in sheet_name.lower()]
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠÙŠÙ†
    target_techs = []
    if search_params["tech_names"]:
        techs = search_params["tech_names"].split(',')
        target_techs = [tech.strip().lower() for tech in techs if tech.strip()]
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
    target_dates = []
    if search_params["date_range"]:
        dates = search_params["date_range"].split(',')
        target_dates = [date.strip().lower() for date in dates if date.strip()]
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†Øµ Ø§Ù„Ø¨Ø­Ø«
    search_terms = []
    if search_params["search_text"]:
        terms = search_params["search_text"].split(',')
        search_terms = [term.strip().lower() for term in terms if term.strip()]
    
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª
    for sheet_name, df in all_sheets.items():
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ø´ÙŠØª Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØ­Ø¯ÙŠØ¯
        if target_sheets and sheet_name not in target_sheets:
            continue
        
        processed_sheets += 1
        if total_sheets > 0:
            progress_bar.progress(processed_sheets / total_sheets)
        
        status_text.text(f"ğŸ” Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø´ÙŠØª: {sheet_name}...")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø´ÙŠØª
        sheet_results = extract_sheet_data(df, sheet_name)
        
        # ÙÙ„ØªØ±Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«
        for result in sheet_results:
            # ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«
            if not check_dynamic_row_criteria(result, target_techs, target_dates, 
                                             search_terms, search_params):
                continue
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
            all_results.append(result)
    
    # Ø¥Ø®ÙØ§Ø¡ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
    progress_bar.empty()
    status_text.empty()
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø©
    if all_results:
        display_search_results_with_duration(all_results, search_params)
    else:
        st.warning("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ ØªØ·Ø§Ø¨Ù‚ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«")
        st.info("ğŸ’¡ Ø­Ø§ÙˆÙ„ ØªØ¹Ø¯ÙŠÙ„ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø« Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØµØ·Ù„Ø­Ø§Øª Ø£ÙˆØ³Ø¹")

def display_search_results_with_duration(results, search_params):
    """Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ù…Ø¹ Ø®Ø§ØµÙŠØ© Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø©"""
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ DataFrame
    if not results:
        st.warning("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ø¹Ø±Ø¶Ù‡Ø§")
        return
    
    result_df = pd.DataFrame(results)
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if result_df.empty:
        st.warning("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¹Ø±Ø¶Ù‡Ø§")
        return
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ù„Ù„Ø¹Ø±Ø¶ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ±ØªÙŠØ¨
    display_df = result_df.copy()
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø© Ø¥Ù„Ù‰ Ø±Ù‚Ù… ØµØ­ÙŠØ­ Ù„Ù„ØªØ±ØªÙŠØ¨
    try:
        display_df['Card_Number_Clean'] = pd.to_numeric(display_df['Card Number'], errors='coerce')
    except:
        display_df['Card_Number_Clean'] = display_df['Card Number']
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ù„ØªØ±ØªÙŠØ¨ Ø²Ù…Ù†ÙŠ
    display_df['Date_Clean'] = pd.to_datetime(display_df['Date'], errors='coerce', dayfirst=True)
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ø´ÙŠØª Ø«Ù… Ø§Ù„ØªØ§Ø±ÙŠØ®
    if search_params["sort_by"] == "Ø§Ù„ØªØ§Ø±ÙŠØ®":
        display_df = display_df.sort_values(by=['Date_Clean', 'Sheet Name'], 
                                          ascending=[False, True], na_position='last')
    elif search_params["sort_by"] == "ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©":
        display_df = display_df.sort_values(by=['Servised by', 'Sheet Name', 'Date_Clean'], 
                                          ascending=[True, True, False], na_position='last')
    elif search_params["sort_by"] == "Ù…Ø¯Ø© Ø§Ù„Ø­Ø¯Ø«":
        # Ø³Ù†Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø£ÙˆÙ„Ø§Ù‹
        pass
    else:  # Ø§Ù„Ø´ÙŠØª (Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ)
        display_df = display_df.sort_values(by=['Sheet Name', 'Date_Clean'], 
                                          ascending=[True, False], na_position='last')
    
    # Ø¥Ø¶Ø§ÙØ© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù„ÙƒÙ„ Ø´ÙŠØª
    display_df['Event_Order'] = display_df.groupby('Sheet Name').cumcount() + 1
    display_df['Total_Events'] = display_df.groupby('Sheet Name')['Sheet Name'].transform('count')
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    st.markdown("### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“‹ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", len(display_df))
    
    with col2:
        unique_sheets = display_df["Sheet Name"].nunique()
        st.metric("ğŸ“‚ Ø¹Ø¯Ø¯ Ø§Ù„Ø´ÙŠØªØ§Øª", unique_sheets)
    
    with col3:
        # Ø¹Ø¯Ø¯ Ø§Ù„Ø´ÙŠØªØ§Øª Ø§Ù„ØªÙŠ Ù„Ø¯ÙŠÙ‡Ø§ Ø£ÙƒØ«Ø± Ù…Ù† Ø­Ø¯Ø«
        if not display_df.empty:
            sheet_counts = display_df.groupby('Sheet Name').size()
            multi_event_sheets = (sheet_counts > 1).sum()
            st.metric("ğŸ“Š Ø´ÙŠØªØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", multi_event_sheets)
        else:
            st.metric("ğŸ“Š Ø´ÙŠØªØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", 0)
    
    with col4:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ù…ÙˆØ¯ Ø§Ù„ØµÙˆØ± ÙÙŠ display_df
        has_images_column = 'Images' in display_df.columns
        if has_images_column:
            with_images = display_df[display_df["Images"].notna() & (display_df["Images"] != "") & (display_df["Images"] != "-")].shape[0]
            st.metric("ğŸ“· ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØµÙˆØ±", with_images)
        else:
            st.metric("ğŸ“· ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØµÙˆØ±", 0)
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø·Ù„ÙˆØ¨Ø§Ù‹
    if search_params.get("calculate_duration", False):
        st.markdown("---")
        st.markdown("### â±ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«")
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø©
        durations_data = calculate_durations_between_events(
            results,
            search_params.get("duration_type", "Ø£ÙŠØ§Ù…"),
            search_params.get("group_by_type", False)
        )
        
        if durations_data:
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ DataFrame
            durations_df = pd.DataFrame(durations_data)
            
            # ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø¯Ø©
            duration_min = search_params.get("duration_filter_min", 0)
            duration_max = search_params.get("duration_filter_max", 365)
            
            filtered_durations = durations_df[
                (durations_df['Duration'] >= duration_min) & 
                (durations_df['Duration'] <= duration_max)
            ]
            
            # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¯Ø©
            st.markdown("#### ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¯Ø©")
            
            col_dur1, col_dur2, col_dur3, col_dur4 = st.columns(4)
            
            with col_dur1:
                avg_duration = filtered_durations['Duration'].mean() if not filtered_durations.empty else 0
                st.metric(f"â³ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø©", f"{avg_duration:.1f} {search_params.get('duration_type', 'Ø£ÙŠØ§Ù…')}")
            
            with col_dur2:
                min_duration = filtered_durations['Duration'].min() if not filtered_durations.empty else 0
                st.metric(f"âš¡ Ø£Ù‚ØµØ± Ù…Ø¯Ø©", f"{min_duration} {search_params.get('duration_type', 'Ø£ÙŠØ§Ù…')}")
            
            with col_dur3:
                max_duration = filtered_durations['Duration'].max() if not filtered_durations.empty else 0
                st.metric(f"ğŸŒ Ø£Ø·ÙˆÙ„ Ù…Ø¯Ø©", f"{max_duration} {search_params.get('duration_type', 'Ø£ÙŠØ§Ù…')}")
            
            with col_dur4:
                total_durations = len(filtered_durations)
                st.metric("ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„ÙØªØ±Ø§Øª", total_durations)
            
            # Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø¯Ø©
            st.markdown("#### ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«")
            
            # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„Ø¹Ø±Ø¶
            display_columns = [
                'Card Number', 'Previous_Event_Date', 'Current_Event_Date',
                'Duration', 'Duration_Unit', 'Event_Type', 'Technician'
            ]
            
            available_columns = [col for col in display_columns if col in filtered_durations.columns]
            
            st.dataframe(
                filtered_durations[available_columns],
                use_container_width=True,
                height=400
            )
            
            # ØªØ­Ù„ÙŠÙ„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
            analysis_options = search_params.get("analysis_options", [])
            if analysis_options:
                st.markdown("---")
                st.markdown("### ğŸ“ˆ ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©")
                
                for analysis in analysis_options:
                    if analysis == "Ù…Ø¹Ø¯Ù„ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø§Ø«":
                        show_event_frequency_analysis(filtered_durations, search_params.get("duration_type", "Ø£ÙŠØ§Ù…"))
                    
                    elif analysis == "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¯Ø© Ø­Ø³Ø¨ Ø§Ù„ÙÙ†ÙŠ":
                        show_technician_comparison_analysis(filtered_durations)
                    
                    elif analysis == "ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø²Ù…Ù†ÙŠØ§Ù‹":
                        show_temporal_distribution_analysis(durations_df)
                    
                    elif analysis == "Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø­Ø¯Ø« ÙˆØ§Ù„ØªØµØ­ÙŠØ­":
                        show_event_correction_comparison(filtered_durations)
        else:
            st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« (ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø­Ø¯Ø«ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù„ÙƒÙ„ Ù…Ø§ÙƒÙŠÙ†Ø©)")
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£ØµÙ„ÙŠØ©
    st.markdown("---")
    st.markdown("### ğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©")
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    display_tabs = st.tabs(["ğŸ“Š Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ÙŠ", "ğŸ“‹ Ø¹Ø±Ø¶ ØªÙØµÙŠÙ„ÙŠ Ø­Ø³Ø¨ Ø§Ù„Ø´ÙŠØª", "ğŸ“· Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±"])
    
    with display_tabs[0]:
        # Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ÙŠ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ
        columns_to_show = ['Sheet Name', 'Card Number', 'Event', 'Correction', 'Servised by', 'Tones', 'Date', 'Event_Order', 'Total_Events']
        
        # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø§Ù„ØµÙˆØ± Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ ÙÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        has_images_in_results = any('Images' in result for result in results)
        if has_images_in_results and 'Images' not in columns_to_show:
            columns_to_show.append('Images')
        
        columns_to_show = [col for col in columns_to_show if col in display_df.columns]
        
        st.dataframe(
            display_df[columns_to_show].style.apply(style_table, axis=1),
            use_container_width=True,
            height=500
        )
    
    with display_tabs[1]:
        # Ø¹Ø±Ø¶ ØªÙØµÙŠÙ„ÙŠ Ù„ÙƒÙ„ Ø´ÙŠØª Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„
        unique_sheets = sorted(display_df['Sheet Name'].unique())
        
        for sheet_name in unique_sheets:
            sheet_data = display_df[display_df['Sheet Name'] == sheet_name].copy()
            sheet_data = sheet_data.sort_values('Event_Order')
            
            with st.expander(f"ğŸ“‚ {sheet_name} - Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«: {len(sheet_data)}", expanded=len(unique_sheets) <= 5):
                
                # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø´ÙŠØª
                col_stats1, col_stats2, col_stats3 = st.columns(3)
                with col_stats1:
                    if not sheet_data.empty and 'Date' in sheet_data.columns:
                        first_date = sheet_data['Date'].iloc[0]
                        st.metric("ğŸ“… Ø£ÙˆÙ„ Ø­Ø¯Ø«", first_date if first_date != "-" else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
                    else:
                        st.metric("ğŸ“… Ø£ÙˆÙ„ Ø­Ø¯Ø«", "-")
                with col_stats2:
                    if not sheet_data.empty and 'Date' in sheet_data.columns:
                        last_date = sheet_data['Date'].iloc[-1]
                        st.metric("ğŸ“… Ø¢Ø®Ø± Ø­Ø¯Ø«", last_date if last_date != "-" else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
                    else:
                        st.metric("ğŸ“… Ø¢Ø®Ø± Ø­Ø¯Ø«", "-")
                with col_stats3:
                    if not sheet_data.empty and 'Servised by' in sheet_data.columns:
                        tech_count = sheet_data['Servised by'].nunique()
                        st.metric("ğŸ‘¨â€ğŸ”§ ÙÙ†ÙŠÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ†", tech_count)
                    else:
                        st.metric("ğŸ‘¨â€ğŸ”§ ÙÙ†ÙŠÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ†", 0)
                
                # Ø¹Ø±Ø¶ Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø´ÙŠØª
                for idx, row in sheet_data.iterrows():
                    st.markdown("---")
                    col_event1, col_event2 = st.columns([3, 2])
                    
                    with col_event1:
                        event_order = row.get('Event_Order', '?')
                        total_events = row.get('Total_Events', '?')
                        st.markdown(f"**Ø§Ù„Ø­Ø¯Ø« #{event_order} Ù…Ù† {total_events}**")
                        if 'Date' in row:
                            st.markdown(f"**ğŸ“… Ø§Ù„ØªØ§Ø±ÙŠØ®:** {row['Date']}")
                        if 'Event' in row and row['Event'] != '-':
                            st.markdown(f"**ğŸ“ Ø§Ù„Ø­Ø¯Ø«:** {row['Event']}")
                        if 'Correction' in row and row['Correction'] != '-':
                            st.markdown(f"**âœ Ø§Ù„ØªØµØ­ÙŠØ­:** {row['Correction']}")
                    
                    with col_event2:
                        if 'Servised by' in row and row['Servised by'] != '-':
                            st.markdown(f"**ğŸ‘¨â€ğŸ”§ ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©:** {row['Servised by']}")
                        if 'Tones' in row and row['Tones'] != '-':
                            st.markdown(f"**âš–ï¸ Ø§Ù„Ø£Ø·Ù†Ø§Ù†:** {row['Tones']}")
                        
                        # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ± Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
                        if 'Images' in row and row['Images'] not in ['-', '', None, 'nan']:
                            images_str = str(row['Images'])
                            if images_str.strip():
                                images_count = len(images_str.split(',')) if images_str else 0
                                st.markdown(f"**ğŸ“· Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ±:** {images_count}")
    
    with display_tabs[2]:
        # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ù„Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØµÙˆØ±
        # Ø¬Ù…Ø¹ Ø§Ù„ØµÙˆØ± Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        events_with_images = []
        
        for result in results:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ØµÙˆØ± ÙÙŠ ÙƒÙ„ Ù†ØªÙŠØ¬Ø©
            if 'Images' in result and result['Images'] and result['Images'] != "-" and result['Images'] != "":
                # Ù†Ø³Ø® Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø©
                event_with_images = result.copy()
                event_with_images['has_images'] = True
                events_with_images.append(event_with_images)
        
        if events_with_images:
            st.markdown("### ğŸ“· Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±ÙÙ‚Ø© Ø¨Ø§Ù„Ø£Ø­Ø¯Ø§Ø«")
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ DataFrame Ù„Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù†Ø¸Ù…
            images_df = pd.DataFrame(events_with_images)
            
            for idx, row in images_df.iterrows():
                sheet_name = row.get('Sheet Name', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')
                card_num = row.get('Card Number', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')
                event_date = row.get('Date', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')
                event_text = row.get('Event', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯')
                
                with st.expander(f"ğŸ“¸ ØµÙˆØ± Ù„Ù„Ø­Ø¯Ø« - {sheet_name} - {card_num} - {event_date}", expanded=False):
                    # Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø­Ø¯Ø«
                    col_img1, col_img2 = st.columns([2, 3])
                    
                    with col_img1:
                        st.markdown("**ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø­Ø¯Ø«:**")
                        st.markdown(f"**Ø§Ù„Ø´ÙŠØª:** {sheet_name}")
                        st.markdown(f"**Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©:** {card_num}")
                        st.markdown(f"**Ø§Ù„ØªØ§Ø±ÙŠØ®:** {event_date}")
                        st.markdown(f"**Ø§Ù„Ø­Ø¯Ø«:** {event_text[:50]}{'...' if len(event_text) > 50 else ''}")
                        st.markdown(f"**Ø§Ù„ØªØµØ­ÙŠØ­:** {row.get('Correction', '-')}")
                        st.markdown(f"**ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©:** {row.get('Servised by', '-')}")
                    
                    with col_img2:
                        # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±
                        images_value = row.get('Images', '')
                        if images_value:
                            display_images(images_value, "Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±ÙÙ‚Ø©")
        else:
            st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø­Ø¯Ø§Ø« ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØµÙˆØ± ÙÙŠ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«")
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ±
    st.markdown("---")
    st.markdown("### ğŸ’¾ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ±")
    
    export_col1, export_col2, export_col3 = st.columns(3)
    
    with export_col1:
        # ØªØµØ¯ÙŠØ± Excel
        if not result_df.empty:
            buffer_excel = io.BytesIO()
            
            export_df = result_df.copy()
            
            # Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ù„Ù„ØªØ±ØªÙŠØ¨
            export_df['Sheet_Name_Clean'] = export_df['Sheet Name']
            export_df['Date_Clean_Export'] = pd.to_datetime(export_df['Date'], errors='coerce', dayfirst=True)
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            export_df = export_df.sort_values(by=['Sheet_Name_Clean', 'Date_Clean_Export'], 
                                             ascending=[True, False], na_position='last')
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            export_df = export_df.drop(['Sheet_Name_Clean', 'Date_Clean_Export'], axis=1, errors='ignore')
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
            export_df.to_excel(buffer_excel, index=False, engine="openpyxl")
            
            st.download_button(
                label="ğŸ“Š Ø­ÙØ¸ ÙƒÙ…Ù„Ù Excel",
                data=buffer_excel.getvalue(),
                file_name=f"Ø¨Ø­Ø«_Ø£Ø­Ø¯Ø§Ø«_Ù…Ø±ØªØ¨_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        else:
            st.info("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØµØ¯ÙŠØ±")
    
    with export_col2:
        # ØªØµØ¯ÙŠØ± CSV
        if not result_df.empty:
            buffer_csv = io.BytesIO()
            
            export_csv = result_df.copy()
            
            # Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ù„Ù„ØªØ±ØªÙŠØ¨
            export_csv['Sheet_Name_Clean'] = export_csv['Sheet Name']
            export_csv['Date_Clean_Export'] = pd.to_datetime(export_csv['Date'], errors='coerce', dayfirst=True)
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            export_csv = export_csv.sort_values(by=['Sheet_Name_Clean', 'Date_Clean_Export'], 
                                               ascending=[True, False], na_position='last')
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
            export_csv = export_csv.drop(['Sheet_Name_Clean', 'Date_Clean_Export'], axis=1, errors='ignore')
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
            export_csv.to_csv(buffer_csv, index=False, encoding='utf-8-sig')
            
            st.download_button(
                label="ğŸ“„ Ø­ÙØ¸ ÙƒÙ…Ù„Ù CSV",
                data=buffer_csv.getvalue(),
                file_name=f"Ø¨Ø­Ø«_Ø£Ø­Ø¯Ø§Ø«_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        else:
            st.info("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØµØ¯ÙŠØ±")
    
    with export_col3:
        # ØªØµØ¯ÙŠØ± ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø¯Ø©
        if search_params.get("calculate_duration", False) and 'durations_data' in locals():
            if durations_data:
                buffer_duration = io.BytesIO()
                
                duration_export_df = pd.DataFrame(durations_data)
                
                with pd.ExcelWriter(buffer_duration, engine='openpyxl') as writer:
                    duration_export_df.to_excel(writer, sheet_name='Ø§Ù„Ù…Ø¯Ø©_Ø¨ÙŠÙ†_Ø§Ù„Ø£Ø­Ø¯Ø§Ø«', index=False)
                    
                    # Ø¥Ø¶Ø§ÙØ© Ù…Ù„Ø®Øµ Ø¥Ø­ØµØ§Ø¦ÙŠ
                    summary_data = []
                    for event_type in duration_export_df['Event_Type'].unique():
                        type_data = duration_export_df[duration_export_df['Event_Type'] == event_type]
                        summary_data.append({
                            'Ù†ÙˆØ¹ Ø§Ù„Ø­Ø¯Ø«': event_type,
                            'Ø¹Ø¯Ø¯ Ø§Ù„ÙØªØ±Ø§Øª': len(type_data),
                            f'Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© ({search_params.get("duration_type", "Ø£ÙŠØ§Ù…")})': type_data['Duration'].mean(),
                            'Ø£Ù‚Ù„ Ù…Ø¯Ø©': type_data['Duration'].min(),
                            'Ø£Ø¹Ù„Ù‰ Ù…Ø¯Ø©': type_data['Duration'].max()
                        })
                    
                    summary_df = pd.DataFrame(summary_data)
                    summary_df.to_excel(writer, sheet_name='Ù…Ù„Ø®Øµ_Ø¥Ø­ØµØ§Ø¦ÙŠ', index=False)
                
                st.download_button(
                    label="â±ï¸ Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø¯Ø©",
                    data=buffer_duration.getvalue(),
                    file_name=f"ØªÙ‚Ø±ÙŠØ±_Ø§Ù„Ù…Ø¯Ø©_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            else:
                st.info("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¯Ø© Ù„Ù„ØªØµØ¯ÙŠØ±")

def show_event_frequency_analysis(durations_df, duration_unit):
    """ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ø¯Ù„ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø§Ø«"""
    st.markdown("#### ğŸ“ˆ Ù…Ø¹Ø¯Ù„ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø£Ø­Ø¯Ø§Ø«")
    
    if durations_df.empty:
        st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø±")
        return
    
    # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©
    machine_stats = durations_df.groupby('Card Number').agg({
        'Duration': ['count', 'mean', 'std', 'min', 'max']
    }).round(2)
    
    machine_stats.columns = ['Ø¹Ø¯Ø¯_Ø§Ù„ÙØªØ±Ø§Øª', 'Ù…ØªÙˆØ³Ø·_Ø§Ù„Ù…Ø¯Ø©', 'Ø§Ù†Ø­Ø±Ø§Ù_Ù…Ø¹ÙŠØ§Ø±ÙŠ', 'Ø£Ù‚Ù„_Ù…Ø¯Ø©', 'Ø£Ø¹Ù„Ù‰_Ù…Ø¯Ø©']
    machine_stats = machine_stats.reset_index()
    
    # Ø¹Ø±Ø¶ Ø£ÙØ¶Ù„ 10 Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ù…Ù† Ø­ÙŠØ« Ø§Ù„ØªÙƒØ±Ø§Ø±
    st.markdown("##### ğŸ¥‡ Ø£ÙØ¶Ù„ 10 Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ù…Ù† Ø­ÙŠØ« ØªÙƒØ±Ø§Ø± Ø§Ù„ØµÙŠØ§Ù†Ø©")
    top_10_frequent = machine_stats.sort_values('Ø¹Ø¯Ø¯_Ø§Ù„ÙØªØ±Ø§Øª', ascending=False).head(10)
    st.dataframe(top_10_frequent, use_container_width=True)
    
    # Ø¹Ø±Ø¶ Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ø¨Ø£Ø·ÙˆÙ„ Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«
    st.markdown("##### ğŸŒ Ù…Ø§ÙƒÙŠÙ†Ø§Øª Ø¨Ø£Ø·ÙˆÙ„ Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«")
    top_10_longest = machine_stats.sort_values('Ù…ØªÙˆØ³Ø·_Ø§Ù„Ù…Ø¯Ø©', ascending=False).head(10)
    st.dataframe(top_10_longest, use_container_width=True)
    
    try:
        import plotly.express as px
        
        # Ù…Ø®Ø·Ø· ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¯Ø©
        fig1 = px.histogram(durations_df, x='Duration', 
                           title=f'ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« (Ø¨ÙˆØ­Ø¯Ø© {duration_unit})',
                           labels={'Duration': f'Ø§Ù„Ù…Ø¯Ø© ({duration_unit})'},
                           nbins=20)
        fig1.update_layout(showlegend=False)
        st.plotly_chart(fig1, use_container_width=True)
        
        # Ù…Ø®Ø·Ø· Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø¹Ø¯Ø¯ Ø§Ù„ÙØªØ±Ø§Øª ÙˆØ§Ù„Ù…ØªÙˆØ³Ø·
        fig2 = px.scatter(machine_stats, x='Ø¹Ø¯Ø¯_Ø§Ù„ÙØªØ±Ø§Øª', y='Ù…ØªÙˆØ³Ø·_Ø§Ù„Ù…Ø¯Ø©',
                         title='Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø¹Ø¯Ø¯ Ø§Ù„ÙØªØ±Ø§Øª ÙˆÙ…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø©',
                         hover_data=['Card Number'])
        fig2.update_layout(xaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„ÙØªØ±Ø§Øª", yaxis_title=f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© ({duration_unit})")
        st.plotly_chart(fig2, use_container_width=True)
        
    except ImportError:
        st.info("ğŸ“Š Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© plotly")

def show_technician_comparison_analysis(durations_df):
    """Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¯Ø© Ø­Ø³Ø¨ Ø§Ù„ÙÙ†ÙŠ"""
    st.markdown("#### ğŸ‘¨â€ğŸ”§ Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙÙ†ÙŠÙŠÙ†")
    
    if durations_df.empty or 'Technician' not in durations_df.columns:
        st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙ†ÙŠÙŠÙ† Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
        return
    
    # ÙÙ„ØªØ±Ø© Ø§Ù„ÙÙ†ÙŠÙŠÙ† ØºÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙˆÙÙŠÙ†
    filtered_df = durations_df[durations_df['Technician'] != '-'].copy()
    
    if filtered_df.empty:
        st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
        return
    
    # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„ÙÙ†ÙŠ
    tech_stats = filtered_df.groupby('Technician').agg({
        'Duration': ['count', 'mean', 'std', 'min', 'max'],
        'Card Number': 'nunique'
    }).round(2)
    
    tech_stats.columns = ['Ø¹Ø¯Ø¯_Ø§Ù„ÙØªØ±Ø§Øª', 'Ù…ØªÙˆØ³Ø·_Ø§Ù„Ù…Ø¯Ø©', 'Ø§Ù†Ø­Ø±Ø§Ù_Ù…Ø¹ÙŠØ§Ø±ÙŠ', 'Ø£Ù‚Ù„_Ù…Ø¯Ø©', 'Ø£Ø¹Ù„Ù‰_Ù…Ø¯Ø©', 'Ø¹Ø¯Ø¯_Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª']
    tech_stats = tech_stats.reset_index()
    
    # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© (Ø§Ù„Ø£Ø³Ø±Ø¹ Ø£ÙˆÙ„Ø§Ù‹)
    tech_stats = tech_stats.sort_values('Ù…ØªÙˆØ³Ø·_Ø§Ù„Ù…Ø¯Ø©')
    
    st.dataframe(tech_stats, use_container_width=True)
    
    try:
        import plotly.express as px
        
        # Ù…Ø®Ø·Ø· Ø´Ø±ÙŠØ·ÙŠ Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© Ø­Ø³Ø¨ Ø§Ù„ÙÙ†ÙŠ
        fig = px.bar(tech_stats, x='Technician', y='Ù…ØªÙˆØ³Ø·_Ø§Ù„Ù…Ø¯Ø©',
                    title='Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø­Ø³Ø¨ Ø§Ù„ÙÙ†ÙŠ',
                    color='Ø¹Ø¯Ø¯_Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª',
                    hover_data=['Ø¹Ø¯Ø¯_Ø§Ù„ÙØªØ±Ø§Øª', 'Ø£Ù‚Ù„_Ù…Ø¯Ø©', 'Ø£Ø¹Ù„Ù‰_Ù…Ø¯Ø©'])
        fig.update_layout(xaxis_title="Ø§Ù„ÙÙ†ÙŠ", yaxis_title="Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø©")
        st.plotly_chart(fig, use_container_width=True)
        
    except ImportError:
        st.info("ğŸ“Š Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© plotly")

def show_temporal_distribution_analysis(durations_df):
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø²Ù…Ù†ÙŠ"""
    st.markdown("#### ğŸ“… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø²Ù…Ù†ÙŠ")
    
    if durations_df.empty:
        st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ")
        return
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ù‡Ø± ÙˆØ§Ù„Ø³Ù†Ø© Ù…Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
    def extract_month_year(date_str):
        try:
            date_obj = datetime.strptime(str(date_str), "%d/%m/%Y")
            return date_obj.strftime("%Y-%m")
        except:
            return "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
    
    durations_df['Month_Year'] = durations_df['Current_Event_Date'].apply(extract_month_year)
    
    # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø±
    monthly_stats = durations_df[durations_df['Month_Year'] != 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'].groupby('Month_Year').agg({
        'Duration': ['count', 'mean'],
        'Card Number': 'nunique'
    }).round(2)
    
    monthly_stats.columns = ['Ø¹Ø¯Ø¯_Ø§Ù„Ø£Ø­Ø¯Ø§Ø«', 'Ù…ØªÙˆØ³Ø·_Ø§Ù„Ù…Ø¯Ø©', 'Ø¹Ø¯Ø¯_Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª']
    monthly_stats = monthly_stats.reset_index()
    
    if monthly_stats.empty:
        st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ© ØµØ§Ù„Ø­Ø©")
        return
    
    st.dataframe(monthly_stats, use_container_width=True)
    
    try:
        import plotly.express as px
        
        # Ù…Ø®Ø·Ø· Ø®Ø·ÙŠ Ù„ØªØ·ÙˆØ± Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù…Ø¹ Ø§Ù„ÙˆÙ‚Øª
        fig1 = px.line(monthly_stats, x='Month_Year', y='Ø¹Ø¯Ø¯_Ø§Ù„Ø£Ø­Ø¯Ø§Ø«',
                      title='ØªØ·ÙˆØ± Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø´Ù‡Ø±ÙŠ',
                      markers=True)
        fig1.update_layout(xaxis_title="Ø§Ù„Ø´Ù‡Ø±", yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«")
        st.plotly_chart(fig1, use_container_width=True)
        
        # Ù…Ø®Ø·Ø· Ø®Ø·ÙŠ Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© Ù…Ø¹ Ø§Ù„ÙˆÙ‚Øª
        fig2 = px.line(monthly_stats, x='Month_Year', y='Ù…ØªÙˆØ³Ø·_Ø§Ù„Ù…Ø¯Ø©',
                      title='ØªØ·ÙˆØ± Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø­Ø¯Ø§Ø«',
                      markers=True)
        fig2.update_layout(xaxis_title="Ø§Ù„Ø´Ù‡Ø±", yaxis_title="Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø©")
        st.plotly_chart(fig2, use_container_width=True)
        
    except ImportError:
        st.info("ğŸ“Š Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© plotly")

def show_event_correction_comparison(durations_df):
    """Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø­Ø¯Ø« Ø§Ù„Ø¹Ø§Ø¯ÙŠ ÙˆØ§Ù„ØªØµØ­ÙŠØ­"""
    st.markdown("#### âš–ï¸ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø­Ø¯Ø« ÙˆØ§Ù„ØªØµØ­ÙŠØ­")
    
    if durations_df.empty:
        st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
        return
    
    # ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø­Ø¯Ø«
    event_type_stats = durations_df.groupby('Event_Type').agg({
        'Duration': ['count', 'mean', 'std', 'min', 'max'],
        'Card Number': 'nunique'
    }).round(2)
    
    event_type_stats.columns = ['Ø¹Ø¯Ø¯_Ø§Ù„ÙØªØ±Ø§Øª', 'Ù…ØªÙˆØ³Ø·_Ø§Ù„Ù…Ø¯Ø©', 'Ø§Ù†Ø­Ø±Ø§Ù_Ù…Ø¹ÙŠØ§Ø±ÙŠ', 'Ø£Ù‚Ù„_Ù…Ø¯Ø©', 'Ø£Ø¹Ù„Ù‰_Ù…Ø¯Ø©', 'Ø¹Ø¯Ø¯_Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª']
    event_type_stats = event_type_stats.reset_index()
    
    st.dataframe(event_type_stats, use_container_width=True)
    
    try:
        import plotly.express as px
        
        # Ù…Ø®Ø·Ø· Ø¯Ø§Ø¦Ø±ÙŠ Ù„ØªÙˆØ²ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«
        fig1 = px.pie(event_type_stats, values='Ø¹Ø¯Ø¯_Ø§Ù„ÙØªØ±Ø§Øª', names='Event_Type',
                     title='ØªÙˆØ²ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«')
        st.plotly_chart(fig1, use_container_width=True)
        
        # Ù…Ø®Ø·Ø· Ø´Ø±ÙŠØ·ÙŠ Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        fig2 = px.bar(event_type_stats, x='Event_Type', y='Ù…ØªÙˆØ³Ø·_Ø§Ù„Ù…Ø¯Ø©',
                     title='Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø­Ø¯Ø«',
                     color='Ø¹Ø¯Ø¯_Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø§Øª',
                     hover_data=['Ø¹Ø¯Ø¯_Ø§Ù„ÙØªØ±Ø§Øª', 'Ø£Ù‚Ù„_Ù…Ø¯Ø©', 'Ø£Ø¹Ù„Ù‰_Ù…Ø¯Ø©'])
        fig2.update_layout(xaxis_title="Ù†ÙˆØ¹ Ø§Ù„Ø­Ø¯Ø«", yaxis_title="Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ø©")
        st.plotly_chart(fig2, use_container_width=True)
        
    except ImportError:
        st.info("ğŸ“Š Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© plotly")

# ===============================
# ğŸ–¥ Ø¯ÙˆØ§Ù„ Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©
# ===============================
def display_dynamic_sheets(sheets_edit):
    """Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ø¨Ø´ÙƒÙ„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ"""
    st.subheader("ğŸ“‚ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª")
    
    if not sheets_edit:
        st.warning("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø´ÙŠØªØ§Øª Ù…ØªØ§Ø­Ø©")
        return
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù„ÙƒÙ„ Ø´ÙŠØª
    sheet_tabs = st.tabs(list(sheets_edit.keys()))
    
    for i, (sheet_name, df) in enumerate(sheets_edit.items()):
        with sheet_tabs[i]:
            st.markdown(f"### ğŸ“‹ {sheet_name}")
            st.info(f"Ø§Ù„ØµÙÙˆÙ: {len(df)} | Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {len(df.columns)}")
            
            # Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            if st.checkbox(f"Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©", key=f"show_all_{sheet_name}"):
                st.dataframe(df, use_container_width=True)
            else:
                # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙ‚Ø·
                display_cols = []
                for col in df.columns:
                    col_lower = str(col).lower()
                    if any(keyword in col_lower for keyword in ['card', 'date', 'event', 'correction', 'servised', 'serviced', 'images', 'ØµÙˆØ±', 'technician', 'ÙÙ†ÙŠ']):
                        display_cols.append(col)
                
                if display_cols:
                    st.dataframe(df[display_cols], use_container_width=True)
                else:
                    st.dataframe(df.head(10), use_container_width=True)
            
            # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            with st.expander("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø´ÙŠØª", expanded=False):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ", len(df))
                with col2:
                    st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©", len(df.columns))
                with col3:
                    non_empty = df.notna().sum().sum()
                    total_cells = len(df) * len(df.columns)
                    st.metric("Ø®Ù„Ø§ÙŠØ§ ØºÙŠØ± ÙØ§Ø±ØºØ©", f"{non_empty}/{total_cells}")

# -------------------------------
# ğŸ–¥ Ø¯Ø§Ù„Ø© Ø¥Ø¶Ø§ÙØ© Ø¥ÙŠÙÙŠÙ†Øª Ø¬Ø¯ÙŠØ¯ - Ù…Ø¹ Ø®Ø§ØµÙŠØ© Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±
# -------------------------------
def add_new_event(sheets_edit):
    """Ø¥Ø¶Ø§ÙØ© Ø¥ÙŠÙÙŠÙ†Øª Ø¬Ø¯ÙŠØ¯ ÙÙŠ Ø´ÙŠØª Ù…Ù†ÙØµÙ„ Ù…Ø¹ Ø®Ø§ØµÙŠØ© Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±"""
    st.subheader("â• Ø¥Ø¶Ø§ÙØ© Ø­Ø¯Ø« Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ ØµÙˆØ±")
    
    sheet_name = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØª:", list(sheets_edit.keys()), key="add_event_sheet")
    df = sheets_edit[sheet_name].astype(str)
    
    st.markdown("Ø£Ø¯Ø®Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø¯Ø« Ø§Ù„Ø¬Ø¯ÙŠØ¯:")
    
    col1, col2 = st.columns(2)
    with col1:
        card_num = st.text_input("Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©/Ø§Ù„Ù…Ø¹Ø±Ù:", key="new_event_card")
        event_text = st.text_area("Ø§Ù„Ø­Ø¯Ø«:", key="new_event_text")
    with col2:
        correction_text = st.text_area("Ø§Ù„ØªØµØ­ÙŠØ­:", key="new_correction_text")
        serviced_by = st.text_input("ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©:", key="new_serviced_by")
    
    event_date = st.text_input("Ø§Ù„ØªØ§Ø±ÙŠØ® (Ù…Ø«Ø§Ù„: 20/5/2025):", key="new_event_date")
    
    # Ù‚Ø³Ù… Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±
    st.markdown("---")
    st.markdown("### ğŸ“· Ø±ÙØ¹ ØµÙˆØ± Ù„Ù„Ø­Ø¯Ø« (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±
    uploaded_files = st.file_uploader(
        "Ø§Ø®ØªØ± Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±ÙÙ‚Ø© Ù„Ù„Ø­Ø¯Ø«:",
        type=APP_CONFIG["ALLOWED_IMAGE_TYPES"],
        accept_multiple_files=True,
        key="event_images_uploader"
    )
    
    if uploaded_files:
        st.info(f"ğŸ“ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± {len(uploaded_files)} ØµÙˆØ±Ø©")
        # Ø¹Ø±Ø¶ Ù…Ø¹Ø§ÙŠÙ†Ø© Ù„Ù„ØµÙˆØ± Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
        preview_cols = st.columns(min(3, len(uploaded_files)))
        for idx, uploaded_file in enumerate(uploaded_files):
            with preview_cols[idx % 3]:
                try:
                    st.image(uploaded_file, caption=uploaded_file.name, use_column_width=True)
                except:
                    st.write(f"ğŸ“· {uploaded_file.name}")
    
    if st.button("ğŸ’¾ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø­Ø¯Ø« Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ Ø§Ù„ØµÙˆØ±", key="add_new_event_btn"):
        if not card_num.strip():
            st.warning("âš  Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©.")
            return
        
        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©
        saved_images = []
        if uploaded_files:
            saved_images = save_uploaded_images(uploaded_files)
            if saved_images:
                st.success(f"âœ… ØªÙ… Ø­ÙØ¸ {len(saved_images)} ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­")
        
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙ Ø¬Ø¯ÙŠØ¯
        new_row = {}
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        new_row["card"] = card_num.strip()
        if event_date.strip():
            new_row["Date"] = event_date.strip()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø­Ø¯Ø« ÙˆØ§Ù„ØªØµØ­ÙŠØ­ ÙˆØ§Ù„ÙÙ†ÙŠ
        for col in df.columns:
            col_lower = str(col).lower()
            if "event" in col_lower or "Ø­Ø¯Ø«" in col_lower:
                if event_text.strip():
                    new_row[col] = event_text.strip()
            elif "correction" in col_lower or "ØªØµØ­ÙŠØ­" in col_lower:
                if correction_text.strip():
                    new_row[col] = correction_text.strip()
            elif "servis" in col_lower or "service" in col_lower or "ÙÙ†ÙŠ" in col_lower:
                if serviced_by.strip():
                    new_row[col] = serviced_by.strip()
            elif "images" in col_lower or "ØµÙˆØ±" in col_lower:
                if saved_images:
                    new_row[col] = ", ".join(saved_images)
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯
        new_row_df = pd.DataFrame([new_row]).astype(str)
        df_new = pd.concat([df, new_row_df], ignore_index=True)
        
        sheets_edit[sheet_name] = df_new.astype(object)
        
        # Ø­ÙØ¸ ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙÙŠ GitHub
        new_sheets = auto_save_to_github(
            sheets_edit,
            f"Ø¥Ø¶Ø§ÙØ© Ø­Ø¯Ø« Ø¬Ø¯ÙŠØ¯ ÙÙŠ {sheet_name}" + (f" Ù…Ø¹ {len(saved_images)} ØµÙˆØ±Ø©" if saved_images else "")
        )
        if new_sheets is not None:
            sheets_edit = new_sheets
            st.success("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø­Ø¯Ø« Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­!")
            
            # Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ
            with st.expander("ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„Ø­Ø¯Ø« Ø§Ù„Ù…Ø¶Ø§ÙØ©", expanded=True):
                st.markdown(f"**Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©:** {card_num}")
                st.markdown(f"**Ø§Ù„Ø­Ø¯Ø«:** {event_text[:100]}{'...' if len(event_text) > 100 else ''}")
                if saved_images:
                    st.markdown(f"**Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±ÙÙ‚Ø©:** {len(saved_images)}")
                    display_images(saved_images, "Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©")
            
            st.rerun()

# -------------------------------
# ğŸ–¥ Ø¯Ø§Ù„Ø© ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù† - Ù…Ø¹ Ø®Ø§ØµÙŠØ© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµÙˆØ±
# -------------------------------
def edit_events_and_corrections(sheets_edit):
    """ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø­Ø¯Ø« ÙˆØ§Ù„ØªØµØ­ÙŠØ­ ÙˆØ§Ù„ØµÙˆØ±"""
    st.subheader("âœ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø­Ø¯Ø« ÙˆØ§Ù„ØªØµØ­ÙŠØ­ ÙˆØ§Ù„ØµÙˆØ±")
    
    sheet_name = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØª:", list(sheets_edit.keys()), key="edit_events_sheet")
    df = sheets_edit[sheet_name].astype(str)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    st.markdown("### ğŸ“‹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©")
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    display_columns = []
    
    for col in df.columns:
        col_lower = str(col).lower()
        if any(keyword in col_lower for keyword in ['card', 'date', 'event', 'correction', 'servis', 'service', 'ÙÙ†ÙŠ', 'images', 'ØµÙˆØ±']):
            display_columns.append(col)
    
    # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ø¶Ø­Ø©ØŒ Ù†Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 Ø£Ø¹Ù…Ø¯Ø©
    if not display_columns and len(df.columns) > 0:
        display_columns = list(df.columns[:5])
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    display_df = df[display_columns].copy()
    st.dataframe(display_df, use_container_width=True)
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØµÙ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„
    st.markdown("### âœ Ø§Ø®ØªØ± Ø§Ù„ØµÙ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„")
    row_index = st.number_input("Ø±Ù‚Ù… Ø§Ù„ØµÙ (Ø§Ø¨Ø¯Ø£ Ù…Ù† 0):", min_value=0, max_value=len(df)-1, step=1, key="edit_row_index")
    
    if st.button("ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙ", key="load_row_data"):
        if 0 <= row_index < len(df):
            st.session_state["editing_row"] = row_index
            st.session_state["editing_data"] = df.iloc[row_index].to_dict()
    
    if "editing_data" in st.session_state:
        editing_data = st.session_state["editing_data"]
        
        st.markdown("### ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        card_col = None
        date_col = None
        event_col = None
        correction_col = None
        tech_col = None
        images_col = None
        
        for col in df.columns:
            col_lower = str(col).lower()
            if "card" in col_lower or "Ø±Ù‚Ù…" in col_lower:
                card_col = col
            elif "date" in col_lower or "ØªØ§Ø±ÙŠØ®" in col_lower:
                date_col = col
            elif "event" in col_lower or "Ø­Ø¯Ø«" in col_lower:
                event_col = col
            elif "correction" in col_lower or "ØªØµØ­ÙŠØ­" in col_lower:
                correction_col = col
            elif "servis" in col_lower or "service" in col_lower or "ÙÙ†ÙŠ" in col_lower:
                tech_col = col
            elif "images" in col_lower or "ØµÙˆØ±" in col_lower:
                images_col = col
        
        col1, col2 = st.columns(2)
        with col1:
            if card_col:
                new_card = st.text_input("Ø±Ù‚Ù… Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø©:", value=editing_data.get(card_col, ""), key="edit_card")
            if date_col:
                new_date = st.text_input("Ø§Ù„ØªØ§Ø±ÙŠØ®:", value=editing_data.get(date_col, ""), key="edit_date")
        with col2:
            if tech_col:
                new_serviced_by = st.text_input("ÙÙ†ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©:", value=editing_data.get(tech_col, ""), key="edit_serviced_by")
        
        # Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†
        if event_col:
            new_event = st.text_area("Ø§Ù„Ø­Ø¯Ø«:", value=editing_data.get(event_col, ""), key="edit_event")
        if correction_col:
            new_correction = st.text_area("Ø§Ù„ØªØµØ­ÙŠØ­:", value=editing_data.get(correction_col, ""), key="edit_correction")
        
        # Ù‚Ø³Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµÙˆØ±
        st.markdown("---")
        st.markdown("### ğŸ“· Ø¥Ø¯Ø§Ø±Ø© ØµÙˆØ± Ø§Ù„Ø­Ø¯Ø«")
        
        existing_images = []
        if images_col and images_col in editing_data:
            existing_images_str = editing_data.get(images_col, "")
            if existing_images_str and existing_images_str != "-":
                existing_images = [img.strip() for img in existing_images_str.split(",") if img.strip()]
        
        # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        if existing_images:
            st.markdown("**Ø§Ù„ØµÙˆØ± Ø§Ù„Ø­Ø§Ù„ÙŠØ©:**")
            display_images(existing_images, "")
            
            # Ø®ÙŠØ§Ø± Ø­Ø°Ù Ø§Ù„ØµÙˆØ±
            if st.checkbox("ğŸ—‘ï¸ Ø­Ø°Ù ÙƒÙ„ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø­Ø§Ù„ÙŠØ©", key="delete_existing_images"):
                existing_images = []
        
        # Ø¥Ø¶Ø§ÙØ© ØµÙˆØ± Ø¬Ø¯ÙŠØ¯Ø©
        st.markdown("**Ø¥Ø¶Ø§ÙØ© ØµÙˆØ± Ø¬Ø¯ÙŠØ¯Ø©:**")
        new_uploaded_files = st.file_uploader(
            "Ø§Ø®ØªØ± ØµÙˆØ± Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø¥Ø¶Ø§ÙØªÙ‡Ø§:",
            type=APP_CONFIG["ALLOWED_IMAGE_TYPES"],
            accept_multiple_files=True,
            key="edit_images_uploader"
        )
        
        all_images = existing_images.copy()
        
        if new_uploaded_files:
            st.info(f"ğŸ“ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± {len(new_uploaded_files)} ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©")
            # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            new_saved_images = save_uploaded_images(new_uploaded_files)
            if new_saved_images:
                all_images.extend(new_saved_images)
                st.success(f"âœ… ØªÙ… Ø­ÙØ¸ {len(new_saved_images)} ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©")
        
        if st.button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª ÙˆØ§Ù„ØµÙˆØ±", key="save_edits_btn"):
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if card_col:
                df.at[row_index, card_col] = new_card
            if date_col:
                df.at[row_index, date_col] = new_date
            if event_col:
                df.at[row_index, event_col] = new_event
            if correction_col:
                df.at[row_index, correction_col] = new_correction
            if tech_col:
                df.at[row_index, tech_col] = new_serviced_by.strip()
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙˆØ±
            if images_col:
                if all_images:
                    df.at[row_index, images_col] = ", ".join(all_images)
                else:
                    df.at[row_index, images_col] = ""
            
            sheets_edit[sheet_name] = df.astype(object)
            
            # Ø­ÙØ¸ ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙÙŠ GitHub
            new_sheets = auto_save_to_github(
                sheets_edit,
                f"ØªØ¹Ø¯ÙŠÙ„ Ø­Ø¯Ø« ÙÙŠ {sheet_name} - Ø§Ù„ØµÙ {row_index}" + (f" Ù…Ø¹ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙˆØ±" if all_images else "")
            )
            if new_sheets is not None:
                sheets_edit = new_sheets
                st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
                
                # Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ
                if all_images:
                    st.info(f"ğŸ“· Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„ØµÙˆØ±: {len(all_images)}")
                    display_images(all_images, "Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©")
                
                # Ù…Ø³Ø­ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©
                if "editing_row" in st.session_state:
                    del st.session_state["editing_row"]
                if "editing_data" in st.session_state:
                    del st.session_state["editing_data"]
                st.rerun()

# -------------------------------
# ğŸ–¥ Ø¯Ø§Ù„Ø© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø´ÙŠØªØ§Øª ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø©
# -------------------------------
def manage_sheets_and_columns(sheets_edit):
    """Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø´ÙŠØªØ§Øª ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø©"""
    st.subheader("ğŸ—‚ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø´ÙŠØªØ§Øª ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø©")
    
    if not sheets_edit:
        st.warning("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø©")
        return sheets_edit
    
    # ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù„Ù„Ø¥Ø¯Ø§Ø±Ø©
    manage_tabs = st.tabs(["â• Ø¥Ù†Ø´Ø§Ø¡ Ø´ÙŠØª Ø¬Ø¯ÙŠØ¯", "âœ Ø¥Ø¯Ø§Ø±Ø© Ø£Ø¹Ù…Ø¯Ø© Ø´ÙŠØª", "ğŸ—‘ Ø­Ø°Ù Ø´ÙŠØª"])
    
    with manage_tabs[0]:
        st.markdown("### â• Ø¥Ù†Ø´Ø§Ø¡ Ø´ÙŠØª Ø¬Ø¯ÙŠØ¯")
        
        col1, col2 = st.columns(2)
        
        with col1:
            new_sheet_name = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø´ÙŠØª Ø§Ù„Ø¬Ø¯ÙŠØ¯:", placeholder="Ù…Ø«Ø§Ù„: Card10 Ø£Ùˆ ServiceLog", key="new_sheet_name")
            
            # Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            column_template = st.selectbox(
                "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:",
                ["Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©", "Ù†Ø³Ø® Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ø´ÙŠØª Ù…ÙˆØ¬ÙˆØ¯", "ØªØ­Ø¯ÙŠØ¯ Ø£Ø¹Ù…Ø¯Ø© Ù…Ø®ØµØµØ©"],
                key="column_template"
            )
        
        with col2:
            if column_template == "Ù†Ø³Ø® Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ø´ÙŠØª Ù…ÙˆØ¬ÙˆØ¯":
                source_sheet = st.selectbox(
                    "Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØª Ù„Ù†Ø³Ø® Ø£Ø¹Ù…Ø¯Ø© Ù…Ù†Ù‡:",
                    list(sheets_edit.keys()),
                    key="source_sheet_for_columns"
                )
            elif column_template == "ØªØ­Ø¯ÙŠØ¯ Ø£Ø¹Ù…Ø¯Ø© Ù…Ø®ØµØµØ©":
                custom_columns = st.text_area(
                    "Ø£Ø¯Ø®Ù„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„):",
                    placeholder="Ù…Ø«Ø§Ù„: card, Date, Event, Correction, Servised by",
                    key="custom_columns"
                )
        
        # Ø®ÙŠØ§Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
        initial_rows = st.number_input("Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©:", min_value=0, max_value=100, value=0, step=1, key="initial_rows")
        
        if st.button("ğŸš€ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø´ÙŠØª Ø§Ù„Ø¬Ø¯ÙŠØ¯", key="create_new_sheet_btn", type="primary"):
            if not new_sheet_name.strip():
                st.warning("âš  Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ù„Ù„Ø´ÙŠØª Ø§Ù„Ø¬Ø¯ÙŠØ¯")
                return sheets_edit
            
            if new_sheet_name in sheets_edit:
                st.warning(f"âš  Ø§Ù„Ø´ÙŠØª '{new_sheet_name}' Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„!")
                return sheets_edit
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            columns_to_use = APP_CONFIG["DEFAULT_COLUMNS"]
            
            if column_template == "Ù†Ø³Ø® Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ø´ÙŠØª Ù…ÙˆØ¬ÙˆØ¯" and source_sheet in sheets_edit:
                columns_to_use = list(sheets_edit[source_sheet].columns)
            
            elif column_template == "ØªØ­Ø¯ÙŠØ¯ Ø£Ø¹Ù…Ø¯Ø© Ù…Ø®ØµØµØ©" and custom_columns.strip():
                columns_to_use = [col.strip() for col in custom_columns.split(',') if col.strip()]
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø´ÙŠØª Ø§Ù„Ø¬Ø¯ÙŠØ¯
            new_df = pd.DataFrame(columns=columns_to_use)
            sheets_edit[new_sheet_name] = new_df
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø¥Ø°Ø§ Ø·Ù„Ø¨
            if initial_rows > 0:
                empty_data = {col: [""] * initial_rows for col in columns_to_use}
                sheets_edit[new_sheet_name] = pd.DataFrame(empty_data)
            
            # Ø­ÙØ¸ ÙÙŠ GitHub
            new_sheets = auto_save_to_github(
                sheets_edit,
                f"Ø¥Ù†Ø´Ø§Ø¡ Ø´ÙŠØª Ø¬Ø¯ÙŠØ¯ '{new_sheet_name}' Ù…Ø¹ {len(columns_to_use)} Ø£Ø¹Ù…Ø¯Ø©"
            )
            
            if new_sheets is not None:
                sheets_edit = new_sheets
                st.success(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø´ÙŠØª '{new_sheet_name}' Ø¨Ù†Ø¬Ø§Ø­!")
                st.info(f"Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {', '.join(columns_to_use[:5])}{'...' if len(columns_to_use) > 5 else ''}")
                st.rerun()
    
    with manage_tabs[1]:
        st.markdown("### âœ Ø¥Ø¯Ø§Ø±Ø© Ø£Ø¹Ù…Ø¯Ø© Ø´ÙŠØª")
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø´ÙŠØª
        selected_sheet = st.selectbox(
            "Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØª:",
            list(sheets_edit.keys()),
            key="selected_sheet_for_columns"
        )
        
        if selected_sheet:
            df = sheets_edit[selected_sheet]
            columns = list(df.columns)
            
            st.markdown(f"**Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙÙŠ '{selected_sheet}':**")
            st.info(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {len(columns)}")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
            columns_df = pd.DataFrame({
                "Ø§Ù„Ø±Ù‚Ù…": range(1, len(columns) + 1),
                "Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯": columns,
                "Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª": [str(df[col].dtype) for col in columns]
            })
            
            st.dataframe(columns_df, use_container_width=True)
            
            # ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª
            column_ops_tabs = st.tabs(["Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø¹Ù…ÙˆØ¯", "Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯", "Ø­Ø°Ù Ø¹Ù…ÙˆØ¯", "Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©"])
            
            with column_ops_tabs[0]:
                st.markdown("#### Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø¹Ù…ÙˆØ¯")
                
                col_rename1, col_rename2 = st.columns(2)
                
                with col_rename1:
                    old_column_name = st.selectbox(
                        "Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ³Ù…ÙŠØ©:",
                        columns,
                        key="old_column_name"
                    )
                
                with col_rename2:
                    new_column_name = st.text_input(
                        "Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ø¹Ù…ÙˆØ¯:",
                        value=old_column_name if 'old_column_name' in locals() else "",
                        key="new_column_name_input"
                    )
                
                if st.button("âœï¸ Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ©", key="rename_column_btn"):
                    if old_column_name and new_column_name and old_column_name != new_column_name:
                        df.rename(columns={old_column_name: new_column_name}, inplace=True)
                        sheets_edit[selected_sheet] = df
                        
                        new_sheets = auto_save_to_github(
                            sheets_edit,
                            f"Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø¹Ù…ÙˆØ¯ '{old_column_name}' Ø¥Ù„Ù‰ '{new_column_name}' ÙÙŠ Ø´ÙŠØª '{selected_sheet}'"
                        )
                        
                        if new_sheets is not None:
                            sheets_edit = new_sheets
                            st.success(f"âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ '{old_column_name}' Ø¥Ù„Ù‰ '{new_column_name}'")
                            st.rerun()
                    else:
                        st.warning("âš  Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø¹Ù…ÙˆØ¯ ÙˆØ¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø¬Ø¯ÙŠØ¯ Ù…Ø®ØªÙ„Ù")
            
            with column_ops_tabs[1]:
                st.markdown("#### Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯")
                
                new_column_name_add = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯:", key="new_column_to_add")
                default_value_add = st.text_input("Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ):", key="default_value_for_new_column")
                
                if st.button("â• Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯", key="add_new_column_btn"):
                    if new_column_name_add:
                        if new_column_name_add not in df.columns:
                            df[new_column_name_add] = default_value_add if default_value_add else ""
                            sheets_edit[selected_sheet] = df
                            
                            new_sheets = auto_save_to_github(
                                sheets_edit,
                                f"Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯ '{new_column_name_add}' Ø¥Ù„Ù‰ Ø´ÙŠØª '{selected_sheet}'"
                            )
                            
                            if new_sheets is not None:
                                sheets_edit = new_sheets
                                st.success(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ '{new_column_name_add}'")
                                st.rerun()
                        else:
                            st.warning(f"âš  Ø§Ù„Ø¹Ù…ÙˆØ¯ '{new_column_name_add}' Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„!")
                    else:
                        st.warning("âš  Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ù„Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯")
            
            with column_ops_tabs[2]:
                st.markdown("#### Ø­Ø°Ù Ø¹Ù…ÙˆØ¯")
                
                column_to_delete = st.selectbox(
                    "Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù„Ù„Ø­Ø°Ù:",
                    columns,
                    key="column_to_delete"
                )
                
                if st.button("ğŸ—‘ Ø­Ø°Ù Ø§Ù„Ø¹Ù…ÙˆØ¯", key="delete_column_btn", type="secondary"):
                    if column_to_delete:
                        confirm = st.checkbox(f"Ù‡Ù„ Ø£Ù†Øª Ù…ØªØ£ÙƒØ¯ Ù…Ù† Ø­Ø°Ù Ø§Ù„Ø¹Ù…ÙˆØ¯ '{column_to_delete}'ØŸ")
                        
                        if confirm:
                            df.drop(columns=[column_to_delete], inplace=True)
                            sheets_edit[selected_sheet] = df
                            
                            new_sheets = auto_save_to_github(
                                sheets_edit,
                                f"Ø­Ø°Ù Ø¹Ù…ÙˆØ¯ '{column_to_delete}' Ù…Ù† Ø´ÙŠØª '{selected_sheet}'"
                            )
                            
                            if new_sheets is not None:
                                sheets_edit = new_sheets
                                st.success(f"âœ… ØªÙ… Ø­Ø°Ù Ø§Ù„Ø¹Ù…ÙˆØ¯ '{column_to_delete}'")
                                st.rerun()
            
            with column_ops_tabs[3]:
                st.markdown("#### Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©")
                
                st.info("Ø§Ø³Ø­Ø¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨Ù‡Ø§:")
                
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… multiselect Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„ØªØ±ØªÙŠØ¨
                column_order = st.multiselect(
                    "ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:",
                    columns,
                    default=columns,
                    key="column_order_multiselect"
                )
                
                if st.button("ğŸ”„ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯", key="apply_column_order_btn"):
                    if len(column_order) == len(columns):
                        df = df[column_order]
                        sheets_edit[selected_sheet] = df
                        
                        new_sheets = auto_save_to_github(
                            sheets_edit,
                            f"Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø£Ø¹Ù…Ø¯Ø© Ø´ÙŠØª '{selected_sheet}'"
                        )
                        
                        if new_sheets is not None:
                            sheets_edit = new_sheets
                            st.success("âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¨Ù†Ø¬Ø§Ø­!")
                            st.rerun()
                    else:
                        st.warning("âš  ÙŠØ¬Ø¨ Ø§Ø®ØªÙŠØ§Ø± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„ØªØ±ØªÙŠØ¨")
    
    with manage_tabs[2]:
        st.markdown("### ğŸ—‘ Ø­Ø°Ù Ø´ÙŠØª")
        
        sheet_to_delete = st.selectbox(
            "Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØª Ù„Ù„Ø­Ø°Ù:",
            list(sheets_edit.keys()),
            key="sheet_to_delete"
        )
        
        if sheet_to_delete:
            st.warning(f"âš  ØªØ­Ø°ÙŠØ±: Ø³ÙŠØªÙ… Ø­Ø°Ù Ø§Ù„Ø´ÙŠØª '{sheet_to_delete}' Ø¨Ø´ÙƒÙ„ Ø¯Ø§Ø¦Ù…!")
            
            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´ÙŠØª
            if sheet_to_delete in sheets_edit:
                df_to_delete = sheets_edit[sheet_to_delete]
                st.info(f"Ø§Ù„Ø´ÙŠØª ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰: {len(df_to_delete)} ØµÙ Ùˆ {len(df_to_delete.columns)} Ø¹Ù…ÙˆØ¯")
            
            confirm_delete = st.checkbox(f"Ø£Ù†Ø§ Ø£Ø¯Ø±Ùƒ Ø£Ù† Ø­Ø°Ù Ø§Ù„Ø´ÙŠØª '{sheet_to_delete}' Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¹Ù†Ù‡", key="confirm_sheet_delete")
            
            if st.button("ğŸ—‘ï¸ Ø­Ø°Ù Ø§Ù„Ø´ÙŠØª Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹", key="delete_sheet_btn", disabled=not confirm_delete, type="secondary"):
                if confirm_delete:
                    # Ø­Ø°Ù Ø§Ù„Ø´ÙŠØª
                    del sheets_edit[sheet_to_delete]
                    
                    new_sheets = auto_save_to_github(
                        sheets_edit,
                        f"Ø­Ø°Ù Ø´ÙŠØª '{sheet_to_delete}'"
                    )
                    
                    if new_sheets is not None:
                        sheets_edit = new_sheets
                        st.success(f"âœ… ØªÙ… Ø­Ø°Ù Ø§Ù„Ø´ÙŠØª '{sheet_to_delete}' Ø¨Ù†Ø¬Ø§Ø­!")
                        st.rerun()
    
    return sheets_edit

# -------------------------------
# ğŸ–¥ Ø¯Ø§Ù„Ø© ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø´ÙŠØª Ù…Ø¹ Ø²Ø± Ø­ÙØ¸ ÙŠØ¯ÙˆÙŠ
# -------------------------------
def edit_sheet_with_save_button(sheets_edit):
    """ØªØ¹Ø¯ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´ÙŠØª Ù…Ø¹ Ø²Ø± Ø­ÙØ¸ ÙŠØ¯ÙˆÙŠ"""
    st.subheader("âœ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    
    if "original_sheets" not in st.session_state:
        st.session_state.original_sheets = sheets_edit.copy()
    
    if "unsaved_changes" not in st.session_state:
        st.session_state.unsaved_changes = {}
    
    sheet_name = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØª:", list(sheets_edit.keys()), key="edit_sheet")
    
    if sheet_name not in st.session_state.unsaved_changes:
        st.session_state.unsaved_changes[sheet_name] = False
    
    df = sheets_edit[sheet_name].astype(str).copy()
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ø±ÙŠØ±
    st.markdown(f"### ğŸ“‹ ØªØ­Ø±ÙŠØ± Ø´ÙŠØª: {sheet_name}")
    st.info(f"Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ: {len(df)} | Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {len(df.columns)}")
    
    # Ù…Ø­Ø±Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    edited_df = st.data_editor(
        df, 
        num_rows="dynamic", 
        use_container_width=True,
        key=f"editor_{sheet_name}"
    )
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ØªØºÙŠÙŠØ±Ø§Øª
    has_changes = not edited_df.equals(df)
    
    if has_changes:
        st.session_state.unsaved_changes[sheet_name] = True
        
        # Ø¹Ø±Ø¶ Ø¥Ø´Ø¹Ø§Ø± Ø¨Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
        st.warning("âš  Ù„Ø¯ÙŠÙƒ ØªØºÙŠÙŠØ±Ø§Øª ØºÙŠØ± Ù…Ø­ÙÙˆØ¸Ø©!")
        
        # Ø£Ø²Ø±Ø§Ø± Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            if st.button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª", key=f"save_{sheet_name}", type="primary"):
                # Ø­ÙØ¸ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
                sheets_edit[sheet_name] = edited_df.astype(object)
                
                # Ø­ÙØ¸ ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙÙŠ GitHub
                new_sheets = auto_save_to_github(
                    sheets_edit,
                    f"ØªØ¹Ø¯ÙŠÙ„ ÙŠØ¯ÙˆÙŠ ÙÙŠ Ø´ÙŠØª {sheet_name}"
                )
                
                if new_sheets is not None:
                    sheets_edit = new_sheets
                    st.session_state.unsaved_changes[sheet_name] = False
                    st.success(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ø´ÙŠØª {sheet_name} Ø¨Ù†Ø¬Ø§Ø­!")
                    
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©
                    st.session_state.original_sheets[sheet_name] = edited_df.copy()
                    
                    # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ø¹Ø¯ Ø«Ø§Ù†ÙŠØ©
                    import time
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª!")
        
        with col2:
            if st.button("â†©ï¸ ØªØ±Ø§Ø¬Ø¹ Ø¹Ù† Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª", key=f"undo_{sheet_name}"):
                # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©
                if sheet_name in st.session_state.original_sheets:
                    sheets_edit[sheet_name] = st.session_state.original_sheets[sheet_name].astype(object)
                    st.session_state.unsaved_changes[sheet_name] = False
                    st.info(f"â†©ï¸ ØªÙ… Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¹Ù† Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ø´ÙŠØª {sheet_name}")
                    st.rerun()
                else:
                    st.warning("âš  Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø£ØµÙ„ÙŠØ© Ù„Ù„ØªØ±Ø§Ø¬Ø¹!")
        
        with col3:
            # Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
            with st.expander("ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª", expanded=False):
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª
                changes_count = 0
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…Ø¶Ø§ÙØ©
                if len(edited_df) > len(df):
                    added_rows = len(edited_df) - len(df)
                    st.write(f"â• **ØµÙÙˆÙ Ù…Ø¶Ø§ÙØ©:** {added_rows}")
                    changes_count += added_rows
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©
                elif len(edited_df) < len(df):
                    deleted_rows = len(df) - len(edited_df)
                    st.write(f"ğŸ—‘ï¸ **ØµÙÙˆÙ Ù…Ø­Ø°ÙˆÙØ©:** {deleted_rows}")
                    changes_count += deleted_rows
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„Ù‚ÙŠÙ…
                changed_cells = 0
                if len(edited_df) == len(df) and edited_df.columns.equals(df.columns):
                    for col in df.columns:
                        if not edited_df[col].equals(df[col]):
                            col_changes = (edited_df[col] != df[col]).sum()
                            changed_cells += col_changes
                
                if changed_cells > 0:
                    st.write(f"âœï¸ **Ø®Ù„Ø§ÙŠØ§ Ù…Ø¹Ø¯Ù„Ø©:** {changed_cells}")
                    changes_count += changed_cells
                
                if changes_count == 0:
                    st.write("ğŸ”„ **Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØºÙŠÙŠØ±Ø§Øª**")
    else:
        if st.session_state.unsaved_changes.get(sheet_name, False):
            st.info("â„¹ï¸ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© ØªÙ… Ø­ÙØ¸Ù‡Ø§.")
            st.session_state.unsaved_changes[sheet_name] = False
        
        # Ø²Ø± Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if st.button("ğŸ”„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", key=f"refresh_{sheet_name}"):
            st.rerun()
    
    return sheets_edit

# ===============================
# ğŸ–¥ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
# ===============================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title=APP_CONFIG["APP_TITLE"], layout="wide")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ±
setup_images_folder()

# Ø´Ø±ÙŠØ· ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ / Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø© ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
with st.sidebar:
    st.header("ğŸ‘¤ Ø§Ù„Ø¬Ù„Ø³Ø©")
    if not st.session_state.get("logged_in"):
        if not login_ui():
            st.stop()
    else:
        state = cleanup_sessions(load_state())
        username = st.session_state.username
        user_role = st.session_state.user_role
        rem = remaining_time(state, username)
        if rem:
            mins, secs = divmod(int(rem.total_seconds()), 60)
            st.success(f"ğŸ‘‹ {username} | Ø§Ù„Ø¯ÙˆØ±: {user_role} | â³ {mins:02d}:{secs:02d}")
        else:
            logout_action()

    st.markdown("---")
    st.write("ğŸ”§ Ø£Ø¯ÙˆØ§Øª:")
    if st.button("ğŸ”„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„Ù Ù…Ù† GitHub", key="refresh_github"):
        if fetch_from_github_requests():
            st.rerun()
    
    # Ø²Ø± Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´
    if st.button("ğŸ—‘ Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´", key="clear_cache"):
        try:
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´: {e}")
    
    # Ø²Ø± ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ù„Ø³Ø©
    if st.button("ğŸ”„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ù„Ø³Ø©", key="refresh_session"):
        # ØªØ­Ù…ÙŠÙ„ Ø£Ø­Ø¯Ø« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† GitHub
        users = load_users()
        username = st.session_state.get("username")
        if username and username in users:
            st.session_state.user_role = users[username].get("role", "viewer")
            st.session_state.user_permissions = users[username].get("permissions", ["view"])
            st.success("âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©!")
            st.rerun()
        else:
            st.warning("âš  Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ù„Ø³Ø©.")
    
    # Ø²Ø± Ù„Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
    if st.session_state.get("unsaved_changes", {}):
        unsaved_count = sum(1 for v in st.session_state.unsaved_changes.values() if v)
        if unsaved_count > 0:
            st.markdown("---")
            st.warning(f"âš  Ù„Ø¯ÙŠÙƒ {unsaved_count} Ø´ÙŠØª Ø¨Ù‡ ØªØºÙŠÙŠØ±Ø§Øª ØºÙŠØ± Ù…Ø­ÙÙˆØ¸Ø©")
            if st.button("ğŸ’¾ Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª", key="save_all_changes", type="primary"):
                # Ø³ÙŠØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù‡Ø°Ø§ ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
                st.session_state["save_all_requested"] = True
                st.rerun()
    
    # Ø²Ø± Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµÙˆØ±
    st.markdown("---")
    st.markdown("**ğŸ“· Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµÙˆØ±:**")
    if os.path.exists(IMAGES_FOLDER):
        image_files = [f for f in os.listdir(IMAGES_FOLDER) if f.lower().endswith(tuple(APP_CONFIG["ALLOWED_IMAGE_TYPES"]))]
        st.caption(f"Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ±: {len(image_files)}")
    
    st.markdown("---")
    # Ø²Ø± Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬
    if st.button("ğŸšª ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬", key="logout_btn"):
        logout_action()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª (Ø¹Ø±Ø¶ ÙˆØªØ­Ù„ÙŠÙ„)
all_sheets = load_all_sheets()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª Ù„Ù„ØªØ­Ø±ÙŠØ± (dtype=object)
sheets_edit = load_sheets_for_edit()

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.title(f"{APP_CONFIG['APP_ICON']} {APP_CONFIG['APP_TITLE']}")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª - Ø§Ø³ØªØ®Ø¯Ù… .get() Ù„Ù…Ù†Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
username = st.session_state.get("username")
user_role = st.session_state.get("user_role", "viewer")
user_permissions = st.session_state.get("user_permissions", ["view"])
permissions = get_user_permissions(user_role, user_permissions)

# Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
if all_sheets:
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“‚ Ø§Ù„Ø´ÙŠØªØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©")
    
    sheet_list = list(all_sheets.keys())
    selected_sheet_info = st.sidebar.selectbox("Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø´ÙŠØª:", sheet_list)
    
    if selected_sheet_info in all_sheets:
        df_info = all_sheets[selected_sheet_info]
        st.sidebar.info(f"**{selected_sheet_info}:** {len(df_info)} ØµÙ Ã— {len(df_info.columns)} Ø¹Ù…ÙˆØ¯")
        
        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if st.sidebar.checkbox("Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
            st.sidebar.dataframe(df_info.head(3), use_container_width=True)

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª
if permissions["can_manage_users"]:  # admin
    tabs = st.tabs(APP_CONFIG["CUSTOM_TABS"])
    
elif permissions["can_edit"]:  # editor
    tabs = st.tabs(["ğŸ“‹ ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†", "ğŸ›  ØªØ¹Ø¯ÙŠÙ„ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"])
else:  # viewer
    tabs = st.tabs(["ğŸ“‹ ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†"])

# -------------------------------
# Tab: ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù† (Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†)
# -------------------------------
with tabs[0]:
    st.header("ğŸ“‹ ÙØ­Øµ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù†")
    
    if all_sheets is None:
        st.warning("â— Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ø³ØªØ®Ø¯Ù… Ø²Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù…Ù† GitHub.")
    else:
        # ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø­Ø« Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±
        check_events_and_corrections(all_sheets)

# -------------------------------
# Tab: ØªØ¹Ø¯ÙŠÙ„ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª - Ù„Ù„Ù…Ø­Ø±Ø±ÙŠÙ† ÙˆØ§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠÙ† ÙÙ‚Ø·
# -------------------------------
if permissions["can_edit"] and len(tabs) > 1:
    with tabs[1]:
        st.header("ğŸ›  ØªØ¹Ø¯ÙŠÙ„ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

        # ØªØ­Ù‚Ù‚ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø±ÙØ¹
        token_exists = bool(st.secrets.get("github", {}).get("token", None))
        can_push = token_exists and GITHUB_AVAILABLE

        if sheets_edit is None:
            st.warning("â— Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ø¶ØºØ· ØªØ­Ø¯ÙŠØ« Ù…Ù† GitHub ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ø£ÙˆÙ„Ù‹Ø§.")
        else:
            # Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´ÙŠØªØ§Øª Ø£ÙˆÙ„Ø§Ù‹
            display_dynamic_sheets(sheets_edit)
            
            # ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ù„Ø¥Ø¯Ø§Ø±Ø©
            tab_names = [
                "Ø¹Ø±Ø¶ ÙˆØªØ¹Ø¯ÙŠÙ„ Ø´ÙŠØª",
                "Ø¥Ø¶Ø§ÙØ© ØµÙ Ø¬Ø¯ÙŠØ¯", 
                "Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯",
                "â• Ø¥Ø¶Ø§ÙØ© Ø­Ø¯Ø« Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ ØµÙˆØ±",
                "âœ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø­Ø¯Ø« ÙˆØ§Ù„ØµÙˆØ±",
                "ğŸ—‚ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø´ÙŠØªØ§Øª ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø©",
                "ğŸ“· Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµÙˆØ±"
            ]
            
            tabs_edit = st.tabs(tab_names)

            # Tab 1: ØªØ¹Ø¯ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¹Ø±Ø¶
            with tabs_edit[0]:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø·Ù„Ø¨ Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
                if st.session_state.get("save_all_requested", False):
                    st.info("ğŸ’¾ Ø¬Ø§Ø±ÙŠ Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª...")
                    # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© Ù…Ù†Ø·Ù‚ Ù„Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
                    st.session_state["save_all_requested"] = False
                
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù…Ø¹ Ø²Ø± Ø§Ù„Ø­ÙØ¸
                sheets_edit = edit_sheet_with_save_button(sheets_edit)

            # Tab 2: Ø¥Ø¶Ø§ÙØ© ØµÙ Ø¬Ø¯ÙŠØ¯
            with tabs_edit[1]:
                st.subheader("â• Ø¥Ø¶Ø§ÙØ© ØµÙ Ø¬Ø¯ÙŠØ¯")
                sheet_name_add = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØª Ù„Ø¥Ø¶Ø§ÙØ© ØµÙ:", list(sheets_edit.keys()), key="add_sheet")
                df_add = sheets_edit[sheet_name_add].astype(str).reset_index(drop=True)
                
                st.markdown("Ø£Ø¯Ø®Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯:")

                new_data = {}
                cols = st.columns(3)
                for i, col in enumerate(df_add.columns):
                    with cols[i % 3]:
                        new_data[col] = st.text_input(f"{col}", key=f"add_{sheet_name_add}_{col}")

                col_btn1, col_btn2 = st.columns(2)
                with col_btn1:
                    if st.button("ğŸ’¾ Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯", key=f"add_row_{sheet_name_add}", type="primary"):
                        new_row_df = pd.DataFrame([new_data]).astype(str)
                        df_new = pd.concat([df_add, new_row_df], ignore_index=True)
                        
                        sheets_edit[sheet_name_add] = df_new.astype(object)

                        new_sheets = auto_save_to_github(
                            sheets_edit,
                            f"Ø¥Ø¶Ø§ÙØ© ØµÙ Ø¬Ø¯ÙŠØ¯ ÙÙŠ {sheet_name_add}"
                        )
                        if new_sheets is not None:
                            sheets_edit = new_sheets
                            st.success("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­!")
                            st.rerun()
                
                with col_btn2:
                    if st.button("ğŸ—‘ Ù…Ø³Ø­ Ø§Ù„Ø­Ù‚ÙˆÙ„", key=f"clear_{sheet_name_add}"):
                        st.rerun()

            # Tab 3: Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯
            with tabs_edit[2]:
                st.subheader("ğŸ†• Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯")
                sheet_name_col = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØª Ù„Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯:", list(sheets_edit.keys()), key="add_col_sheet")
                df_col = sheets_edit[sheet_name_col].astype(str)
                
                new_col_name = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯:", key="new_col_name")
                default_value = st.text_input("Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„ÙƒÙ„ Ø§Ù„ØµÙÙˆÙ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ):", "", key="default_value")

                col_btn1, col_btn2 = st.columns(2)
                with col_btn1:
                    if st.button("ğŸ’¾ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯", key=f"add_col_{sheet_name_col}", type="primary"):
                        if new_col_name:
                            df_col[new_col_name] = default_value
                            sheets_edit[sheet_name_col] = df_col.astype(object)
                            
                            new_sheets = auto_save_to_github(
                                sheets_edit,
                                f"Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯ '{new_col_name}' Ø¥Ù„Ù‰ {sheet_name_col}"
                            )
                            if new_sheets is not None:
                                sheets_edit = new_sheets
                                st.success("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­!")
                                st.rerun()
                        else:
                            st.warning("âš  Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯.")
                
                with col_btn2:
                    if st.button("ğŸ—‘ Ù…Ø³Ø­", key=f"clear_col_{sheet_name_col}"):
                        st.rerun()

            # Tab 4: Ø¥Ø¶Ø§ÙØ© Ø¥ÙŠÙÙŠÙ†Øª Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ ØµÙˆØ±
            with tabs_edit[3]:
                add_new_event(sheets_edit)

            # Tab 5: ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¥ÙŠÙÙŠÙ†Øª ÙˆØ§Ù„ÙƒÙˆØ±ÙŠÙƒØ´Ù† ÙˆØ§Ù„ØµÙˆØ±
            with tabs_edit[4]:
                edit_events_and_corrections(sheets_edit)
            
            # Tab 6: Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø´ÙŠØªØ§Øª ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø©
            with tabs_edit[5]:
                sheets_edit = manage_sheets_and_columns(sheets_edit)
            
            # Tab 7: Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµÙˆØ±
            with tabs_edit[6]:
                st.subheader("ğŸ“· Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø®Ø²Ù†Ø©")
                
                if os.path.exists(IMAGES_FOLDER):
                    image_files = [f for f in os.listdir(IMAGES_FOLDER) if f.lower().endswith(tuple(APP_CONFIG["ALLOWED_IMAGE_TYPES"]))]
                    
                    if image_files:
                        st.info(f"Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø®Ø²Ù†Ø©: {len(image_files)}")
                        
                        # ÙÙ„ØªØ±Ø© Ø§Ù„ØµÙˆØ±
                        search_term = st.text_input("ğŸ” Ø¨Ø­Ø« Ø¹Ù† ØµÙˆØ±:", placeholder="Ø§Ø¨Ø­Ø« Ø¨Ø§Ø³Ù… Ø§Ù„ØµÙˆØ±Ø©")
                        
                        filtered_images = image_files
                        if search_term:
                            filtered_images = [img for img in image_files if search_term.lower() in img.lower()]
                            st.caption(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(filtered_images)} ØµÙˆØ±Ø©")
                        
                        # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±
                        images_per_page = 9
                        if "image_page" not in st.session_state:
                            st.session_state.image_page = 0
                        
                        total_pages = (len(filtered_images) + images_per_page - 1) // images_per_page
                        
                        if filtered_images:
                            # Ø£Ø²Ø±Ø§Ø± Ø§Ù„ØªÙ†Ù‚Ù„ Ø¨ÙŠÙ† Ø§Ù„ØµÙØ­Ø§Øª
                            col_nav1, col_nav2, col_nav3 = st.columns([1, 2, 1])
                            with col_nav1:
                                if st.button("âª Ø§Ù„Ø³Ø§Ø¨Ù‚", disabled=st.session_state.image_page == 0):
                                    st.session_state.image_page = max(0, st.session_state.image_page - 1)
                                    st.rerun()
                            
                            with col_nav2:
                                st.caption(f"Ø§Ù„ØµÙØ­Ø© {st.session_state.image_page + 1} Ù…Ù† {total_pages}")
                            
                            with col_nav3:
                                if st.button("Ø§Ù„ØªØ§Ù„ÙŠ â©", disabled=st.session_state.image_page == total_pages - 1):
                                    st.session_state.image_page = min(total_pages - 1, st.session_state.image_page + 1)
                                    st.rerun()
                            
                            # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±
                            start_idx = st.session_state.image_page * images_per_page
                            end_idx = min(start_idx + images_per_page, len(filtered_images))
                            
                            for i in range(start_idx, end_idx, 3):
                                cols = st.columns(3)
                                for j in range(3):
                                    idx = i + j
                                    if idx < end_idx:
                                        with cols[j]:
                                            img_file = filtered_images[idx]
                                            img_path = os.path.join(IMAGES_FOLDER, img_file)
                                            
                                            try:
                                                st.image(img_path, caption=img_file, use_column_width=True)
                                                
                                                # Ø²Ø± Ø­Ø°Ù Ø§Ù„ØµÙˆØ±Ø©
                                                if st.button(f"ğŸ—‘ Ø­Ø°Ù", key=f"delete_{img_file}"):
                                                    if delete_image_file(img_file):
                                                        st.success(f"âœ… ØªÙ… Ø­Ø°Ù {img_file}")
                                                        st.rerun()
                                                    else:
                                                        st.error(f"âŒ ÙØ´Ù„ Ø­Ø°Ù {img_file}")
                                            except:
                                                st.write(f"ğŸ“· {img_file}")
                                                st.caption("âš  Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©")
                    else:
                        st.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ± Ù…Ø®Ø²Ù†Ø© Ø¨Ø¹Ø¯")
                else:
                    st.warning(f"âš  Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ± {IMAGES_FOLDER} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")

# -------------------------------
# Tab: ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© - Ù„Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠÙ† ÙÙ‚Ø·
# -------------------------------
if permissions["can_manage_users"] and len(tabs) > 2:
    with tabs[2]:
        st.header("ğŸ“Š ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©")
        
        if all_sheets is None:
            st.warning("â— Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù„ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
        else:
            st.markdown("### ğŸ“ˆ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø´Ø§Ù…Ù„Ø©")
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
            total_sheets = len(all_sheets)
            total_rows = sum(len(df) for df in all_sheets.values())
            total_columns = sum(len(df.columns) for df in all_sheets.values())
            
            col_stat1, col_stat2, col_stat3 = st.columns(3)
            with col_stat1:
                st.metric("ğŸ“‚ Ø¹Ø¯Ø¯ Ø§Ù„Ø´ÙŠØªØ§Øª", total_sheets)
            with col_stat2:
                st.metric("ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ", total_rows)
            with col_stat3:
                st.metric("ğŸ“‹ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©", total_columns)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª
            st.markdown("### ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª")
            
            sheets_analysis = []
            for sheet_name, df in all_sheets.items():
                non_empty = df.notna().sum().sum()
                total_cells = len(df) * len(df.columns)
                fill_rate = (non_empty / total_cells * 100) if total_cells > 0 else 0
                
                sheets_analysis.append({
                    "Ø§Ø³Ù… Ø§Ù„Ø´ÙŠØª": sheet_name,
                    "Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ": len(df),
                    "Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©": len(df.columns),
                    "Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ø¨Ø¦Ø© %": round(fill_rate, 2),
                    "Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ±ÙŠØ¯Ø©": ", ".join(df.columns[:3]) + ("..." if len(df.columns) > 3 else "")
                })
            
            analysis_df = pd.DataFrame(sheets_analysis)
            st.dataframe(analysis_df, use_container_width=True)
            
            # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø´ÙŠØªØ§Øª
            st.markdown("### ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            
            chart_data = pd.DataFrame({
                "Ø§Ù„Ø´ÙŠØª": list(all_sheets.keys()),
                "Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ": [len(df) for df in all_sheets.values()],
                "Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©": [len(df.columns) for df in all_sheets.values()]
            })
            
            try:
                import plotly.express as px
                
                fig1 = px.bar(chart_data, x='Ø§Ù„Ø´ÙŠØª', y='Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ', 
                            title='ØªÙˆØ²ÙŠØ¹ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø­Ø³Ø¨ Ø§Ù„Ø´ÙŠØª')
                st.plotly_chart(fig1, use_container_width=True)
                
                fig2 = px.bar(chart_data, x='Ø§Ù„Ø´ÙŠØª', y='Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©',
                            title='ØªÙˆØ²ÙŠØ¹ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø­Ø³Ø¨ Ø§Ù„Ø´ÙŠØª')
                st.plotly_chart(fig2, use_container_width=True)
                
            except ImportError:
                st.info("ğŸ“Š Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© plotly")
